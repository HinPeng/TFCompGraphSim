model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_1_grad/Sum 637080 637088
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_1/strided_slice_1 349812 349821
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/add_grad/Sum 997758 997766
model/get_train_op/model/Transformer/decoder_stack/layer_1/encdec_attention/attention/k/kernel/Adam 680 686
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot_grad/Reshape 1017399 1017409
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/Reshape 224815 224831
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/floordiv_1 83156 83172
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/v/Tensordot 314769 314775
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Prod 126863 126875
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/combine_heads/Reshape_grad/Shape 291619 291626
model/get_train_op/model/Transformer/decoder_stack/layer_1/encdec_attention/attention/q/kernel/Adam_1 716 722
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/div_grad/Shape_1 4534 4538
model/get_train_op/beta1_power 7428 7473
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/concat_2 56929 56964
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/add_grad/Shape_1 357501 357510
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/add_grad/Sum 475168 475178
model/get_train_op/model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale/Adam 1205 1210
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/attention_weights_grad/Sum/reduction_indices 6917 6923
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp 11269 11279
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/floordiv_1 99511 99526
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_2/Reshape 202098 202104
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/v/Tensordot_grad/Shape 314778 314785
model/get_train_op/model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias/Adam_1 2146 2151
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Prod 237764 237782
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/floordiv 325325 325335
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_2/Reshape/shape 118470 118480
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot 377030 377038
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/v/Tensordot_grad/Shape 201423 201430
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/add_grad/Shape 365081 365090
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_2/strided_slice 314877 314886
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Prod_1 365168 365177
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Square_grad/Const 496364 496372
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/tuple/group_deps 489204 489208
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/sub_1_grad/Shape_1 307362 307369
model/get_train_op/model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias/Adam_1 1545 1550
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot_grad/Shape 129594 129608
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_1_grad/tuple/group_deps 502140 502145
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Maximum/y 7035 7043
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/Prod_1 294607 294628
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Shape 368289 368296
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1 225464 225474
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/Reshape 644566 644574
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/ReadVariableOp 8548 8556
model/Transformer/decode/shift_targets/Pad/paddings 3532 3536
model/Transformer/decoder_stack/layer_3/encdec_attention/attention/output_transform/kernel 5418 5422
model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel 5568 5572
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/sub_grad/Shape_1 225343 225359
model/Transformer/decoder_stack/layer_0/self_attention/self_attention/v/kernel 3495 3502
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/floordiv 255454 255465
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_1_grad/Shape_1 126577 126588
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot_grad/Shape 255679 255693
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape 486291 486307
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/transpose_1_grad/InvertPermutation 356 364
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1 13447 13456
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Shape 365099 365106
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/k/Tensordot_grad/Shape 279761 279771
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/add_grad/BroadcastGradientArgs 153996 154008
model/loss/pad_to_same_length/Pad/paddings/0_1 5140 5145
model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias 5383 5388
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads/Reshape/shape 360519 360532
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/tuple/group_deps 1009227 1009230
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/dropout/div_grad/Shape_1 4798 4802
model/get_train_op/model/Transformer/decoder_stack/layer_3/self_attention/self_attention/output_transform/kernel/Adam 1577 1582
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Maximum/y 4702 4710
model/get_train_op/model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias/Adam 6528 6536
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/dropout/div_grad/Sum 599181 599206
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_grad/Shape 82728 82739
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Shape 165400 165409
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/dropout/div_grad/BroadcastGradientArgs 45345 45373
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/add_grad/Reshape_1 990762 990770
model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias 5338 5342
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/Shape_1 4968 4973
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape 1005734 1005745
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_grad/Shape_1 21173 21192
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_grad/Reshape 996260 996270
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_1_grad/Sum 505553 505564
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/concat_2 396986 397009
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/Gather_grad/strided_slice 15824 15846
model/get_train_op/model/Transformer/decoder_stack/layer_5/encdec_attention/attention/k/kernel/Adam_1 1955 1960
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1 14939 14950
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads/strided_slice 23958 23980
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/floordiv 360242 360253
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/k/Tensordot/transpose_1 15085 15098
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/Maximum/y 4198 4203
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/re_add_padding/Squeeze 54845 54863
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/v/Tensordot/transpose_1 15514 15523
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/Maximum_1 253376 253393
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/dropout/div_grad/Shape 45270 45287
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Prod 307445 307455
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_grad/Shape 400627 400635
model/get_train_op/train/ReadVariableOp 1021265 1021272
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1 13770 13775
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/stack 109714 109742
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_1_grad/Shape_1 4855 4860
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/transpose_1 16168 16175
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/sub_grad/Reshape 485702 485713
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_grad/BroadcastGradientArgs 393324 393344
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads/Reshape 384988 384994
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads/strided_slice 349769 349783
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1 13189 13199
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/Maximum_1 41893 41918
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_1_grad/Sum 1016319 1016326
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/k/Tensordot 244787 244792
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/div_grad/Shape 174253 174263
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp 11258 11267
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/BroadcastGradientArgs 99610 99628
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Maximum 244406 244429
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp 10955 10965
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/dropout/div_grad/Reshape 1010674 1010683
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/dropout/div_grad/Shape 287391 287400
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_grad/Shape_1 154150 154161
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/div_grad/BroadcastGradientArgs 146726 146738
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/v/Tensordot/Reshape_grad/Shape 308012 308018
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_grad/Reshape 989801 989809
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Prod 181785 181795
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot_grad/Shape 54721 54741
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot 45137 45153
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_1_grad/Reshape_1 999363 999372
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_1_grad/Reshape 640252 640264
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Shape 99694 99704
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_2/strided_slice_1 118411 118421
model/get_train_op/model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel/Adam_1 2084 2090
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_grad/Shape 288112 288128
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/mul_grad/Sum 494889 494898
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/mul_grad/Reshape 473422 473434
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/v/Tensordot/Reshape_grad/Shape 193989 193996
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/attention_weights_grad/Sum/reduction_indices 4590 4598
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/concat_2 308136 308168
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Maximum_1 20646 20659
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads/Reshape 279962 279969
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1 225448 225461
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1 13062 13069
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_grad/Shape_1 193014 193020
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot_grad/Shape 184700 184711
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_1_grad/Reshape 510498 510508
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Maximum_1 365285 365296
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/mul_grad/Reshape 499224 499237
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Prod 55622 55641
model/Transformer/decoder_stack/layer_1/self_attention/self_attention/v/kernel 5638 5642
model/get_train_op/model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias/Adam 1826 1833
model/get_train_op/model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_scale/Adam_1 765 771
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/attention_weights_grad/Sum/reduction_indices 6309 6315
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/mul_grad/BroadcastGradientArgs 17806 17855
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_1_grad/tuple/group_deps 505817 505820
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/add_grad/Sum 1013407 1013415
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/sub_1_grad/Shape_1 252823 252836
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_1_grad/Reshape_1 988484 988491
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_grad/Reshape_1 509150 509160
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads/Reshape 118483 118491
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/add_grad/Sum 994511 994519
model/get_train_op/model/Transformer/decoder_stack/layer_2/encdec_attention/attention/output_transform/kernel/Adam_1 1040 1049
model/get_train_op/model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel/Adam_1 863 868
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_grad/Reshape 1009596 1009607
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_2/strided_slice 63262 63273
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Maximum 263066 263099
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_grad/tuple/group_deps 999211 999215
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/Prod_1 255368 255391
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Maximum_1 39851 39865
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/mul_grad/Shape 255816 255828
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/mul_grad/BroadcastGradientArgs 17978 18007
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/stack 271919 271942
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/add_grad/Sum_1 479378 479386
model/get_train_op/gradients/model/loss/smoothing_cross_entropy/sub_grad/BroadcastGradientArgs 466567 466582
model/get_train_op/model/Transformer/decoder_stack/layer_1/encdec_attention/attention/output_transform/kernel/Adam 694 700
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Prod 225305 225320
model/Transformer/encode/encoder_stack/layer_3/ffn/dropout/Shape 137655 137666
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/v/Tensordot 63142 63148
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/k/Tensordot/Reshape_grad/Shape 193947 193955
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Prod 330316 330325
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/tuple/group_deps 1006161 1006164
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/k/Tensordot_grad/Reshape 505137 505148
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/dropout/div_grad/Sum 480010 480023
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_1_grad/Reshape_1 636452 636459
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/div_grad/Reshape 992358 992367
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_1/Reshape/shape 24121 24159
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_1_grad/Sum 1000749 1000757
model/Transformer/decode/decoder_stack/layer_5/self_attention/dropout/Shape 392524 392532
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_grad/BroadcastGradientArgs 154833 154846
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/add_grad/Reshape 644521 644530
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/strided_slice/stack 3034 3095
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Shape 401028 401035
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp 11875 11885
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Prod 71490 71506
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/add_grad/Shape 342281 342291
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/combine_heads/Reshape_grad/Shape 396800 396807
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp 10911 10924
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/sub_grad/Shape 272327 272335
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Maximum/y 4481 4485
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_1_grad/Shape 296006 296019
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot_grad/Shape 38969 38986
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Shape 368279 368287
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp 11501 11510
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/tuple/group_deps 995721 995724
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot_grad/Reshape 1012186 1012198
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape 479669 479683
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/sub_grad/Shape_1 322677 322684
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/dropout/div_grad/BroadcastGradientArgs 364899 364923
model/get_train_op/model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_bias/Adam 1380 1389
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/add_grad/Reshape_1 500995 501008
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/add_grad/Reshape_1 996460 996470
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/dropout/div_grad/BroadcastGradientArgs 263387 263399
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/stack 38810 38842
model/get_train_op/gradients/model/loss/pad_to_same_length/Pad_grad/Slice/begin 4050 4057
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Reshape 480793 480805
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/div_grad/Shape_1 6302 6308
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Reshape_1 989780 989787
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_1_grad/Shape_1 4300 4306
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/floordiv_1 56410 56434
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/ReadVariableOp 8709 8720
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_1_grad/Shape 126448 126457
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_1_grad/Shape 192956 192967
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_1/ReadVariableOp 10752 10766
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/div_grad/Shape_1 5654 5659
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_2/Reshape 63385 63393
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/add_grad/Reshape 1012092 1012101
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/Reshape_grad/Shape 288637 288644
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/add_grad/Sum 1001731 1001739
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_1_grad/BroadcastGradientArgs 154267 154286
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/mul_grad/Reshape 1018224 1018234
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/stack 145598 145628
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/floordiv_1 225944 225961
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Reshape 478811 478827
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp 11361 11370
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_grad/Shape 99282 99293
model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias 5527 5531
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/mul_grad/Reshape 1002642 1002652
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/mul_grad/Shape_1 146856 146865
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Shape 295893 295914
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot 126198 126207
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp 11143 11148
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/k/Tensordot 23760 23771
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp 12212 12223
model/get_train_op/model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias/Adam_1 877 886
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/Shape_1 3272 3292
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/v/Tensordot_grad/Shape 201284 201292
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_1/strided_slice_1 384897 384918
model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel 5401 5407
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs 22245 22271
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp_1 13521 13529
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/Reshape_1 993577 993584
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/sub_grad/Reshape 509469 509479
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/tuple/group_deps 1019831 1019833
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_grad/Reshape 999375 999385
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_1_grad/Sum 1020054 1020061
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_1_grad/Reshape 467577 467594
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/combine_heads/Reshape_grad/Reshape 1002047 1002062
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice/stack_1 7333 7342
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_grad/Shape_1 295832 295842
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/concat_2 203702 203725
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/floordiv 255425 255436
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/div_grad/Shape 396297 396306
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_grad/Shape 182009 182019
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_2/strided_slice 201619 201630
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_1/Shape 23917 23930
model/get_train_op/model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias/Adam_1 460 468
model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias 6110 6116
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/re_add_padding/ScatterNd/shape 72674 72685
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_1_grad/Shape_1 193005 193012
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/concat_2 323465 323484
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp 12448 12457
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/ReadVariableOp 10391 10402
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/mul_grad/Shape_1 2445 2453
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_1_grad/BroadcastGradientArgs 99677 99692
model/get_train_op/model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias/Adam_1 1142 1150
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape 490618 490634
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Maximum_1 21146 21168
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_grad/BroadcastGradientArgs 358010 358037
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1 13614 13625
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/dropout/div_grad/Shape 98573 98583
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_1_grad/Reshape 1005943 1005953
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/floordiv 263105 263124
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Sum 508924 508933
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Square_grad/Const 470546 470557
model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel 4997 5001
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_2/Shape 145882 145889
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp 12735 12747
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Shape 182645 182651
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads/strided_slice 173507 173522
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/transpose_1 16259 16266
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/mul_grad/BroadcastGradientArgs 385155 385171
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/stack 90483 90508
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/floordiv_1 342824 342835
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/v/Tensordot/Reshape_grad/Shape 22350 22361
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp 10982 10994
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/add_grad/Shape 400278 400286
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_1_grad/BroadcastGradientArgs 323358 323368
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Prod_1 260582 260600
model/get_train_op/model/Transformer/encoder_stack/layer_0/self_attention/self_attention/output_transform/kernel/Adam 3313 3319
model/get_train_op/model/Transformer/decoder_stack/layer_2/self_attention/self_attention/output_transform/kernel/Adam 1260 1265
model/Transformer/encode/add_pos_encoding/ExpandDims 19107 19122
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/stack 192409 192440
model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_bias 3737 3742
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape 498113 498130
model/Transformer/decoder_stack/layer_5/encdec_attention/attention/k/kernel 4770 4774
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_grad/Shape 253140 253153
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Prod_1 39723 39737
model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/Slice_2 413525 413539
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/add_grad/Shape_1 126394 126403
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/add_grad/Sum 472645 472655
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/dropout/div_grad/Reshape 971222 971233
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_grad/Shape 39788 39802
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1 13896 13915
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/stack 306897 306929
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp 12557 12567
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/dropout/div_grad/Shape 350490 350499
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Reshape 1009397 1009407
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_2/strided_slice 90842 90853
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/mul_grad/Shape 15868 15881
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot_grad/Shape 368028 368041
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/dropout/div_grad/BroadcastGradientArgs 74626 74645
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Prod_1 342609 342617
model/get_train_op/model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel/Adam_1 1781 1786
model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/Slice_1 466185 466198
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_grad/Sum 996209 996216
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/k/Tensordot/transpose_1 15169 15178
model/get_train_op/gradients/model/Transformer/decode/dropout/div_grad/Reshape 991280 991289
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/Reshape_1 1019633 1019640
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_1/strided_slice 201697 201706
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Maximum 90363 90383
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/Prod 393193 393209
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/add_1_grad/Sum 467215 467229
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/combine_heads/strided_slice 315993 316003
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Prod_1 272731 272742
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/add_grad/Sum 509646 509654
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/mul_grad/Sum 1019103 1019111
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_1_grad/Reshape 996007 996017
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot 228185 228194
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/sub_1_grad/Reshape_1 478798 478808
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/add_grad/BroadcastGradientArgs 365108 365117
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_grad/Reshape 614053 614065
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Shape 281036 281041
model/Transformer/decode/decoder_stack/layer_4/self_attention/dropout/Shape 357306 357312
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/floordiv_1 21724 21749
model/get_train_op/model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale/Adam 5876 5883
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/v/Tensordot/Reshape_grad/Shape 238365 238373
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/combine_heads/Reshape_grad/Reshape 493020 493041
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/floordiv_1 165809 165827
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/floordiv 349394 349403
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_1_grad/Reshape 474192 474206
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/concat_2 281147 281165
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/transpose_1 16058 16063
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/dropout/div_grad/Sum 1005487 1005498
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/combine_heads/Shape 26239 26259
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1 156805 156826
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape 1016071 1016085
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/div_grad/Sum 512563 512571
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Reshape 1011705 1011713
model/get_train_op/model/Transformer/encoder_stack/layer_5/self_attention/self_attention/v/kernel/Adam 7259 7263
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Shape 273095 273102
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_1/strided_slice 349800 349810
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp 10875 10888
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/add_grad/Reshape 504623 504632
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_grad/Shape_1 4981 4985
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/floordiv_1 238120 238136
model/Transformer/decode/decoder_stack/layer_1/ffn/dropout/Shape 272120 272130
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/stack 403144 403171
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/dropout/div_grad/BroadcastGradientArgs 153805 153821
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/mul_grad/Shape_1 203188 203216
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/re_add_padding/Reshape/shape 99867 99879
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/Reshape_grad/Shape 396873 396881
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Shape 83099 83109
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp 11025 11036
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/re_add_padding/Squeeze 82379 82389
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_grad/Sum 1009538 1009549
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape 1019458 1019471
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp 11437 11443
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot 184713 184721
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/mul_grad/Sum 493734 493744
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Maximum 367742 367758
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/k/Tensordot/Reshape_grad/Reshape 505325 505337
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp 12425 12433
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/Maximum/y 2716 2723
model/get_train_op/model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias/Adam_1 6475 6482
model/get_train_op/model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias/Adam_1 5868 5875
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot_grad/Reshape 988879 988891
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/add_grad/Reshape 648819 648829
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/transpose_1 15970 15982
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/add_grad/Reshape_1 506505 506512
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1 272523 272528
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/stack 74333 74362
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Maximum/y 5033 5038
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads/Reshape/shape 325673 325684
model/get_train_op/model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias/Adam 5807 5811
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/Reshape_1 1014428 1014436
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Square_grad/Const 1011780 1011787
model/get_train_op/train/beta2 3916 3961
model/get_train_op/train/beta1 7544 7627
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/combine_heads/Reshape_grad/Reshape 471422 471437
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/mul_grad/Sum 484091 484105
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/mul_grad/Reshape 508371 508382
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_1/strided_slice_1 24037 24057
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Maximum 314422 314441
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Shape 155281 155289
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/dropout/div_grad/BroadcastGradientArgs 39125 39149
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/mul_grad/Sum 998276 998283
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/Reshape_grad/Reshape 495360 495379
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/dropout/mul_grad/Shape 280600 280607
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Prod_1 55773 55789
model/get_train_op/model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias/Adam 6779 6783
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Shape 400528 400536
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_1_grad/Shape 226060 226070
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Reshape 341914 341926
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape 989067 989077
model/Transformer/decoder_stack/layer_4/encdec_attention/attention/k/kernel 7287 7294
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/Prod 41669 41684
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Shape_1 6234 6240
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/combine_heads/Reshape/shape 396840 396851
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1 14374 14384
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Maximum/y 6086 6091
model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias 5439 5444
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/ReadVariableOp 10267 10279
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1 15014 15023
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_1/Reshape 63372 63381
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1 14163 14171
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/k/Tensordot_grad/Shape 63121 63131
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/add_grad/Reshape_1 1001760 1001768
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/combine_heads/Reshape_grad/Reshape 991267 991277
model/get_train_op/model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias/Adam 2140 2145
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/mul_1_grad/Reshape 992347 992356
model/get_train_op/model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias/Adam_1 2098 2103
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Reshape_1 998975 998982
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_grad/Reshape 1004445 1004456
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/BiasAdd/ReadVariableOp 10433 10446
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/q/kernel/ResourceApplyAdam/ReadVariableOp 11577 11586
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/dropout/Shape 329940 329947
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/Shape 377997 378004
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/dropout/div_grad/Reshape 501593 501609
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Reshape 1017185 1017194
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/Prod 357686 357697
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Shape_1 4620 4625
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Reshape 999388 999397
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_grad/Shape_1 127082 127091
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_1_grad/BroadcastGradientArgs 261313 261330
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Shape 72652 72660
model/get_train_op/model/Transformer/decoder_stack/layer_0/self_attention/self_attention/v/kernel/Adam_1 670 678
model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/Slice 413506 413521
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Shape 72662 72672
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1 14468 14476
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/Shape 287669 287679
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/v/Tensordot/ReadVariableOp 10530 10540
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/Gather_grad/ExpandDims 7972 7982
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Maximum 297893 297924
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp 10928 10939
model/get_train_op/model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias/Adam_1 596 602
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/combine_heads/Reshape_grad/Reshape 996732 996745
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_grad/tuple/group_deps 995927 995930
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Reshape 192445 192458
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/dropout/div_grad/Shape_1 5729 5734
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_1_grad/Shape_1 181691 181698
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/add_grad/Shape_1 98768 98779
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/div_grad/BroadcastGradientArgs 174304 174316
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1 14952 14962
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/dropout/div_grad/Reshape 503436 503444
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Maximum_1 330631 330642
model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias 298 304
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/add_1_grad/Sum 636044 636054
model/get_train_op/model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_bias/Adam_1 1718 1723
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/dropout/Shape 45330 45342
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/stack 70937 70971
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_grad/BroadcastGradientArgs 21491 21523
model/get_train_op/model/Transformer/decoder_stack/layer_3/encdec_attention/attention/q/kernel/Adam 1338 1346
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp 11775 11785
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Maximum_1 365522 365530
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/k/Tensordot/transpose_1 15348 15355
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_grad/Shape 83239 83257
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Shape 147271 147278
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/add_grad/BroadcastGradientArgs 25172 25203
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Prod 20834 20851
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp 11920 11931
model/get_train_op/model/Transformer/decoder_stack/layer_2/encdec_attention/attention/v/kernel/Adam_1 1082 1090
model/Transformer/encode/embedding_shared_weights/embedding_1/ExpandDims/dim 3513 3521
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_grad/Reshape 1014813 1014824
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/floordiv_1 288043 288059
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Shape 225530 225539
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp_1 13227 13239
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Prod_1 287075 287093
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/combine_heads/strided_slice_1 326680 326692
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/v/Tensordot 23795 23810
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/add_grad/Shape 322628 322636
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_1_grad/Shape 253480 253489
model/get_train_op/model/Transformer/encoder_stack/layer_5/self_attention/self_attention/output_transform/kernel/Adam_1 7226 7229
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Const_2 5224 5240
model/Transformer/decoder_stack/layer_2/self_attention/self_attention/v/kernel 5542 5546
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/Reshape_1 99707 99717
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_grad/Reshape_1 505992 506002
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/Prod_1 393278 393293
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/dropout/div_grad/Shape_1 6970 6975
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/stack 399902 399941
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/v/Tensordot/transpose_1 15762 15772
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/k/Tensordot_grad/Shape 349705 349712
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1 13992 14001
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/k/Tensordot_grad/Shape 201439 201446
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/dropout/mul_grad/Shape 245627 245634
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1 13500 13505
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/sub_1_grad/Shape_1 20385 20398
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/stack 333039 333066
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/dropout/div_grad/Sum 994600 994607
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Prod 182055 182066
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Shape 307876 307885
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/dropout/div_grad/Reshape 511537 511545
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Shape 20658 20675
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads/strided_slice 384857 384871
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/dropout/mul_grad/Reshape 476303 476314
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs 20504 20530
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/dropout/div_grad/BroadcastGradientArgs 184836 184850
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/add_1_grad/Reshape 636206 636220
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/Prod_1 193387 193396
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/floordiv_1 110688 110704
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/dropout/div_grad/Reshape 480025 480034
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/add_grad/Shape_1 412345 412353
model/get_train_op/model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel/Adam 6484 6491
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/floordiv 129339 129357
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice/stack_1 6373 6380
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Reshape 184620 184635
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_grad/Shape 154490 154503
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/add_grad/Reshape_1 486015 486030
model/Transformer/decode/presoftmax_linear/MatMul/ReadVariableOp 9332 9344
model/Transformer/decode/decoder_self_attention_bias/Reshape/shape 18987 18998
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Shape 137881 137889
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Reshape 989042 989055
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp 12413 12423
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_2/Reshape/shape 24061 24076
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_2/Shape 23933 23949
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1 14704 14716
model/get_train_op/model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale/Adam 929 934
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_2/Reshape 173653 173660
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_1_grad/BroadcastGradientArgs 193117 193141
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot_grad/Shape 333175 333189
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_grad/BroadcastGradientArgs 323081 323097
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Shape 330210 330217
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_grad/Shape_1 55756 55770
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Reshape 479210 479223
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Reshape_1 1001016 1001023
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Shape_1 4502 4506
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_grad/Shape_1 253397 253411
model/Transformer/decoder_stack/layer_3/self_attention/self_attention/v/kernel 5467 5471
model/get_train_op/model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale/Adam_1 577 585
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Square_grad/Const 1006582 1006589
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_grad/BroadcastGradientArgs 99368 99387
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/floordiv_1 412684 412695
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_1_grad/Reshape_1 1000807 1000816
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp 12762 12768
model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add/y 3566 3582
model/get_train_op/gradients/model/Transformer/encode/dropout/mul_grad/Reshape 1020602 1020611
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape 995452 995463
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/combine_heads/Shape 280962 280972
model/Transformer/encode/encoder_stack/layer_5/ffn/dropout/Shape 192681 192688
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/Reshape 260023 260038
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_grad/Sum 1009744 1009754
model/Transformer/decode/dropout/Shape 19873 19889
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/stack 23227 23259
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_2/strided_slice 201773 201782
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_1/ReadVariableOp 9038 9046
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp 11653 11662
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Sum 611848 611859
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/Reshape_grad/Reshape 635641 635653
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/floordiv 403038 403047
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/transpose_1 16184 16190
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_1_grad/Reshape_1 994126 994135
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/add_grad/Reshape_1 999808 999816
model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias 3855 3861
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/mul_grad/Sum 508266 508273
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/floordiv 129347 129363
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/mul_grad/Shape_1 7253 7258
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/sub_1_grad/Shape_1 377416 377423
model/get_train_op/model/Transformer/decoder_stack/layer_2/self_attention/self_attention/q/kernel/Adam_1 1279 1285
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/GatherNd_grad/Squeeze 18031 18053
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_grad/Shape 110268 110279
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs 138139 138163
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/ReadVariableOp 9650 9661
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_1_grad/BroadcastGradientArgs 393690 393708
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/add_grad/Reshape_1 598525 598535
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape 480358 480372
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_grad/Sum 1006474 1006483
model/get_train_op/model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale/Adam_1 6555 6562
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/re_add_padding/Reshape/shape 40778 40800
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Maximum/y 5028 5032
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_1/strided_slice 63223 63241
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/stack 287262 287290
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Reshape 403175 403189
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_1_grad/BroadcastGradientArgs 288605 288625
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/mul_grad/Reshape 472261 472278
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/add_1_grad/Shape_1 5067 5072
model/Transformer/decoder_stack/layer_4/self_attention/self_attention/q/kernel 5355 5359
model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_1/ReadVariableOp 7695 7707
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_grad/Reshape 990268 990279
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/Reshape 644555 644563
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/floordiv_1 20804 20826
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_grad/Shape_1 288322 288337
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_1_grad/tuple/group_deps 995530 995533
model/get_train_op/model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias/Adam_1 6143 6147
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/stack 50174 50208
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot_grad/Shape 45115 45133
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/BroadcastGradientArgs 22375 22401
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Shape 238149 238158
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/dropout/div_grad/Shape_1 4529 4533
model/get_train_op/model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias/Adam 5787 5791
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Prod_1 38786 38803
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs 111177 111212
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Maximum/y 7372 7381
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/add_grad/BroadcastGradientArgs 385472 385486
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/add_grad/Shape_1 18262 18275
model/get_train_op/model/Transformer/encoder_stack/layer_normalization/layer_norm_bias/Adam 7395 7401
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp_1 13688 13698
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/add_grad/Reshape 511452 511461
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Shape 181665 181674
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/mul_grad/Shape 24430 24447
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/sub_1_grad/Shape_1 225324 225340
model/get_train_op/model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale/Adam_1 3262 3270
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_1_grad/Shape 71377 71387
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape 515643 515655
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot_grad/Shape 137432 137447
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/stack 259986 260018
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/div_grad/BroadcastGradientArgs 396347 396363
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Maximum/y 2817 2829
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1 342879 342884
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/add_grad/Shape_1 82656 82667
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/combine_heads/strided_slice_1 396809 396824
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/add_grad/Shape 126459 126466
model/get_train_op/model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias/Adam 6755 6762
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/ReadVariableOp 9758 9767
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape 491163 491178
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads/Shape 395692 395699
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Maximum/y 6736 6744
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_1_grad/Reshape 495800 495816
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1 13125 13136
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/BiasAdd/ReadVariableOp 9706 9717
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/add_grad/Sum 1004983 1004991
model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias 3829 3836
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/dropout/div_grad/Shape_1 4353 4357
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/dropout/Shape 245601 245609
model/get_train_op/model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias/Adam_1 6122 6126
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Prod_1 400681 400691
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Maximum 156842 156861
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/v/Tensordot_grad/Reshape 472110 472123
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/Shape 42282 42297
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Maximum 263028 263051
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/transpose_1 15644 15650
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/div_grad/Shape 361100 361107
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_grad/Shape_1 6708 6715
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Sum 1000963 1000971
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_2/strided_slice_1 90829 90839
model/get_train_op/model/Transformer/encoder_stack/layer_1/self_attention/self_attention/q/kernel/Adam 5957 5963
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape 995311 995322
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_grad/Reshape 644077 644089
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/v/Tensordot 244804 244811
model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale 3787 3791
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/v/Tensordot/Reshape_grad/Shape 56782 56798
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/dropout/div_grad/Shape 403366 403375
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp 11863 11873
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_1_grad/Reshape 1011633 1011643
model/get_train_op/gradients/model/Transformer/encode/dropout/mul_grad/Shape_1 20015 20040
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/floordiv_1 138307 138322
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/ExpandDims_grad/Reshape 995390 995403
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/add_grad/Reshape 987786 987796
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Maximum 22104 22121
model/get_train_op/gradients/model/Transformer/decode/dropout/div_grad/BroadcastGradientArgs 19892 19924
model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale 5623 5630
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/Sum 516865 516873
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/re_add_padding/Reshape_grad/Reshape 1015505 1015514
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/v/Tensordot 201465 201472
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/stack 184589 184616
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/dropout/div_grad/Shape 263334 263344
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_1_grad/Reshape 505598 505608
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot 263268 263275
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Maximum_1 225866 225878
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/dropout/div_grad/Shape 280536 280545
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/mul_grad/Sum 1002617 1002627
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Prod_1 20479 20501
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1 14745 14750
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/sub_grad/Shape_1 330240 330246
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Prod_1 117803 117833
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/Prod 252804 252820
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/Prod 287753 287764
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/ReadVariableOp 9512 9524
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_grad/BroadcastGradientArgs 166178 166202
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Reshape 509550 509558
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/Prod_1 329625 329642
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/dropout/div_grad/Sum 501578 501590
model/get_train_op/model/Transformer/decoder_stack/layer_2/self_attention/self_attention/output_transform/kernel/Adam_1 1267 1272
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/k/Tensordot/transpose_1 15341 15347
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/v/Tensordot_grad/Shape 201314 201322
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_grad/Reshape_1 485252 485265
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/BiasAdd/ReadVariableOp 8619 8629
model/get_train_op/model/Transformer/decoder_stack/layer_5/self_attention/self_attention/v/kernel/Adam 2205 2213
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape 1013174 1013185
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_grad/BroadcastGradientArgs 83018 83032
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1 237587 237600
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/dropout/div_grad/Reshape 1010255 1010264
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/BroadcastGradientArgs 182416 182430
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Prod_1 236714 236736
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape 1007077 1007089
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp 11039 11049
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1 365633 365638
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot_grad/Reshape 511548 511556
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot_grad/Shape 325626 325635
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/concat_2 26561 26581
model/get_train_op/model/Transformer/decoder_stack/layer_1/self_attention/self_attention/output_transform/kernel/Adam 961 966
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_grad/Reshape 1004799 1004808
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_1_grad/Reshape_1 644510 644519
model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias 6381 6385
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Maximum 22662 22688
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads/strided_slice 255716 255729
model/get_train_op/model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale/Adam_1 6834 6839
model/get_train_op/model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale/Adam 6512 6518
model/Transformer/decoder_stack/layer_3/encdec_attention/attention/k/kernel 2777 2784
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/ReadVariableOp 10213 10224
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/floordiv 156865 156875
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/dropout/div_grad/Sum 510121 510129
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/dropout/Shape 25620 25654
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_grad/Sum 1004586 1004596
model/Transformer/decoder_stack/layer_2/encdec_attention/attention/v/kernel 3898 3902
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads/strided_slice 118346 118364
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/concat_2 228609 228630
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_grad/BroadcastGradientArgs 138166 138181
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/concat_2 238504 238529
model/get_train_op/model/Transformer/encoder_stack/layer_normalization/layer_norm_scale/Adam 7411 7418
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/dropout/div_grad/Reshape 1015923 1015933
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1 393502 393512
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/floordiv_1 39962 39988
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Shape 99893 99900
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/dropout/div_grad/BroadcastGradientArgs 287455 287472
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1 238139 238147
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_grad/Shape 39495 39504
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1 14911 14924
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape 994801 994815
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/v/Tensordot_grad/Reshape 487116 487134
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/k/Tensordot 173449 173454
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/sub_grad/Reshape 496509 496523
model/get_train_op/model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel/Adam 7110 7116
model/get_train_op/model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel/Adam 5796 5800
model/Transformer/decode/presoftmax_linear/strided_slice 413240 413256
model/Transformer/encoder_stack/layer_4/self_attention/self_attention/k/kernel 5511 5516
model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/concat/values_0 5079 5104
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_1_grad/Reshape 491353 491365
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/Shape 192980 192989
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/combine_heads/Reshape_grad/Shape 203530 203537
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Reshape_1 995712 995719
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Prod_1 376735 376754
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot_grad/Shape 329929 329938
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1 392998 393002
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/Prod_1 412813 412824
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/ReadVariableOp 9835 9847
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Prod_1 165589 165607
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/add_grad/Reshape 481808 481820
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_grad/Reshape_1 502667 502680
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/Maximum/y 2702 2715
model/get_train_op/model/Transformer/encoder_stack/layer_2/self_attention/self_attention/k/kernel/Adam_1 6247 6254
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Prod 365202 365212
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/add_grad/Sum 503320 503329
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Prod_1 182022 182030
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot 400029 400042
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/sub_1_grad/Reshape_1 511031 511039
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Prod 342640 342651
model/get_train_op/model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias/Adam 6467 6474
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/attention_weights_grad/Sum/reduction_indices 6625 6630
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Maximum_1 99449 99460
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_1_grad/BroadcastGradientArgs 181798 181813
model/get_train_op/model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel/Adam_1 6800 6806
model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_1/ReadVariableOp 8058 8070
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/add_grad/BroadcastGradientArgs 55419 55438
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/add_grad/BroadcastGradientArgs 330219 330229
model/get_train_op/model/Transformer/decoder_stack/layer_2/encdec_attention/attention/output_transform/kernel/Adam 1029 1038
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/Reshape 478090 478100
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/Shape 393710 393718
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_2/Reshape/shape 279950 279959
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/mul_grad/Shape_1 396486 396495
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/tuple/group_deps 989145 989148
model/get_train_op/model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias/Adam_1 6816 6824
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape 1001964 1001977
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/mul_grad/Shape 291180 291188
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/add_grad/Sum 1018582 1018590
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/v/Tensordot/transpose_1 15636 15642
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads/Reshape 63396 63403
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot_grad/Reshape 484404 484416
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_grad/Sum 1014966 1014977
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Square_grad/Const 517529 517537
model/Transformer/decode/decoder_self_attention_bias/ones/packed 18968 18985
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_2/strided_slice 201824 201834
model/get_train_op/model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel/Adam_1 1757 1762
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_grad/Shape_1 165522 165532
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/mul_grad/Sum 1013013 1013022
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/Shape 182456 182463
model/get_train_op/gradients/model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/Reshape_2_grad/Shape 466492 466506
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp 12545 12555
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/dropout/div_grad/Shape_1 7054 7061
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot_grad/Shape 157094 157108
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/add_grad/Sum 496741 496755
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/dropout/div_grad/Sum 1015899 1015921
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_1/Shape 63172 63181
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Shape 82741 82749
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Shape 126479 126489
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/dropout/div_grad/BroadcastGradientArgs 165192 165207
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/floordiv_1 412992 413004
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_grad/Shape 357862 357872
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot_grad/Shape 412105 412121
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape 992247 992258
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_grad/BroadcastGradientArgs 110514 110535
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Square_grad/Const 506203 506210
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Square_grad/Const 1001451 1001458
model/get_train_op/model/Transformer/decoder_stack/layer_1/self_attention/self_attention/k/kernel/Adam 947 952
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot 63150 63158
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/stack 329823 329845
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/floordiv 360233 360250
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_grad/Shape_1 39644 39658
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp 10890 10901
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/dropout/div_grad/Shape 184782 184792
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_1_grad/Reshape 988473 988481
model/get_train_op/model/Transformer/decoder_stack/layer_0/encdec_attention/attention/output_transform/kernel/Adam_1 374 379
model/get_train_op/model/Transformer/decoder_stack/layer_3/encdec_attention/attention/k/kernel/Adam_1 1306 1315
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/mul_grad/BroadcastGradientArgs 360949 360966
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Shape 83578 83587
model/get_train_op/gradients/model/Transformer/encode/dropout/mul_grad/Sum 1020593 1020600
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Shape 263517 263525
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/add_grad/Sum_1 511444 511450
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Reshape 1016922 1016931
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads/strided_slice 360506 360516
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/dropout/div_grad/Shape 412176 412186
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/dropout/div_grad/Sum 492734 492742
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_grad/Shape_1 2925 2934
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_1_grad/BroadcastGradientArgs 71635 71655
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp 12053 12064
model/get_train_op/model/Transformer/decoder_stack/layer_2/self_attention/self_attention/k/kernel/Adam_1 1254 1259
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/floordiv 297929 297945
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Reshape 109746 109758
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_grad/Shape_1 4318 4325
model/get_train_op/model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias/Adam 1193 1197
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape 1011061 1011072
model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias 5134 5139
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp_1 15036 15045
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/concat_2 26664 26690
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape 1012298 1012313
model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_1/ReadVariableOp 8981 8993
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/attention_weights_grad/Sum/reduction_indices 4365 4370
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1 253472 253479
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/sub_1_grad/Reshape_1 502851 502867
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/dropout/div_grad/Shape 377072 377080
model/get_train_op/model/Transformer/decoder_stack/layer_3/self_attention/self_attention/v/kernel/Adam 1604 1609
model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale 4326 4334
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_grad/Shape 71676 71685
model/get_train_op/model/Transformer/decoder_stack/layer_4/encdec_attention/attention/v/kernel/Adam_1 1694 1702
model/get_train_op/gradients/model/Transformer/decode/add_pos_encoding/add_grad/BroadcastGradientArgs 19785 19808
model/get_train_op/model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel/Adam 6792 6798
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/dropout/mul_grad/Shape 315594 315601
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1 14737 14743
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/ReadVariableOp 9745 9756
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs 288517 288537
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_1_grad/Sum 640276 640283
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_grad/BroadcastGradientArgs 165631 165643
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Maximum/y 4872 4876
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/dropout/div_grad/Shape 40761 40773
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1 412569 412576
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Maximum/y 4335 4341
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/stack 129466 129498
model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_scale 6958 6962
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape 487327 487339
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_1_grad/Sum 636233 636241
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/Reshape_1 182444 182454
model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_1/ReadVariableOp 9626 9638
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/add_grad/Reshape 598512 598523
model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale 5327 5332
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/dropout/Shape 224997 225007
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/combine_heads/Reshape_grad/Reshape 511753 511766
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/transpose_1 16252 16258
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_grad/Reshape 489616 489631
model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias 3635 3639
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/add_grad/BroadcastGradientArgs 165363 165375
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads/Reshape/shape 24024 24040
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/dropout/div_grad/Reshape 490820 490829
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/floordiv_1 400578 400590
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/dropout/div_grad/BroadcastGradientArgs 412224 412237
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/ReadVariableOp 9797 9809
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/dropout/div_grad/BroadcastGradientArgs 137669 137683
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1 14137 14148
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/add_grad/Shape 63963 63974
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape 987677 987689
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/Reshape 516916 516927
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/Sum 1009154 1009163
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp 12675 12687
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/ReadVariableOp 10488 10499
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/concat_2 333559 333577
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/floordiv_1 42005 42031
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/ReadVariableOp 9677 9689
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot_grad/Reshape 481956 481974
model/get_train_op/model/Transformer/encoder_stack/layer_4/self_attention/self_attention/output_transform/kernel/Adam_1 6889 6893
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot_grad/Shape 192521 192533
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/add_grad/BroadcastGradientArgs 350418 350433
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/Shape 256389 256398
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_grad/BroadcastGradientArgs 127143 127155
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/add_grad/Sum 487632 487646
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/dropout/div_grad/Sum 995037 995050
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/concat_2 42437 42464
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1 12986 12995
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/mul_grad/Sum 627568 627577
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/add_grad/Sum 992556 992564
model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel 5407 5412
model/Transformer/decoder_stack/layer_2/self_attention/self_attention/output_transform/kernel 5506 5510
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/add_grad/Shape 256221 256232
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/dropout/div_grad/Shape_1 7314 7321
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/dropout/div_grad/BroadcastGradientArgs 330023 330036
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_1_grad/Reshape 1004546 1004555
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/Shape 56615 56635
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/Reshape 474646 474655
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Sum 499966 499979
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape 970658 970672
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/k/Tensordot/Reshape_grad/Shape 138962 138971
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Reshape 54626 54642
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_grad/BroadcastGradientArgs 272769 272787
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/Shape 412631 412640
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Maximum 74160 74181
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/Shape 41269 41288
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Reshape 181263 181273
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot 357283 357292
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/add_grad/Reshape 648841 648848
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp_1 14427 14433
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_grad/Reshape_1 1006720 1006729
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Reshape 236951 236967
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/combine_heads/strided_slice_1 26313 26335
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/add_grad/Shape_1 41164 41182
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Prod_1 71955 71972
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/add_grad/Sum_1 626360 626366
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/stack 294801 294823
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/dropout/div_grad/Sum 507591 507602
model/Transformer/encode/embedding_shared_weights/embedding/ExpandDims 16848 16857
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/add_grad/Reshape 487649 487664
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/add_grad/Shape_1 19702 19715
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Maximum/y 2951 2964
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/add_grad/Shape 237338 237346
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/floordiv 74185 74196
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape 1010914 1010925
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Reshape 492113 492123
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_grad/Shape 181869 181880
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/Shape 288627 288634
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/mul_1_grad/Sum 1020695 1020702
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/add_grad/Shape_1 330139 330149
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_1_grad/Reshape 995507 995518
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1 14926 14936
model/Transformer/encoder_stack/layer_5/self_attention/self_attention/k/kernel 5333 5337
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/re_add_padding/Reshape_grad/Reshape 1010266 1010276
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/combine_heads/Shape 245989 246000
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_1_grad/Reshape_1 1004599 1004607
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Shape 260388 260395
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/add_grad/Reshape 997768 997779
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/Maximum_1 357757 357767
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape 599509 599525
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/v/Tensordot/ReadVariableOp 9266 9275
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1 377504 377511
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_grad/Shape_1 6940 6944
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Shape 342546 342555
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/mul_grad/Sum 499067 499080
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/mul_grad/BroadcastGradientArgs 50587 50611
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/re_add_padding/ScatterNd/shape 127527 127537
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Prod_1 341650 341669
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape 488691 488708
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_1_grad/Reshape_1 495819 495827
model/get_train_op/model/Transformer/decoder_stack/layer_5/self_attention/self_attention/q/kernel/Adam 2189 2194
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/Sum 1014372 1014381
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/transpose_1 15960 15968
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Sum 480728 480741
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp_1 14434 14441
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_grad/Shape 40048 40062
model/get_train_op/model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel/Adam 3133 3140
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape 1017505 1017517
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads/Reshape/shape 290615 290627
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/Reshape 1004051 1004062
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Maximum/y 6946 6951
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/Maximum_1 358040 358052
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1 14209 14220
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_grad/Shape_1 40224 40234
model/get_train_op/model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel/Adam_1 6133 6137
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/sub_grad/Reshape_1 481575 481587
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1 14573 14585
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Maximum 101719 101742
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_1_grad/Shape 99630 99640
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Maximum/y 6952 6957
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads/strided_slice_1 349787 349797
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/add_grad/Shape 377299 377309
model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/Reshape 413557 413564
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/mul_grad/Sum 1020741 1020748
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/dropout/div_grad/Shape_1 7306 7313
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/mul_grad/Shape_1 2746 2752
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Reshape 1004619 1004627
model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_scale 3838 3845
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp 11425 11430
model/get_train_op/model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_bias/Adam_1 1104 1115
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_1/Reshape/shape 118457 118467
model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias 3803 3808
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/stack 40610 40635
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp 11951 11961
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_1_grad/tuple/group_deps 643704 643709
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Maximum 129317 129343
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/dropout/div_grad/Shape 137610 137618
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_1_grad/Shape_1 20363 20380
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/Reshape_1 1004064 1004071
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice/stack 7323 7331
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_grad/Shape_1 72128 72142
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_grad/Reshape 989434 989442
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp 12582 12592
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot 395681 395689
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Reshape_1 508978 508985
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_grad/Reshape_1 1020027 1020036
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/tuple/group_deps 480818 480822
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Prod 377402 377413
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/dropout/div_grad/Sum 598618 598626
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Prod_1 137097 137118
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_grad/Shape_1 4470 4474
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/sub_grad/Shape_1 272448 272458
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape 1005643 1005657
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_2/strided_slice_1 145979 145988
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/dropout/div_grad/Shape 102073 102091
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/sub_grad/Reshape 626081 626093
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1 287877 287885
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Maximum/y 4518 4523
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/stack 290458 290480
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_grad/Shape_1 330678 330687
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_grad/BroadcastGradientArgs 71658 71673
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/add_grad/Shape 98837 98847
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads/strided_slice_1 63294 63304
model/get_train_op/model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias/Adam 5827 5834
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/add_grad/Shape 39477 39492
model/get_train_op/model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias/Adam_1 787 796
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/add_grad/BroadcastGradientArgs 412381 412391
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/add_grad/BroadcastGradientArgs 245487 245502
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp_1 14030 14043
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/k/Tensordot 349714 349722
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/floordiv 173062 173080
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/concat_2 100037 100059
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_grad/Shape_1 272855 272864
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/floordiv 466085 466105
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1 367709 367728
model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_scale 3623 3628
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/ExpandDims_grad/Reshape 1010998 1011011
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/k/Tensordot 23825 23841
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Reshape 999667 999676
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/k/Tensordot/Reshape_grad/Shape 343009 343015
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Shape 386072 386079
model/get_train_op/model/Transformer/decoder_stack/layer_5/self_attention/self_attention/k/kernel/Adam_1 2171 2175
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/Maximum_1 41550 41563
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/Reshape 50213 50230
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/add_grad/Shape 25221 25242
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/dropout/div_grad/Shape 74562 74576
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/Reshape 364734 364744
model/Transformer/decoder_stack/layer_4/encdec_attention/attention/q/kernel 5344 5348
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/Shape_1 4814 4819
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/dropout/div_grad/Shape_1 4151 4156
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_1_grad/Sum 989589 989597
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_grad/Sum 645056 645064
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads/Reshape 173634 173641
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_grad/BroadcastGradientArgs 138516 138548
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape 508384 508392
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/Maximum_1 193537 193550
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/mul_grad/Shape 173766 173778
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/Shape_1 2754 2760
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp_1 13214 13225
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/k/Tensordot_grad/Reshape 499051 499063
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads/strided_slice_1 314830 314840
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1 14751 14757
model/get_train_op/model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel/Adam 1751 1756
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/mul_grad/Sum 504242 504249
model/Transformer/encoder_stack/layer_3/self_attention/self_attention/output_transform/kernel 5615 5622
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/Reshape_grad/Shape 42299 42308
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Maximum 90320 90349
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_1/ReadVariableOp 8791 8802
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_2/Reshape/shape 173621 173630
model/Transformer/decoder_stack/layer_2/encdec_attention/attention/k/kernel 3862 3870
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/add_grad/BroadcastGradientArgs 326172 326187
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/Shape 91644 91654
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot_grad/Shape 126181 126196
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_1_grad/Sum 495470 495484
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/mul_1_grad/Shape_1 2990 2996
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_grad/Reshape 1015210 1015222
model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_1/ReadVariableOp 10308 10317
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/mul_grad/Shape 118619 118630
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/dropout/div_grad/Reshape 468681 468695
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/Reshape 399945 399960
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/ExpandDims_grad/Shape 99845 99854
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Maximum_1 377821 377831
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/mul_grad/BroadcastGradientArgs 326050 326066
model/get_train_op/model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias/Adam_1 6538 6544
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1 74094 74117
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot 50334 50347
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/k/Tensordot/Reshape_grad/Reshape 473436 473445
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/v/Tensordot_grad/Shape 145843 145852
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/dropout/div_grad/Shape_1 4225 4229
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/ReadVariableOp 10255 10264
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/add_grad/BroadcastGradientArgs 41232 41248
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp_1 13255 13267
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs 56583 56610
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp 12390 12400
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Shape_1 5753 5758
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/div_grad/Reshape 1013272 1013283
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Maximum_1 400762 400770
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Maximum/y 6658 6663
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/floordiv 395475 395502
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_grad/Shape_1 238053 238067
model/get_train_op/model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel/Adam 855 861
model/get_train_op/model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias/Adam_1 6764 6768
model/get_train_op/model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias/Adam_1 2070 2076
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Reshape 279581 279592
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1 15002 15012
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/floordiv_1 260744 260758
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_1_grad/Reshape_1 1014980 1014988
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Reshape 990495 990504
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Reshape 1011334 1011345
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/floordiv_1 307832 307843
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/dropout/div_grad/Shape_1 2732 2737
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot_grad/Shape 23754 23779
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/Maximum 395422 395443
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/k/Tensordot 118284 118289
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Shape 127517 127525
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape 509873 509886
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_grad/Reshape_1 990414 990424
model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale 5522 5526
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_1_grad/Reshape 480527 480538
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Maximum_1 154362 154373
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Shape 22405 22427
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/Maximum/y 4086 4090
model/get_train_op/gradients/model/Transformer/encode/add_pos_encoding/add_grad/BroadcastGradientArgs 19503 19538
model/Transformer/decoder_stack/layer_0/self_attention/self_attention/output_transform/kernel 3416 3421
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/combine_heads/Reshape_grad/Shape 147181 147189
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/mul_grad/Sum 482925 482936
model/get_train_op/model/Transformer/encoder_stack/layer_normalization/layer_norm_bias/Adam_1 7403 7410
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1 413006 413013
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads/strided_slice_1 23986 24008
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/dropout/div_grad/Shape 298234 298241
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/mul_grad/BroadcastGradientArgs 361510 361522
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/dropout/div_grad/Shape_1 6746 6753
model/Transformer/decoder_stack/layer_1/self_attention/self_attention/k/kernel 5606 5613
model/get_train_op/gradients/model/loss/pad_to_same_length/Pad_grad/stack 4058 4061
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/transpose_1 16243 16250
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Reshape 489176 489186
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_grad/BroadcastGradientArgs 154290 154305
model/loss/pad_to_same_length/strided_slice 413317 413325
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Reshape 1011978 1011988
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/re_add_padding/mul 155250 155261
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_grad/Sum 614011 614021
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/add_grad/Shape 193374 193384
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot 298145 298154
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot 192536 192544
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/tuple/group_deps 510719 510722
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/v/Tensordot/ReadVariableOp 8829 8839
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_grad/BroadcastGradientArgs 182309 182323
model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_1/ReadVariableOp 8764 8775
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/Maximum 360215 360238
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/Prod 193096 193113
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot 360452 360462
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_grad/Reshape_1 1009609 1009618
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_grad/BroadcastGradientArgs 154627 154655
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/ReadVariableOp 9850 9860
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Shape_1 4308 4316
model/Transformer/encoder_stack/layer_1/self_attention/self_attention/output_transform/kernel 3871 3878
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp 12899 12917
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_2/Shape 90749 90758
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads/Shape 255706 255714
model/get_train_op/model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias/Adam_1 6784 6790
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/floordiv_1 377880 377895
model/get_train_op/model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias/Adam 1218 1224
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot_grad/Shape 252453 252465
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_1_grad/tuple/group_deps 513710 513713
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_grad/Reshape 996066 996074
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot_grad/Shape 23713 23731
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Reshape_1 470000 470014
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/add_grad/BroadcastGradientArgs 412846 412862
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_1_grad/Sum 505755 505764
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/floordiv_1 166158 166175
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Maximum 156862 156886
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Prod_1 98216 98237
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/re_add_padding/Reshape_grad/Reshape 994620 994629
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Reshape 478351 478361
model/get_train_op/gradients/model/Transformer/decode/presoftmax_linear/Reshape_grad/Reshape 467183 467210
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/v/kernel/ResourceApplyAdam/ReadVariableOp 11828 11836
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/combine_heads/Reshape_grad/Reshape 486406 486420
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape 1015670 1015683
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Prod_1 411776 411794
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_1_grad/Reshape_1 1020185 1020194
model/get_train_op/train/ReadVariableOp_1 1021389 1021394
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1 14460 14467
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/Reshape_grad/Reshape 505479 505490
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/mul_grad/Shape_1 4454 4458
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape 1015762 1015773
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads/strided_slice_1 290601 290611
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/dropout/mul_grad/Reshape 970876 970886
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/Fill 2577 2700
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/re_add_padding/mul 40758 40774
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/tuple/group_deps 508987 508989
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1 14125 14135
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/add_grad/Shape_1 71312 71324
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/combine_heads/Shape 256805 256815
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_1/Reshape/shape 349864 349874
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/re_add_padding/Squeeze 165040 165050
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/stack 384571 384599
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1 402942 402960
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Prod 71844 71863
model/get_train_op/model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel/Adam 6769 6773
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/Reshape 325534 325548
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/Reshape 506131 506138
model/get_train_op/model/Transformer/decoder_stack/layer_4/encdec_attention/attention/output_transform/kernel/Adam_1 1653 1661
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads/Shape 244813 244820
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/transpose_1 16452 16462
model/Transformer/decoder_stack/layer_1/self_attention/self_attention/q/kernel 5590 5594
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/v/Tensordot_grad/Shape 279782 279789
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/attention_weights_grad/Sum/reduction_indices 4803 4808
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/add_1_grad/BroadcastGradientArgs 413148 413162
model/get_train_op/model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale/Adam 6825 6832
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_1_grad/Shape_1 71510 71528
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_grad/Reshape 1006687 1006697
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Shape 386063 386070
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/v/Tensordot 90714 90723
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/Shape 72476 72485
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_1/Shape 201513 201521
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_1_grad/Sum 510454 510465
model/get_train_op/model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias/Adam_1 1226 1231
model/get_train_op/model/Transformer/decoder_stack/layer_1/self_attention/self_attention/v/kernel/Adam 989 994
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/mul_grad/Reshape 1019228 1019240
model/get_train_op/model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias/Adam_1 6440 6447
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Shape 20215 20228
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Prod 225630 225647
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Reshape 1015001 1015010
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Maximum 145465 145490
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1 41503 41513
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/add_grad/Sum_1 500973 500978
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Prod 137989 138006
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Shape 342868 342877
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Maximum 244383 244406
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads/strided_slice 23867 23923
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Maximum 384408 384425
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/add_grad/Shape_1 225139 225150
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_2/strided_slice 145966 145975
model/get_train_op/model/Transformer/encoder_stack/layer_3/self_attention/self_attention/k/kernel/Adam 6585 6589
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_1_grad/Shape_1 4550 4555
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/mul_grad/Sum 1008705 1008712
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/sub_grad/Shape 377311 377320
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/div_grad/Sum 1013260 1013270
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/k/Tensordot_grad/Reshape 1019088 1019100
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Reshape 1020463 1020471
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/dropout/div_grad/Reshape 481939 481952
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp_1 14832 14841
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_2/Reshape 202079 202087
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp_1 13078 13086
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1 13021 13032
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/add_grad/BroadcastGradientArgs 146595 146609
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_1_grad/Reshape 1006438 1006448
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Prod_1 125821 125838
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/div_grad/Reshape 504480 504490
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1 20586 20598
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/ExpandDims_grad/Reshape 1016235 1016247
model/Transformer/encoder_stack/layer_4/self_attention/self_attention/v/kernel 5537 5541
model/Transformer/decode/decoder_stack/layer_2/ffn/dropout/Shape 307047 307055
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/floordiv 44946 44964
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Prod 110739 110755
model/get_train_op/model/Transformer/decoder_stack/layer_5/encdec_attention/attention/output_transform/kernel/Adam_1 1971 1978
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Reshape 470440 470454
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/add_grad/BroadcastGradientArgs 260358 260369
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/mul_grad/Shape 174318 174326
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Shape 246064 246070
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/v/Tensordot/Reshape_grad/Shape 83796 83804
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Prod 126562 126574
model/Transformer/decode/shift_targets/strided_slice/stack 3537 3541
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/dropout/mul_grad/Reshape 487138 487149
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_1_grad/Reshape_1 640267 640274
model/Transformer/decode/decoder_self_attention_bias/MatrixBandPart/num_upper 3473 3479
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/mul_grad/BroadcastGradientArgs 245162 245177
model/get_train_op/model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_scale/Adam 1117 1125
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/combine_heads/Shape 64560 64572
model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/Shape_2 466171 466183
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/dropout/div_grad/Shape_1 4850 4854
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_2/strided_slice 24062 24077
model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/Shape_1 413482 413492
model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias 2832 2843
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape 516539 516548
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1 14340 14351
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/div_grad/Shape_1 7240 7246
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/floordiv_1 393148 393166
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Maximum/y 6344 6349
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/ReadVariableOp 9937 9949
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/re_add_padding/Squeeze_grad/Shape 192580 192591
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Prod 260465 260480
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_grad/Reshape_1 489443 489459
model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale 4422 4430
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_1_grad/Sum 1014843 1014849
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp 11761 11772
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/Shape 146716 146724
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp 12000 12011
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/v/kernel/ResourceApplyAdam/ReadVariableOp 11418 11423
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Shape 126771 126781
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/dropout/div_grad/Shape_1 6104 6109
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/strided_slice 40631 40659
model/Transformer/decoder_stack/layer_0/encdec_attention/attention/output_transform/kernel 3405 3409
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape 469412 469427
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_1_grad/Reshape_1 1011683 1011691
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/v/Tensordot_grad/Shape 384817 384824
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/k/Tensordot_grad/Reshape 473268 473283
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/dropout/div_grad/Reshape 994609 994618
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/ReadVariableOp 10784 10798
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Maximum 184477 184504
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/add_grad/Shape 245441 245452
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/attention_weights_grad/Sum/reduction_indices 4230 4236
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_2/Reshape 202132 202137
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/Reshape_1 478102 478110
model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel 3798 3802
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/add_grad/Reshape 1017308 1017318
model/get_train_op/gradients/model/Transformer/decode/add_pos_encoding/add_grad/Shape 18834 18846
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_grad/BroadcastGradientArgs 138699 138715
model/get_train_op/model/Transformer/encoder_stack/layer_4/self_attention/self_attention/k/kernel/Adam_1 6878 6882
model/get_train_op/model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias/Adam_1 1171 1176
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/mul_grad/Shape_1 91795 91806
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/q/kernel/ResourceApplyAdam/ReadVariableOp 10832 10838
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_1_grad/Shape_1 5013 5017
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/v/Tensordot/transpose_1 15628 15634
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads/Shape 384834 384840
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/sub_1_grad/Shape_1 272435 272446
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/add_grad/Reshape 479389 479400
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_grad/BroadcastGradientArgs 237933 237962
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Square_grad/Const 1020281 1020288
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_1/Reshape/shape 173606 173617
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/combine_heads/Reshape_grad/Shape 92138 92146
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/floordiv_1 111037 111056
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_grad/Shape_1 358097 358107
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/stack 118031 118059
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/floordiv 22449 22462
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/ExpandDims 127463 127474
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot_grad/Shape 181339 181350
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/mul_grad/BroadcastGradientArgs 396521 396535
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_1/strided_slice 384887 384895
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/transpose_1 15708 15718
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp 11373 11383
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/k/Tensordot_grad/Shape 244776 244785
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Square_grad/Const 1017010 1017017
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/add_grad/Reshape 999795 999806
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/dropout/div_grad/Shape_1 4883 4886
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/combine_heads/strided_slice_1 386010 386023
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_grad/Sum 999348 999360
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1 377513 377518
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/strided_slice_1 127421 127431
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/ReadVariableOp 10241 10252
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/strided_slice_1 40664 40685
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_grad/Shape_1 323149 323159
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/re_add_padding/Squeeze_grad/Reshape 1010314 1010325
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/BiasAdd/ReadVariableOp 8896 8919
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/mul_grad/Shape 203073 203081
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_1/strided_slice 314842 314851
model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_bias 4643 4650
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/sub_1_grad/Shape_1 260483 260498
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Shape 365739 365746
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_grad/Reshape 1011887 1011897
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Maximum/y 4264 4272
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/concat_2 72797 72820
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1 358173 358180
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/BroadcastGradientArgs 238323 238347
model/get_train_op/model/Transformer/encoder_stack/layer_1/self_attention/self_attention/k/kernel/Adam_1 5929 5936
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/dropout/Shape 74614 74623
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_grad/Reshape 994336 994347
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/add_grad/Shape_1 137798 137809
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_2/strided_slice_1 201722 201731
model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel 5558 5562
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/BroadcastGradientArgs 330833 330845
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/ReadVariableOp 9900 9918
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Sum 469923 469939
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_grad/Shape_1 4626 4630
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/mul_grad/Shape 395800 395810
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Maximum_1 261041 261053
model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias 306 312
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Reshape 1001374 1001383
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_1_grad/Sum 469643 469661
model/get_train_op/model/Transformer/decoder_stack/layer_5/encdec_attention/attention/k/kernel/Adam 1949 1954
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/k/kernel/ResourceApplyAdam/ReadVariableOp 11554 11563
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/v/Tensordot/transpose_grad/InvertPermutation 2401 2444
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_1_grad/Shape 40389 40398
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/dropout/div_grad/BroadcastGradientArgs 260190 260205
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Maximum_1 55931 55950
model/get_train_op/model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale/Adam_1 7171 7176
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_1_grad/Shape 154953 154969
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/re_add_padding/ScatterNd/shape 99927 99938
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_grad/Reshape 509271 509285
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/v/Tensordot_grad/Shape 201388 201396
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp 11163 11169
model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias 3726 3731
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_grad/tuple/group_deps 1001224 1001227
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/sub_grad/Shape 237348 237357
model/get_train_op/model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel/Adam_1 5801 5806
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Prod_1 306667 306684
model/get_train_op/gradients/model/loss/pad_to_same_length/Pad_grad/Reshape 413459 413468
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/sub_grad/Reshape_1 990740 990749
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/Shape_1 4608 4618
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/Reshape 645607 645616
model/get_train_op/model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel/Adam 812 820
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/dropout/div_grad/Shape_1 4947 4951
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1 13627 13637
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot 252467 252476
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/div_grad/Shape_1 5056 5060
model/Transformer/encode/encoder_stack/layer_3/self_attention/dropout/Shape 126259 126269
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/add_grad/Sum_1 492631 492637
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_1/Shape 23831 23844
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_1/Shape 244822 244830
model/get_train_op/model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias/Adam_1 7135 7142
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/dropout/div_grad/Shape_1 6424 6430
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot_grad/Shape 395667 395679
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/dropout/div_grad/Shape 368116 368124
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/Reshape_grad/Reshape 473728 473747
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/k/Tensordot_grad/Reshape 484073 484088
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/Prod 412717 412727
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_grad/Reshape 1016746 1016757
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/Maximum/y 4401 4410
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/div_grad/Shape_1 5974 5982
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/concat_2 74884 74901
model/get_train_op/model/Transformer/encoder_stack/layer_2/self_attention/self_attention/v/kernel/Adam 6322 6326
model/get_train_op/model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias/Adam 6432 6438
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_grad/Shape 225651 225667
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/mul_grad/Reshape 1008802 1008814
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/add_grad/Sum_1 1010167 1010173
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1 14719 14728
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Reshape 598339 598350
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_1_grad/Shape_1 4752 4757
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Prod_1 295371 295382
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/mul_grad/Shape 326282 326290
_SOURCE 0 86
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/div_grad/Reshape 512573 512582
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/add_grad/Reshape_1 470992 471000
model/get_train_op/model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel/Adam 3173 3180
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/Prod_1 41475 41489
model/get_train_op/model/Transformer/decoder_stack/layer_2/self_attention/self_attention/q/kernel/Adam 1274 1278
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp 12289 12299
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/mul_grad/Shape 64168 64177
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/dropout/div_grad/BroadcastGradientArgs 225010 225025
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_1_grad/Shape_1 82854 82871
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/add_grad/Shape 392761 392769
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp 12483 12493
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/Reshape_grad/Reshape 482104 482120
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/concat_2 119889 119927
model/Transformer/decode/presoftmax_linear/Shape 413185 413193
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Reshape 228066 228083
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Shape 246072 246079
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_grad/tuple/group_deps 1014838 1014840
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_1_grad/Shape 330820 330831
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_grad/Reshape 481233 481244
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_grad/Shape_1 110405 110415
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/Sum 993517 993527
model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_1/ReadVariableOp 9968 9981
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/floordiv 367799 367810
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/mul_grad/Sum 488258 488271
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/add_grad/Reshape_1 490218 490228
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Prod_1 164623 164641
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/add_grad/BroadcastGradientArgs 98812 98823
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/k/Tensordot/ReadVariableOp 10475 10485
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/add_grad/Reshape 485994 486011
model/get_train_op/gradients/model/Transformer/decode/add_pos_encoding/add_grad/Reshape 991847 991859
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/sub_1_grad/Reshape_1 614068 614078
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_grad/BroadcastGradientArgs 20534 20557
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/stack 298056 298077
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/combine_heads/Reshape 256869 256877
model/get_train_op/train/epsilon 3962 4001
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_grad/BroadcastGradientArgs 72218 72233
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/tuple/group_deps 989811 989814
model/get_train_op/model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_bias/Adam 2019 2028
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_grad/Reshape 502829 502845
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_grad/Reshape_1 496081 496092
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/dropout/div_grad/Shape 82472 82481
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/div_grad/Shape_1 4358 4364
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_1_grad/Sum 1001229 1001235
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_grad/Reshape_1 999181 999207
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/mul_grad/Reshape 992085 992096
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Prod_1 21448 21471
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Shape 157378 157388
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_2/Reshape 385004 385010
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1 14666 14677
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/dropout/div_grad/Shape_1 4952 4956
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/ReadVariableOp 10018 10024
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/Maximum/y 7278 7285
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp 12402 12411
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/add_grad/Sum 485971 485981
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_1/strided_slice_1 201658 201669
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_1_grad/Sum 995932 995938
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/v/Tensordot/Reshape_grad/Shape 273104 273111
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Reshape_1 510709 510717
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads/Reshape 360535 360541
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Prod_1 237871 237891
model/get_train_op/gradients/model/Transformer/encode/add_pos_encoding/add_grad/Reshape 1020663 1020670
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot 82318 82327
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_grad/Reshape_1 467842 467856
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Prod 56099 56125
model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_1/ReadVariableOp 8534 8547
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/mul_grad/Reshape 483052 483068
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_1_grad/Reshape 1020126 1020136
model/get_train_op/model/Transformer/encoder_stack/layer_4/self_attention/self_attention/q/kernel/Adam 6894 6898
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/v/Tensordot 201324 201329
model/get_train_op/model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel/Adam 1178 1184
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/Prod_1 193058 193069
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Maximum 74114 74141
model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias 6273 6280
model/get_train_op/gradients/model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/Reshape_2_grad/Reshape 466947 466953
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Shape 296038 296044
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp 12105 12116
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/floordiv 74145 74163
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Prod_1 126947 126957
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/mul_grad/Shape 91051 91063
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Square_grad/Const 489762 489772
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/add_grad/BroadcastGradientArgs 342311 342319
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_1_grad/Sum 513642 513653
model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias 3715 3720
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_1/Reshape/shape 201939 201949
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Shape 228484 228491
model/get_train_op/model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_scale/Adam_1 2050 2059
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Shape 307341 307349
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Maximum/y 6405 6410
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Maximum_1 400516 400526
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Reshape 998962 998973
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/mul_grad/Shape_1 5991 5995
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1 13776 13782
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1 41492 41500
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/Reshape 1014415 1014426
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/dropout/div_grad/Reshape 1005081 1005089
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/BiasAdd/ReadVariableOp 9639 9647
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/re_add_padding/Reshape_grad/Reshape 999893 999903
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/transpose_1 15919 15927
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Shape 333445 333453
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot_grad/Reshape 505372 505382
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/combine_heads/strided_slice_1 291644 291654
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/add_grad/Sum 1003018 1003026
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp 11963 11972
model/Transformer/decoder_stack/layer_normalization/layer_norm_scale 5187 5191
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_1/Reshape 146046 146052
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/v/Tensordot_grad/Reshape 515494 515507
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Maximum/y 7044 7052
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/sub_grad/Reshape 492371 492382
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads/Reshape 50429 50441
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot 403294 403304
model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_1/ReadVariableOp 10601 10612
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_grad/Reshape_1 517309 517320
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_grad/Shape 41687 41698
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape 1009044 1009056
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Reshape_1 1019823 1019829
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/ReadVariableOp 9720 9730
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/add_grad/Reshape_1 648831 648838
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_1_grad/tuple/group_deps 988623 988626
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_2/strided_slice_1 279897 279915
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/floordiv_1 154432 154444
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/transpose_1 16337 16343
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_2/strided_slice 279885 279894
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Maximum/y 4838 4842
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape 491037 491057
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Reshape 38847 38863
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot 23733 23742
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_grad/BroadcastGradientArgs 288219 288240
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape 649650 649659
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_1/Reshape/shape 279937 279947
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/floordiv 90386 90399
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/Maximum/y 4567 4572
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice/stack 6986 6994
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/mul_grad/Shape_1 4963 4967
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/k/Tensordot/ReadVariableOp 10326 10333
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs 253547 253570
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/dropout/div_grad/Shape 192690 192697
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/v/Tensordot/ReadVariableOp 10010 10017
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/Shape 396864 396871
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice 72588 72600
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_grad/Shape_1 365567 365577
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/transpose_1 16012 16023
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/mul_grad/Shape 396396 396406
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/div_grad/BroadcastGradientArgs 64148 64164
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/sub_grad/Shape 357565 357572
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/dropout/div_grad/Shape 126209 126216
model/get_train_op/model/Transformer/decoder_stack/layer_3/self_attention/self_attention/v/kernel/Adam_1 1611 1615
model/get_train_op/gradients/model/Transformer/decode/shift_targets/Pad_grad/Reshape 2858 2868
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/mul_grad/BroadcastGradientArgs 173812 173831
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1 14287 14298
model/Transformer/decode/decoder_stack/layer_2/self_attention/dropout/Shape 287443 287453
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Square_grad/Const 478935 478948
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_1_grad/Shape_1 4108 4113
model/get_train_op/model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel/Adam 2104 2109
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/sub_1_grad/Shape_1 342322 342328
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/Shape 393072 393084
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/tuple/group_deps 499761 499766
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape 501794 501812
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/dropout/div_grad/Sum 1010660 1010671
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_1_grad/Shape 127255 127263
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Reshape 333072 333086
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_grad/Shape_1 4867 4871
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_grad/Shape_1 71531 71547
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/sub_grad/Shape 412393 412400
model/get_train_op/gradients/model/Transformer/decode/add_pos_encoding/add_grad/Shape_1 19716 19735
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/dropout/div_grad/BroadcastGradientArgs 126271 126284
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/combine_heads/Reshape/shape 386039 386050
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/add_grad/Shape 330192 330200
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Shape_1 4114 4121
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/combine_heads/Reshape_grad/Reshape 969736 969777
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Maximum/y 4652 4659
model/get_train_op/model/Transformer/encoder_stack/layer_4/self_attention/self_attention/q/kernel/Adam_1 6899 6910
model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_bias 6963 6969
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/strided_slice 182554 182564
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/floordiv 44332 44350
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Maximum/y 6717 6725
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/mul_grad/Shape_1 6924 6928
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/tuple/group_deps 478372 478375
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp_1 14795 14804
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs 323324 323338
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Shape 72449 72461
model/get_train_op/gradients/model/loss/mul_grad/BroadcastGradientArgs 466621 466632
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_grad/Shape_1 2474 2481
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Shape 261333 261341
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/mul_grad/Sum 473286 473299
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_grad/Reshape_1 644092 644103
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Shape 261343 261351
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape 995216 995230
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot_grad/Shape 364809 364818
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Reshape 82219 82235
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_2/strided_slice_1 63277 63289
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Reshape 137349 137364
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Prod 138350 138367
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Sum 1016507 1016515
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/BiasAdd/ReadVariableOp 10656 10668
model/get_train_op/model/Transformer/encoder_stack/layer_4/self_attention/self_attention/output_transform/kernel/Adam 6883 6888
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Reshape 1019810 1019821
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp 11064 11071
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1 13918 13930
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_2/Reshape/shape 202005 202014
model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel 3765 3769
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/Reshape_1 499751 499758
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/dropout/div_grad/BroadcastGradientArgs 307124 307137
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_grad/Reshape_1 999626 999637
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/add_grad/Sum_1 990732 990737
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/v/Tensordot_grad/Reshape 507372 507383
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/dropout/div_grad/BroadcastGradientArgs 40846 40866
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/add_grad/Shape_1 295189 295219
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_grad/BroadcastGradientArgs 342736 342758
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/mul_grad/Sum 988464 988470
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/k/Tensordot_grad/Reshape 1003539 1003552
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/mul_grad/Shape 290680 290689
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/v/Tensordot_grad/Reshape 1018210 1018222
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/combine_heads/Reshape/shape 64624 64637
model/get_train_op/model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel/Adam_1 1185 1191
model/get_train_op/gradients/model/Transformer/decode/shift_targets/Pad_grad/Shape 18432 18440
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_2/strided_slice 173576 173585
model/get_train_op/model/Transformer/encoder_stack/layer_5/self_attention/self_attention/q/kernel/Adam 7230 7234
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_1/Reshape 90926 90934
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Reshape 271945 271956
model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale 3674 3678
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads/Reshape/shape 90857 90871
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_grad/Shape_1 21625 21643
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot 38988 39006
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_1/strided_slice 90801 90811
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_grad/Shape 110538 110554
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_1_grad/Shape 288541 288551
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/v/Tensordot/transpose_1 16476 16484
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Shape 40309 40318
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/dropout/div_grad/BroadcastGradientArgs 350540 350552
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_1/Shape 118325 118332
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/v/Tensordot/Reshape_grad/Shape 193936 193945
model/get_train_op/model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale/Adam_1 1558 1563
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp_1 13675 13686
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_grad/Reshape 500440 500449
model/get_train_op/model/Transformer/decoder_stack/layer_5/self_attention/self_attention/output_transform/kernel/Adam 2176 2182
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/add_grad/Reshape 1003029 1003038
model/get_train_op/model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale/Adam_1 1212 1217
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/div_grad/Shape 291114 291123
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/dropout/div_grad/BroadcastGradientArgs 315580 315591
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1 261125 261132
model/Transformer/encode/dropout/Shape 19737 19757
model/get_train_op/model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias/Adam_1 7102 7108
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/div_grad/Reshape 494054 494069
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Prod_1 377734 377747
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/sub_grad/Reshape_1 514449 514459
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/Shape 326189 326196
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/k/Tensordot/transpose_1 15620 15626
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/add_grad/Shape 396166 396178
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_1_grad/Shape 413015 413022
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Prod_1 83316 83334
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/combine_heads/Reshape 361623 361630
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Maximum/y 4475 4479
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/ReadVariableOp 13070 13076
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/add_grad/Reshape 470975 470989
model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel 5310 5315
model/get_train_op/model/Transformer/encoder_stack/layer_3/self_attention/self_attention/v/kernel/Adam 6636 6640
model/get_train_op/model/Transformer/decoder_stack/layer_5/self_attention/self_attention/v/kernel/Adam_1 2214 2223
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_1_grad/Reshape_1 473932 473942
model/Transformer/encoder_stack/layer_0/self_attention/self_attention/v/kernel 4725 4730
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_1_grad/Shape 42052 42071
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/v/Tensordot_grad/Reshape 476289 476300
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_grad/Sum 1020018 1020025
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/BroadcastGradientArgs 308035 308044
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/v/Tensordot_grad/Shape 349732 349740
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/ReadVariableOp 8585 8592
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot_grad/Reshape 475344 475354
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_grad/BroadcastGradientArgs 39763 39785
model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_bias 3846 3854
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Shape 138717 138726
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/div_grad/Shape_1 6620 6624
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_1_grad/Shape 358255 358268
model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale 5366 5370
model/get_train_op/model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale/Adam_1 5884 5891
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Prod_1 99333 99345
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_1/strided_slice 201585 201600
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/re_add_padding/Reshape/shape 72626 72638
model/get_train_op/model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias/Adam 2116 2121
model/get_train_op/gradients/model/Transformer/encode/add_pos_encoding/add_grad/Shape_1 19400 19427
model/get_train_op/model/Transformer/decoder_stack/layer_1/encdec_attention/attention/q/kernel/Adam 709 715
model/loss/pad_to_same_length/Pad_1/paddings 413388 413396
model/Transformer/decoder_stack/layer_4/self_attention/self_attention/v/kernel 5396 5400
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1 14396 14402
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_1/Reshape/shape 201966 201975
model/get_train_op/model/Transformer/decoder_stack/layer_1/encdec_attention/attention/k/kernel/Adam_1 687 693
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/floordiv_1 330464 330474
model/get_train_op/model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias/Adam 1538 1543
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/sub_grad/Reshape_1 489965 489978
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_1_grad/Reshape 644348 644358
model/get_train_op/model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale/Adam_1 5852 5858
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Maximum/y 4711 4719
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp 12520 12530
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/dropout/div_grad/Shape 307057 307064
model/get_train_op/model/Transformer/decoder_stack/layer_5/encdec_attention/attention/q/kernel/Adam_1 1990 1998
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/v/Tensordot 23867 23886
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_grad/BroadcastGradientArgs 21048 21081
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/add_grad/Sum 1010157 1010165
model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias 4793 4797
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_1_grad/Shape_1 4496 4501
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/v/Tensordot 145854 145861
model/get_train_op/model/Transformer/decoder_stack/layer_2/encdec_attention/attention/v/kernel/Adam 1071 1079
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/mul_grad/Reshape 493856 493870
model/get_train_op/model/Transformer/decoder_stack/layer_1/self_attention/self_attention/output_transform/kernel/Adam_1 968 974
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_grad/Reshape_1 481063 481074
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/tuple/group_deps 1014633 1014635
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_1/Reshape 202156 202163
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/combine_heads/Reshape_grad/Shape 26375 26405
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Square_grad/Const 481377 481386
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape 497079 497099
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_grad/Sum 506076 506085
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/k/Tensordot/Reshape_grad/Shape 83806 83815
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Reshape 23304 23330
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_1_grad/tuple/group_deps 491386 491391
model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_scale 4631 4636
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/dropout/div_grad/Shape_1 6351 6354
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/k/Tensordot/ReadVariableOp 7722 7734
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/sub_1_grad/Reshape_1 489635 489652
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/Shape 307975 307988
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/sub_grad/Shape 295280 295289
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp 12713 12723
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/Shape_1 7183 7189
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/Gather_grad/strided_slice/stack 2997 3003
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Shape 272337 272347
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/mul_grad/Shape 280095 280107
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp 12633 12643
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/mul_grad/Shape 119246 119254
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/add_grad/BroadcastGradientArgs 225184 225198
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp 12532 12542
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/k/Tensordot/Reshape_grad/Shape 56729 56745
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/Shape 252726 252734
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_grad/Sum 644453 644462
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_1_grad/Reshape 513688 513699
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/add_grad/Shape 272317 272324
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_2/Reshape/shape 63340 63352
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Shape_1 5910 5919
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/Maximum/y 4214 4219
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1 14880 14889
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_grad/Reshape 990351 990360
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/sub_grad/Shape_1 287780 287789
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/k/Tensordot_grad/Shape 314753 314760
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_1_grad/Shape_1 4376 4381
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/mul_grad/Shape_1 17265 17309
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/add_grad/BroadcastGradientArgs 110239 110252
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/Maximum 255429 255451
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1 13138 13147
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot_grad/Shape 98540 98554
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/dropout/Shape 228311 228321
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Maximum/y 4524 4528
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Square_grad/Const 474750 474761
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Shape 129927 129939
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/tuple/group_deps 989455 989458
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_1/Reshape/shape 90875 90886
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/v/Tensordot/ReadVariableOp 7984 7992
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/div_grad/Sum 1018434 1018445
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/re_add_padding/Squeeze_grad/Reshape 649635 649648
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/Reshape 1019620 1019630
model/get_train_op/model/Transformer/decoder_stack/layer_2/self_attention/self_attention/v/kernel/Adam_1 1292 1298
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/Maximum_1 393389 393408
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/combine_heads/strided_slice_1 64587 64604
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_1_grad/tuple/group_deps 640581 640585
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot_grad/Reshape 649279 649288
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape 599664 599679
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_grad/Shape_1 110970 110988
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/GatherNd_grad/Shape 99731 99740
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_grad/Shape_1 400773 400780
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Square_grad/Const 999469 999477
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/AssignVariableOp_1 16786 16798
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_grad/Shape_1 307821 307831
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp_1 14627 14638
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Shape 295291 295300
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/v/Tensordot/ReadVariableOp 9122 9133
model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_scale 3732 3736
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/k/Tensordot 314762 314767
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_grad/Reshape 1016900 1016919
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Shape 127506 127514
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Sum 510654 510663
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/ReadVariableOp 10558 10571
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/floordiv 290381 290399
model/Transformer/encode/embedding_shared_weights/embedding_1/mul_1/y 3523 3531
model/Transformer/decoder_stack/layer_3/self_attention/self_attention/k/kernel 5455 5460
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/floordiv 314468 314484
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Prod_1 82974 82993
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp 12118 12128
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/Maximum_1 322835 322846
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1 14765 14771
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_grad/Shape_1 181700 181709
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp 11478 11487
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Sum 502327 502339
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/concat_2 298519 298548
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/Shape 203594 203600
model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias 3889 3896
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Shape 138249 138260
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_1_grad/Reshape 1009701 1009711
model/get_train_op/model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias/Adam_1 843 853
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/Prod 357916 357929
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/combine_heads/strided_slice 147206 147222
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Reshape_1 478363 478370
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Shape 226141 226150
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1 272514 272521
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_1_grad/tuple/group_deps 467608 467611
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/add_grad/BroadcastGradientArgs 119069 119086
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_1_grad/Shape_1 4918 4923
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Shape 21773 21793
model/get_train_op/model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias/Adam 6840 6844
model/get_train_op/model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel/Adam 5817 5821
model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_1/ReadVariableOp 8921 8934
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Prod_1 252126 252146
model/get_train_op/model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale/Adam_1 7149 7154
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/add_grad/BroadcastGradientArgs 192991 193002
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot_grad/Reshape 1001841 1001849
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Prod_1 81963 81984
model/get_train_op/model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias/Adam_1 1835 1843
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Shape 26418 26429
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/dropout/div_grad/Shape_1 4486 4490
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/re_add_padding/mul 72641 72650
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_1/Shape 201531 201539
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Prod 82834 82851
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/mul_grad/Shape 15852 15866
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_grad/Reshape 1020038 1020048
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Shape 272942 272951
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Shape 166206 166222
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/add_grad/Shape_1 110194 110206
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_2/Reshape/shape 146023 146033
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/sub_grad/Shape_1 295325 295333
model/get_train_op/model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias/Adam 553 560
model/get_train_op/model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias/Adam_1 3219 3226
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Reshape 287295 287306
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/add_grad/BroadcastGradientArgs 126436 126446
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_grad/Reshape_1 1006350 1006359
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/dropout/div_grad/BroadcastGradientArgs 294996 295011
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/mul_grad/Sum 1018199 1018208
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1 14772 14778
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/Prod_1 259766 259787
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/sub_grad/Reshape 468299 468309
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp 12507 12518
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_1_grad/Sum 994003 994009
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/add_grad/Shape_1 18180 18194
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot 322355 322364
model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias 4259 4263
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape 499526 499542
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1 13640 13651
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_1/strided_slice_1 279872 279882
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/ReadVariableOp 9108 9119
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Reshape 503208 503220
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Reshape 298080 298090
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/sub_grad/Reshape_1 509515 509524
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Reshape_1 491644 491659
model/get_train_op/model/Transformer/encoder_stack/layer_5/self_attention/self_attention/q/kernel/Adam_1 7235 7239
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/concat_2 330973 331003
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/Maximum 44903 44940
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/add_grad/Reshape 1005000 1005010
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/Shape 253028 253037
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp 12176 12182
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads/Shape 173476 173486
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp_1 14059 14070
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/dropout/div_grad/Sum 1001819 1001826
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/stack 23265 23298
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_1_grad/Reshape_1 1016890 1016898
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1 400478 400483
model/get_train_op/model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale/Adam 5844 5850
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Prod_1 56201 56213
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads/Reshape 24192 24206
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_1_grad/Shape_1 98974 98986
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Shape 330848 330854
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/sub_1_grad/Shape_1 322668 322676
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp_1 14236 14248
model/Transformer/decode/decoder_stack/layer_3/self_attention/dropout/Shape 322379 322385
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1 13820 13833
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Shape_1 4686 4692
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/stack 82182 82214
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_1/Reshape 279971 279980
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1 322776 322781
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/ReadVariableOp 10587 10598
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/div_grad/Shape 326198 326205
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Sum 998917 998927
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_grad/Shape 98850 98859
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/dropout/div_grad/BroadcastGradientArgs 237153 237167
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_1_grad/Shape 154010 154018
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/k/Tensordot/ReadVariableOp 10147 10157
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/re_add_padding/Squeeze_grad/Shape 54823 54842
model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_1/ReadVariableOp 8868 8881
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_2/strided_slice 201873 201882
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_1_grad/Reshape 600181 600193
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_2/strided_slice_1 201884 201893
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/k/Tensordot/transpose_1 16509 16518
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/transpose_1 16130 16136
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/sub_grad/Shape_1 365128 365134
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/Shape_1 6860 6866
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/dropout/div_grad/BroadcastGradientArgs 403416 403431
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Maximum_1 72106 72124
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/Gather_grad/Reshape_1 15180 15190
model/get_train_op/gradients/model/Transformer/encode/add_pos_encoding/add_grad/Sum 1020655 1020661
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/div_grad/Shape_1 6911 6916
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/add_grad/BroadcastGradientArgs 82701 82713
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp 11732 11744
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/add_grad/Reshape_1 496788 496796
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/v/Tensordot/ReadVariableOp 9091 9097
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/mul_1_grad/Shape 18010 18022
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/stack 364707 364731
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Const_2 3685 3692
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_grad/Shape 55792 55809
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Maximum_1 83083 83096
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp 12377 12388
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_grad/tuple/group_deps 989460 989463
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_grad/Sum 1001510 1001517
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot_grad/Shape 228168 228183
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/add_grad/Shape_1 55348 55364
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/transpose_1 16280 16290
model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias 4393 4399
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Reshape 509297 509305
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1 14989 15000
model/get_train_op/model/Transformer/decoder_stack/layer_0/self_attention/self_attention/v/kernel/Adam 663 669
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/Sum 1019577 1019586
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/mul_grad/Shape_1 4742 4746
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Reshape 118064 118082
model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_1/ReadVariableOp 9862 9874
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/floordiv 22125 22137
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Maximum_1 138605 138621
model/Transformer/encoder_stack/layer_0/self_attention/self_attention/k/kernel 4174 4179
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp 12365 12375
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/floordiv 332881 332913
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Shape 127315 127323
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/add_grad/Reshape_1 511463 511472
model/get_train_op/model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias/Adam 490 499
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp 12204 12210
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/add_grad/Shape 146547 146559
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/GatherNd_grad/Shape 40542 40554
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape 1016161 1016173
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/sub_1_grad/Shape_1 237461 237478
model/get_train_op/gradients/model/Transformer/decode/dropout/div_grad/Shape 19812 19826
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Sum 489117 489132
model/get_train_op/model/Transformer/decoder_stack/layer_4/self_attention/self_attention/output_transform/kernel/Adam 1884 1892
model/get_train_op/model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias/Adam_1 1744 1749
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/Reshape 506377 506386
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/add_grad/Shape 307321 307331
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/re_add_padding/Squeeze_grad/Reshape 999963 999977
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/Maximum 200545 200560
model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_1/ReadVariableOp 9160 9171
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/Gather_grad/ExpandDims 7993 8001
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/add_grad/BroadcastGradientArgs 392744 392758
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/re_add_padding/Reshape_grad/Shape 192671 192679
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/add_grad/Sum_1 648812 648817
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/mul_grad/BroadcastGradientArgs 91835 91849
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/add_grad/Shape_1 153953 153962
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_grad/Reshape 1011694 1011703
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/dropout/div_grad/BroadcastGradientArgs 357383 357397
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape 1014047 1014056
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/sub_grad/Shape_1 252838 252852
model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_1/ReadVariableOp 8967 8979
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Shape 64654 64662
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Shape 102293 102303
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape 1016305 1016316
model/get_train_op/model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel/Adam_1 5822 5826
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/dropout/div_grad/Shape_1 4579 4583
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp 11386 11393
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot 98557 98569
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Maximum/y 4274 4282
model/get_train_op/model/Transformer/encoder_stack/layer_3/self_attention/self_attention/output_transform/kernel/Adam 6595 6599
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/sub_grad/Reshape_1 511287 511296
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/div_grad/Reshape 1008073 1008084
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/mul_grad/Reshape 632566 632575
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/re_add_padding/Reshape 192659 192669
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/Shape 256879 256885
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Prod_1 314384 314397
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_grad/Sum 470358 470373
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Maximum/y 6411 6416
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/dropout/div_grad/Sum 469189 469201
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs 21889 21936
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp 12226 12236
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot 368011 368024
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/Maximum/y 4929 4935
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/floordiv_1 225587 225602
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/Shape_1 6571 6577
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_1_grad/tuple/group_deps 469734 469739
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp 11131 11136
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_grad/Reshape 1014990 1014998
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/transpose_1 16360 16370
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Shape 225222 225232
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_2/strided_slice 244901 244922
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_grad/BroadcastGradientArgs 193725 193749
model/get_train_op/gradients/model/loss/pad_to_same_length/Pad_grad/Reshape/shape 4063 4067
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/Sum 478027 478042
model/Transformer/decode/presoftmax_linear/Reshape/shape 5157 5163
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_1_grad/Sum 995465 995472
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Shape 263506 263515
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Prod_1 225426 225444
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/floordiv_1 237723 237737
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/sub_grad/Shape_1 342330 342336
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/Reshape 998754 998764
model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel 3398 3404
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs 377980 377994
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_grad/Reshape 994137 994145
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/k/Tensordot/Reshape_grad/Shape 193965 193971
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_1_grad/Sum 480461 480476
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Shape 20665 20678
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/add_grad/BroadcastGradientArgs 400350 400361
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/mul_grad/Reshape 1003654 1003667
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp_1 14806 14818
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/dropout/div_grad/Reshape 1015494 1015503
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads/strided_slice_1 90783 90796
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs 238219 238245
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1 288414 288426
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp 11987 11998
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/dropout/div_grad/Reshape 1005500 1005510
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_1_grad/Sum 502043 502061
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot_grad/Reshape 506584 506594
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp 12824 12835
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp 12886 12896
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/add_grad/Sum 504613 504621
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/add_grad/Reshape_1 1015418 1015425
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp 11137 11142
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_1/Shape 314795 314802
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/k/Tensordot/transpose_1 15997 16009
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Maximum 332875 332896
model/get_train_op/model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias/Adam 450 458
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1 42036 42048
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/add_grad/Reshape 509665 509673
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1 13202 13212
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Reshape_1 502399 502413
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Prod 39603 39620
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/k/Tensordot/Reshape_grad/Shape 22364 22375
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Sum 517082 517090
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Maximum 145442 145462
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_1_grad/tuple/group_deps 510519 510522
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Shape 260687 260697
model/get_train_op/model/Transformer/decoder_stack/layer_4/self_attention/self_attention/output_transform/kernel/Adam_1 1894 1912
model/get_train_op/model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale/Adam 1233 1239
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/stack 157002 157024
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Reshape_grad/Shape 166446 166454
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/mul_grad/Shape 63550 63564
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/sub_1_grad/Shape_1 287767 287778
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/dropout/div_grad/Sum 649237 649243
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/sub_1_grad/Reshape_1 481246 481259
model/get_train_op/beta2_power 7479 7519
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_1/strided_slice 201798 201807
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/v/Tensordot_grad/Reshape 997386 997396
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/mul_grad/Sum 512349 512356
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Shape 154375 154385
model/get_train_op/model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias/Adam_1 501 514
model/get_train_op/gradients/model/Transformer/encode/dropout/div_grad/BroadcastGradientArgs 19761 19787
model/Transformer/decoder_stack/layer_3/encdec_attention/attention/v/kernel 5718 5723
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_grad/Reshape_1 1015250 1015260
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/Reshape 993564 993575
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_grad/Shape 154308 154320
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_1_grad/Reshape 484715 484731
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/div_grad/Sum 992338 992345
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/re_add_padding/Reshape_grad/Reshape 1005092 1005101
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/BiasAdd/ReadVariableOp 9008 9021
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot_grad/Shape 294890 294903
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp 11746 11758
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/ReadVariableOp 10159 10169
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1 13307 13318
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape 991149 991161
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/Shape 194006 194012
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/mul_grad/Shape 146170 146182
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads/Shape 50350 50361
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp 12849 12859
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/combine_heads/strided_slice_1 147226 147236
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_1_grad/Sum 474131 474141
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1 342418 342424
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Shape 295554 295565
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/mul_1_grad/BroadcastGradientArgs 18410 18429
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/Prod 41387 41401
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Shape 83782 83794
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_1/Reshape/shape 202043 202052
model/get_train_op/gradients/concat_1 16689 16777
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/Shape 287967 287979
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_1_grad/Shape 261222 261231
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/add_grad/Shape_1 19664 19684
model/get_train_op/model/Transformer/encoder_stack/layer_2/self_attention/self_attention/output_transform/kernel/Adam 6256 6263
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/add_grad/Reshape 990752 990760
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_grad/Shape_1 6010 6017
model/Transformer/encode/encoder_stack/layer_2/self_attention/dropout/Shape 98585 98593
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp 12013 12024
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_2/Shape 201540 201548
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/mul_grad/Shape_1 25785 25798
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/sub_grad/Reshape_1 506340 506349
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/floordiv 227857 227868
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads/strided_slice_1 255733 255743
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/ReadVariableOp_6 17157 17173
model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias 4513 4517
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/add_1_grad/Shape_1 4068 4074
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_grad/Sum 990206 990218
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/combine_heads/strided_slice 280984 280997
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Shape_1 6394 6399
model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_1/ReadVariableOp 10516 10527
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/Maximum_1 253015 253025
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_1_grad/Reshape_1 640599 640606
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/v/Tensordot/Reshape_grad/Shape 343001 343007
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape 469535 469550
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_2/Reshape/shape 202030 202040
model/get_train_op/model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale/Adam_1 2134 2139
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_1/Shape 145874 145880
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp 11543 11552
model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_1/ReadVariableOp 9187 9194
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Shape 72236 72246
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1 412578 412583
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/v/Tensordot/transpose_1 16027 16038
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1 14420 14426
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/Gather_grad/Size 277 298
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/dropout/Shape 333253 333262
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/ReadVariableOp 10544 10556
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp 10825 10831
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1 13811 13819
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot_grad/Shape 50314 50332
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_grad/Shape 137870 137879
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp_1 13382 13392
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot 137449 137458
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_grad/Shape 99090 99101
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_1/strided_slice 279860 279869
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_grad/Reshape 496230 496246
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Reshape 995699 995709
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1 272932 272939
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/add_grad/Shape_1 165322 165332
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape 514815 514827
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_2/Shape 244832 244837
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp 12027 12037
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/v/Tensordot/Reshape_grad/Shape 111319 111334
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/sub_grad/Reshape 511246 511258
model/get_train_op/model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel/Adam_1 480 488
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/k/Tensordot/Reshape_grad/Shape 193925 193934
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/transpose_1 16344 16351
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/combine_heads/Reshape_grad/Shape 174743 174751
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1 14493 14499
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp 11852 11861
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1 129257 129276
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp 11238 11246
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_2/Reshape/shape 201924 201936
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/BiasAdd/ReadVariableOp 7667 7679
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/floordiv 44562 44578
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Prod_1 330280 330289
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/ReadVariableOp 9769 9781
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/dropout/Shape 184826 184835
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/ExpandDims 72615 72624
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Shape 99543 99552
ConstantFolding/model/get_train_op/learning_rate/truediv_recip 3504 3512
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Prod 110376 110389
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Maximum_1 225513 225528
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/concat_2 139088 139109
Identity 16628 16634
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Sum 993717 993726
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/combine_heads/Reshape_grad/Shape 26264 26280
model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_1/ReadVariableOp 10199 10210
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/add_grad/Shape 252707 252715
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Shape 377916 377925
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/add_grad/BroadcastGradientArgs 181676 181687
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1 13347 13356
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_1_grad/Shape 358158 358170
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/Reshape_grad/Reshape 484538 484556
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/k/Tensordot_grad/Reshape 988450 988461
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/GatherNd_grad/Shape 182479 182487
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/Gather_grad/concat/axis 2914 2923
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot_grad/Shape 74455 74474
model/get_train_op/model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale/Adam_1 6184 6190
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp 12251 12262
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1 307466 307472
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Reshape 70977 70992
model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias 3820 3828
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Maximum/y 4637 4642
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/tuple/group_deps 488943 488947
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_1_grad/tuple/group_deps 1000818 1000821
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot 279750 279759
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/Reshape_1 998766 998773
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_1_grad/BroadcastGradientArgs 193897 193922
model/get_train_op/model/Transformer/encoder_stack/layer_3/self_attention/self_attention/k/kernel/Adam_1 6590 6594
model/get_train_op/model/Transformer/decoder_stack/layer_0/encdec_attention/attention/k/kernel/Adam 343 349
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/floordiv 184470 184481
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_grad/tuple/group_deps 1016770 1016772
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/stack 173179 173211
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/Shape 138816 138832
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape 510377 510391
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/sub_1_grad/Shape_1 365119 365126
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/add_grad/Sum 507747 507755
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/dropout/div_grad/Sum 1000323 1000334
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/combine_heads/Reshape_grad/Reshape 482216 482237
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/dropout/div_grad/BroadcastGradientArgs 228322 228336
model/get_train_op/model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias/Adam_1 5835 5842
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Maximum 227866 227894
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp 12154 12164
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Reshape 1004244 1004255
model/Transformer/decoder_stack/layer_2/self_attention/self_attention/k/kernel 5532 5536
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/sub_grad/Shape 252717 252724
model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel 5483 5488
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot 164972 164980
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/ReadVariableOp 8641 8653
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/BroadcastGradientArgs 127235 127252
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/add_grad/Reshape 507757 507766
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_2/Reshape/shape 349876 349887
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1 13870 13881
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/sub_1_grad/Shape_1 41405 41414
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot_grad/Reshape 1014158 1014169
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads/Reshape/shape 173588 173602
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/v/Tensordot_grad/Shape 244795 244802
model/get_train_op/model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias/Adam 2091 2096
model/Transformer/decode/decoder_stack/layer_0/ffn/dropout/Shape 237140 237150
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Prod_1 377491 377502
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/combine_heads/Reshape_grad/Shape 246002 246009
model/Transformer/encoder_stack/layer_3/self_attention/self_attention/k/kernel 3433 3438
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/stack 395572 395593
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Maximum_1 377554 377566
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/tuple/group_deps 502416 502420
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/ReadVariableOp 10116 10127
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Prod 154470 154487
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_grad/tuple/group_deps 1011547 1011551
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/BiasAdd/ReadVariableOp 10735 10748
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/add_grad/BroadcastGradientArgs 193512 193533
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot_grad/Reshape 473591 473603
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/transpose_1 15721 15731
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/dropout/div_grad/Sum 506562 506569
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_grad/Shape_1 99463 99473
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/combine_heads/strided_slice 119715 119729
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/dropout/mul_grad/Shape 350555 350562
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_grad/Shape 83035 83045
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_1_grad/BroadcastGradientArgs 358304 358316
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Reshape 994410 994419
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp 12608 12617
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/re_add_padding/Squeeze 192594 192603
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot 392501 392510
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape 1000091 1000104
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/add_grad/Sum 515882 515890
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/Shape_1 5892 5901
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/Maximum/y 4763 4769
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/dropout/div_grad/Sum 971190 971219
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/dropout/div_grad/Sum 1017379 1017385
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Reshape_grad/Shape 22378 22387
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/tuple/group_deps 1004073 1004076
model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel 3559 3565
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/Shape 361091 361098
model/get_train_op/model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias/Adam 5859 5866
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_1_grad/Sum 1016775 1016780
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/add_grad/BroadcastGradientArgs 357583 357592
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Reshape_grad/Shape 378127 378134
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape 476478 476493
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Prod 295660 295671
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/v/kernel/ResourceApplyAdam/ReadVariableOp 11224 11235
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Maximum_1 20635 20654
model/get_train_op/model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias/Adam_1 3163 3171
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads/strided_slice_1 360489 360502
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_1_grad/Sum 600080 600092
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp 12143 12152
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads/Reshape 90902 90924
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/dropout/div_grad/Shape 357314 357320
model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_1/ReadVariableOp 9148 9158
model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale 5050 5055
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_1_grad/BroadcastGradientArgs 226122 226139
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Shape 378099 378107
model/get_train_op/model/Transformer/decoder_stack/layer_normalization/layer_norm_scale/Adam 2244 2253
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_1_grad/Shape 365707 365720
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Shape 400296 400304
model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale 2803 2814
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp 11887 11897
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/v/Tensordot/transpose_1 15207 15216
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/BroadcastGradientArgs 166386 166411
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_1/Reshape 384997 385002
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/mul_grad/BroadcastGradientArgs 395846 395863
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/BroadcastGradientArgs 72309 72335
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/sub_grad/Reshape_1 626183 626195
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/re_add_padding/Squeeze_grad/Shape 137497 137509
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_1_grad/Reshape_1 495546 495557
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/BroadcastGradientArgs 365723 365737
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape 598957 598971
model/get_train_op/model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias/Adam 914 921
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/dropout/div_grad/Sum 1012163 1012171
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_grad/Reshape_1 995914 995925
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/floordiv_1 253456 253469
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Reshape_1 1009409 1009416
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/transpose_1 16227 16233
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/k/Tensordot_grad/Reshape 1008691 1008702
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/combine_heads/Reshape 64641 64651
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/dropout/div_grad/BroadcastGradientArgs 400147 400160
model/get_train_op/model/Transformer/decoder_stack/layer_5/self_attention/self_attention/output_transform/kernel/Adam_1 2183 2188
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/add_grad/Sum 514587 514595
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/mul_grad/Shape 24367 24387
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_2/Shape 118334 118343
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/k/Tensordot/transpose_1 16192 16202
model/get_train_op/model/Transformer/decoder_stack/layer_4/self_attention/self_attention/k/kernel/Adam_1 1874 1883
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp 11327 11337
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/add_grad/Shape_1 19732 19743
model/get_train_op/model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale/Adam_1 6217 6225
model/get_train_op/gradients/model/loss/smoothing_cross_entropy/sub_grad/Reshape 466937 466944
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/Gather_grad/VariableShape 9315 9330
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/dropout/div_grad/Shape_1 4669 4675
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/Maximum_1 287949 287964
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/Reshape_grad/Shape 393720 393727
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Shape_1 6698 6706
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/floordiv 279472 279490
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/stack 54587 54620
model/get_train_op/model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale/Adam 1551 1556
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_grad/BroadcastGradientArgs 165996 166024
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1 252953 252963
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_grad/Reshape_1 989444 989453
model/get_train_op/model/Transformer/encoder_stack/layer_1/self_attention/self_attention/q/kernel/Adam_1 5964 5972
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_grad/Shape_1 41922 41940
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/add_grad/Shape 55497 55513
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/mul/y 5277 5294
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp 11111 11116
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/dropout/div_grad/Shape 272073 272084
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Shape 184976 184984
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_1_grad/Sum 473843 473856
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/add_grad/Sum 512715 512722
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot_grad/Reshape 492756 492771
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1 13333 13344
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/add_grad/Reshape 1008215 1008225
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/dropout/div_grad/Reshape 626564 626574
model/get_train_op/model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale/Adam_1 6856 6859
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Reshape 993759 993770
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_1_grad/Shape 110255 110266
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/dropout/Shape 400061 400068
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/transpose_1 15307 15313
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp 12788 12798
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/BroadcastGradientArgs 296022 296035
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_grad/Reshape_1 1020425 1020436
model/get_train_op/gradients/model/Sum_grad/Reshape/shape 4032 4039
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Shape 20176 20193
model/Transformer/decoder_stack/layer_0/self_attention/self_attention/q/kernel 3427 3432
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/v/Tensordot/ReadVariableOp 10573 10585
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Reshape 511326 511335
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/BroadcastGradientArgs 400898 400922
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/concat_2 22597 22628
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/k/Tensordot 201415 201420
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/dropout/div_grad/BroadcastGradientArgs 252536 252548
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/sub_grad/Reshape 598190 598220
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/attention_weights_grad/Sum/reduction_indices 5660 5665
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Prod_1 260898 260928
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/dropout/div_grad/Sum 498217 498235
model/get_train_op/model/Transformer/encoder_stack/layer_1/self_attention/self_attention/v/kernel/Adam_1 6002 6008
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/Reshape 395597 395607
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/sub_1_grad/Reshape_1 514221 514229
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/add_grad/Shape 412730 412740
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/mul_grad/Shape_1 174430 174438
model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_1/ReadVariableOp 10502 10513
model/Transformer/decoder_stack/layer_1/self_attention/self_attention/output_transform/kernel 5578 5584
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/strided_slice_1 99788 99806
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Square_grad/Const 644705 644712
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Shape_1 4975 4980
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/Gather_grad/Size 263 287
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/v/Tensordot_grad/Reshape 1002629 1002640
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_2/Reshape/shape 314932 314943
model/Transformer/decode/add_pos_encoding/range 19000 19012
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Reshape 376958 376967
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/ExpandDims_grad/Shape 155227 155236
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/add_grad/Shape 25075 25097
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/ReadVariableOp 8951 8964
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/Prod_1 252929 252948
model/get_train_op/model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_scale/Adam 2039 2048
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/stack 164846 164872
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/transpose_1 16040 16047
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot_grad/Shape 290548 290560
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/floordiv_1 193618 193635
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/dropout/div_grad/Reshape 501090 501104
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1 14866 14877
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/ExpandDims_grad/Reshape 1000668 1000681
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_1/strided_slice_1 201604 201615
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1 14413 14418
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/Reshape_grad/Reshape 511669 511681
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/floordiv 62802 62833
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_grad/BroadcastGradientArgs 225784 225813
model/get_train_op/model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale/Adam 2128 2133
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_1_grad/Reshape_1 513900 513916
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/k/Tensordot/ReadVariableOp 9877 9889
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/sub_grad/Shape 400288 400295
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Sum 1009355 1009364
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_1_grad/Reshape 994076 994087
model/get_train_op/model/Transformer/encoder_stack/layer_3/self_attention/self_attention/q/kernel/Adam 6611 6614
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/add_1_grad/Reshape 467281 467292
model/get_train_op/gradients/model/loss/smoothing_cross_entropy/sub_grad/Shape_1 4041 4048
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Sum 1019769 1019777
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/add_grad/Shape 287648 287655
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1 357701 357708
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/mul_grad/Sum 505151 505158
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Reshape 145633 145652
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Shape 365342 365352
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/combine_heads/Reshape_grad/Reshape 514896 514919
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/add_grad/Reshape 500980 500991
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_1_grad/Shape_1 7006 7014
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot_grad/Reshape 1019356 1019368
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/stack 137313 137344
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/combine_heads/Shape 203518 203528
model/get_train_op/model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale/Adam_1 3232 3238
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_1_grad/Shape 393625 393634
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/add_grad/BroadcastGradientArgs 91514 91531
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/floordiv 156891 156920
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/Reshape_grad/Shape 323350 323356
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_grad/Shape_1 342812 342822
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Sum 988894 988902
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_grad/Reshape 1011524 1011534
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/dropout/div_grad/Shape 237096 237106
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/combine_heads/Reshape 174797 174805
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/dropout/Shape 294982 294993
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/k/Tensordot/Reshape_grad/Shape 273113 273120
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Reshape 508967 508976
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/Reshape_grad/Shape 358295 358302
model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel 5699 5707
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/k/Tensordot/transpose_1 16065 16072
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Sum 1014565 1014574
model/Transformer/decoder_stack/layer_5/self_attention/self_attention/v/kernel 5305 5309
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/Maximum 44949 44970
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/add_grad/BroadcastGradientArgs 307351 307360
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp_1 14018 14028
model/Transformer/encode/add_pos_encoding/Shape 18394 18407
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/combine_heads/Shape 385989 385999
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp_1 13514 13519
model/get_train_op/model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel/Adam_1 2110 2115
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/tuple/group_deps 611978 611980
model/Transformer/decoder_stack/layer_3/self_attention/self_attention/output_transform/kernel 5434 5438
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/floordiv 314446 314457
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/v/Tensordot/ReadVariableOp 8630 8639
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Shape 55953 55967
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_1/Reshape 24209 24221
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/combine_heads/Reshape_grad/Reshape 497195 497214
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot 118263 118271
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_1_grad/Reshape_1 995520 995528
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/floordiv 227899 227925
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/dropout/div_grad/Reshape 649245 649255
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Reshape 510695 510706
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_grad/Shape_1 377834 377842
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/BroadcastGradientArgs 261203 261219
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_grad/Reshape_1 993986 993995
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/mul_grad/Sum 992428 992436
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/div_grad/Sum 494038 494050
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/transpose_1 16145 16150
model/get_train_op/model/Transformer/decoder_stack/layer_normalization/layer_norm_bias/Adam_1 2234 2242
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice/stack_1 6996 7004
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_grad/Sum 996043 996052
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/dropout/div_grad/Reshape 999881 999890
model/loss/pad_to_same_length/Pad_1/paddings/1 413365 413372
model/get_train_op/model/Transformer/decoder_stack/layer_0/self_attention/self_attention/output_transform/kernel/Adam 633 640
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_grad/Reshape_1 514084 514095
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp 11511 11520
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_grad/tuple/group_deps 644185 644189
model/get_train_op/model/Transformer/decoder_stack/layer_1/self_attention/self_attention/q/kernel/Adam_1 982 987
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/Sum 998713 998721
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/add_grad/Shape_1 392703 392713
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Maximum 403013 403034
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Prod_1 90298 90339
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Reshape 500803 500817
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Shape_1 2761 2767
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/mul_grad/Sum 993088 993096
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/dropout/div_grad/Shape_1 5724 5729
model/get_train_op/model/Transformer/decoder_stack/layer_2/encdec_attention/attention/q/kernel/Adam 1051 1060
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/stack 126062 126092
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_grad/Shape 330505 330515
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/GatherNd_grad/Squeeze 18017 18049
model/get_train_op/gradients/model/Transformer/decode/presoftmax_linear/Reshape_1_grad/Shape 413271 413278
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_1_grad/tuple/group_deps 485016 485019
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Reshape 1001633 1001642
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp_1 13531 13543
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/mul_1_grad/Shape_1 2870 2878
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp 12197 12202
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Prod 20846 20860
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot 272027 272035
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/stack 325499 325529
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_grad/Sum 1004391 1004401
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1 330744 330750
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot 333158 333171
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/combine_heads/Reshape_grad/Shape 280974 280982
model/get_train_op/model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel/Adam_1 825 831
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/k/Tensordot_grad/Reshape 998262 998274
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Reshape 157028 157038
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/add_grad/Shape 290996 291007
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1 14484 14491
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/Prod 412478 412489
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/floordiv_1 295844 295858
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Prod 154116 154131
model/get_train_op/model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel/Adam_1 6457 6464
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1 13735 13744
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/re_add_padding/ScatterNd/shape 155300 155309
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_1/Reshape/shape 244956 244967
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice/stack 6367 6372
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/concat_2 246186 246204
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp 10848 10859
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/combine_heads/Reshape/shape 26342 26367
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1 13602 13612
model/get_train_op/model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_scale/Adam 429 438
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/Reshape 485449 485459
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot_grad/Shape 224900 224926
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/add_grad/Sum 1012074 1012082
model/Transformer/decoder_stack/layer_normalization/layer_norm_bias 5203 5207
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1 14729 14736
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/add_grad/Sum_1 1012084 1012090
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_grad/Reshape_1 1004459 1004467
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Shape 74763 74774
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/k/Tensordot_grad/Shape 23804 23821
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs 166293 166320
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_1/Shape 90737 90746
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Maximum 22434 22456
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp 11431 11436
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/sub_grad/Reshape_1 479140 479153
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/dropout/div_grad/Reshape 1006959 1006968
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/Prod_1 224557 224577
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/concat_2 378222 378238
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/sub/x 2266 2289
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp 11565 11574
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape 501253 501274
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/mul_1_grad/Reshape 1020705 1020713
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads/Reshape 325687 325693
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/re_add_padding/ScatterNd/shape 40845 40863
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/sub_grad/Shape_1 392890 392898
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/sub_1_grad/Reshape_1 500452 500462
model/get_train_op/learning_rate/mul/x 7524 7531
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_2/Shape 201559 201566
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_2/strided_slice 384933 384942
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/add_grad/Sum_1 648797 648802
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Prod 295411 295421
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/re_add_padding/Squeeze_grad/Reshape 1005140 1005151
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot 153729 153739
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Prod_1 154245 154265
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1 357710 357715
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/k/Tensordot 201251 201260
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/Shape 193315 193326
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Shape 403540 403549
model/get_train_op/model/Transformer/encoder_stack/layer_1/self_attention/self_attention/v/kernel/Adam 5996 6000
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_1/Reshape/shape 384961 384971
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/mul_grad/BroadcastGradientArgs 64506 64520
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_1_grad/Reshape 469705 469715
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/ExpandDims_grad/Shape 72605 72614
model/get_train_op/model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias/Adam 6138 6142
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/add_grad/Shape 315407 315419
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_grad/BroadcastGradientArgs 99529 99541
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/add_grad/Reshape 496773 496785
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/Shape 342966 342978
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/transpose_1 15952 15958
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/combine_heads/strided_slice 26408 26428
model/get_train_op/model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias/Adam 6808 6814
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads/Reshape/shape 63356 63367
model/Transformer/decoder_stack/layer_3/encdec_attention/attention/q/kernel 5428 5433
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads/Reshape/shape 244939 244953
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape 469003 469015
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/dropout/div_grad/Sum 501074 501087
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp 12469 12480
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/v/Tensordot 201398 201404
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_1_grad/Sum 988405 988413
model/get_train_op/model/Transformer/decoder_stack/layer_4/self_attention/self_attention/q/kernel/Adam_1 1925 1933
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp 12302 12313
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Reshape 989816 989826
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_1_grad/Shape_1 4747 4751
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot 145814 145822
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_1_grad/tuple/group_deps 495559 495562
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1 365215 365222
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/add_1_grad/tuple/group_deps 636433 636437
model/get_train_op/model/Transformer/decoder_stack/layer_1/self_attention/self_attention/k/kernel/Adam_1 954 959
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/dropout/Shape 102144 102155
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/dropout/div_grad/BroadcastGradientArgs 129762 129784
model/Transformer/encoder_stack/layer_normalization/layer_norm_scale 6355 6360
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1 287865 287875
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Shape 342993 342999
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot_grad/Shape 341990 341999
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/Prod_1 412556 412566
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1 13760 13768
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/mul_grad/Reshape 1014033 1014045
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/stack 252339 252372
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_1/strided_slice 23948 23959
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs 42157 42180
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_1_grad/Shape 72339 72356
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/dropout/div_grad/BroadcastGradientArgs 385599 385611
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp 11351 11359
model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/concat 413543 413554
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/add_grad/Shape_1 18197 18211
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_grad/Sum 999110 999121
model/get_train_op/model/Transformer/encoder_stack/layer_4/self_attention/self_attention/v/kernel/Adam 6929 6933
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/transpose_1 16074 16081
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/Prod_1 287843 287862
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_grad/BroadcastGradientArgs 111060 111085
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_grad/Sum 500391 500407
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/Maximum 466064 466082
model/get_train_op/model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_bias/Adam 1711 1716
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_grad/Shape 393213 393232
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/k/Tensordot/ReadVariableOp 8804 8814
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1 330337 330342
model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_1/ReadVariableOp 9074 9082
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp 11104 11109
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Reshape 1006139 1006149
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp_1 13394 13405
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_2/strided_slice 349836 349846
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Maximum_1 307526 307537
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/Reshape_1 516930 516937
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/Gather_grad/Reshape_1 15218 15224
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/add_grad/BroadcastGradientArgs 25319 25348
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_grad/Reshape 1009769 1009776
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/k/Tensordot/Reshape_grad/Shape 166435 166443
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/k/Tensordot_grad/Shape 118273 118282
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/BiasAdd/ReadVariableOp 7682 7693
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/combine_heads/Shape 326660 326669
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/add_grad/BroadcastGradientArgs 174180 174194
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Maximum/y 5688 5697
model/get_train_op/gradients/model/loss/mul_grad/Shape_1 466151 466167
model/get_train_op/model/Transformer/encoder_stack/layer_2/self_attention/self_attention/q/kernel/Adam_1 6292 6299
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1 252966 252974
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/dropout/div_grad/Sum 475321 475331
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads/Reshape/shape 349848 349860
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/Reshape 496613 496623
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/sub_1_grad/Reshape_1 644544 644553
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/dropout/div_grad/Shape 364828 364835
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/mul_grad/Reshape 504340 504351
model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale 6564 6570
model/get_train_op/model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel/Adam 2077 2082
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/q/kernel/ResourceApplyAdam/ReadVariableOp 11073 11080
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/mul_grad/BroadcastGradientArgs 203249 203260
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/floordiv_1 357822 357832
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/Reshape_1 488927 488938
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/transpose_1 16176 16182
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/sub_grad/Shape 225213 225219
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/div_grad/Shape 146674 146684
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/add_grad/Reshape_1 514617 514625
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp 11444 11449
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Reshape 74367 74382
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/add_grad/Shape_1 307263 307275
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/v/Tensordot/Reshape_grad/Shape 138951 138960
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/concat_2 365854 365886
model/get_train_op/model/Transformer/decoder_stack/layer_normalization/layer_norm_scale/Adam_1 2254 2263
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1 13484 13491
model/get_train_op/model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias/Adam_1 3123 3131
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/BiasAdd/ReadVariableOp 8937 8949
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_grad/Reshape 1020197 1020205
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/re_add_padding/ScatterNd/shape 182652 182662
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/dropout/div_grad/Shape 110008 110017
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_grad/Reshape_1 1017148 1017158
model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias 5192 5196
model/Transformer/decoder_stack/layer_2/encdec_attention/attention/q/kernel 5501 5505
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/add_grad/Sum 598490 598500
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/mul_grad/Shape 385112 385122
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_grad/BroadcastGradientArgs 40150 40171
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/BroadcastGradientArgs 83750 83777
model/get_train_op/gradients/model/Transformer/encode/dropout/mul_grad/BroadcastGradientArgs 20114 20136
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/combine_heads/Reshape/shape 119744 119757
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Reshape 469983 469996
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_1_grad/Shape_1 6692 6697
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/Reshape 475016 475029
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Maximum_1 126757 126769
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Shape_1 5018 5022
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/k/Tensordot/ReadVariableOp 10801 10811
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/add_grad/Reshape_1 481822 481832
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/Shape 127334 127341
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_grad/Shape_1 6081 6085
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/add_grad/BroadcastGradientArgs 322656 322666
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp 12689 12698
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_grad/Reshape 1006497 1006505
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/concat_2 253812 253839
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/Prod_1 41748 41761
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/floordiv 263055 263068
model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale 4204 4208
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot_grad/Reshape 998501 998513
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/tuple/group_deps 478112 478116
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/mul_1_grad/BroadcastGradientArgs 18347 18370
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/k/Tensordot_grad/Reshape 508252 508263
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot_grad/Reshape 503447 503457
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs 358270 358284
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/Reshape 514232 514240
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/dropout/div_grad/Reshape 471096 471103
model/loss/pad_to_same_length/Pad/paddings/1 413356 413363
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Prod_1 20994 21016
model/Transformer/embedding_shared_weights/embedding_and_softmax/weights 4781 4786
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot_grad/Reshape 1006970 1006979
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/add_grad/Sum 631161 631168
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/transpose_1 15580 15592
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/dropout/div_grad/Sum 996522 996529
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_1_grad/Reshape 1011116 1011126
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/dropout/Shape 129750 129760
model/get_train_op/model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias/Adam_1 923 928
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot_grad/Shape 153713 153726
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads/Reshape 244984 244991
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/stack 314574 314595
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Shape_1 7354 7362
model/get_train_op/model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale/Adam_1 2159 2164
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/mul_grad/Reshape 516524 516537
model/loss/pad_to_same_length/Maximum 413327 413337
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/k/Tensordot/ReadVariableOp 7934 7952
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/add_grad/Reshape 514605 514615
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Square_grad/Const 990487 990494
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_1_grad/Reshape 495525 495542
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_grad/Shape 165884 165896
model/Transformer/decode/decoder_stack/layer_normalization/mul_1/ReadVariableOp 9691 9703
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/Sum 1004008 1004017
model/Transformer/attention_bias/ExpandDims_1 17780 17802
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Reshape 357225 357235
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Reshape 500465 500478
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Shape 237663 237673
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_grad/Sum 1016878 1016888
model/loss/pad_to_same_length/Shape_1 292 306
model/get_train_op/model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias/Adam_1 7070 7076
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/Prod_1 290300 290321
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Prod 165861 165880
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/add_grad/Reshape_1 475228 475238
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Shape 40492 40507
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1 297843 297860
model/Transformer/decoder_stack/layer_5/encdec_attention/attention/v/kernel 4936 4940
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot 412124 412137
model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_scale 1633 1641
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Shape 365622 365631
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_1_grad/Reshape_1 996055 996064
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape 480224 480244
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/add_grad/Sum 490182 490194
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Reshape 502872 502886
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/dropout/div_grad/Shape 129697 129710
model/get_train_op/model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_bias/Adam_1 1392 1400
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/v/Tensordot/ReadVariableOp 8494 8504
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Maximum 227830 227854
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/transpose_1 16464 16473
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp 12276 12286
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/add_grad/Shape 280416 280428
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/dropout/div_grad/Shape_1 4661 4667
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/add_grad/Sum 494237 494251
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/floordiv_1 377622 377634
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_2/Reshape 349919 349927
model/Transformer/decode/presoftmax_linear/strided_slice_1 413259 413268
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Reshape_1 1014623 1014630
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1 14275 14285
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp_1 14613 14624
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_1_grad/BroadcastGradientArgs 413075 413091
model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_1/ReadVariableOp 10615 10626
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_grad/Sum 1004752 1004760
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/concat_2 185104 185122
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp 12862 12872
model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias 4342 4346
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/ExpandDims_grad/Shape 127452 127461
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_grad/Reshape_1 478616 478627
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1 13984 13990
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/ReadVariableOp 10048 10059
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/dropout/div_grad/Reshape 509746 509756
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_1_grad/Shape 42184 42200
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_grad/Reshape 993972 993983
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/add_grad/Sum_1 481792 481805
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/tuple/group_deps 1014438 1014441
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/tuple/group_deps 517146 517149
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot 173429 173436
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_1_grad/Sum 513846 513855
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/transpose_1 15679 15691
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/BiasAdd/ReadVariableOp 10461 10472
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_grad/Sum 1001149 1001157
model/Transformer/decode/decoder_self_attention_bias/Reshape/shape/0 3480 3487
model/Transformer/decode/add_pos_encoding/Shape 18848 18855
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Reshape_1 1004257 1004264
model/Transformer/encode/encoder_stack/layer_5/self_attention/dropout/Shape 181353 181359
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/Maximum 466036 466057
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot 260118 260127
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/k/Tensordot/Reshape_grad/Reshape 513346 513354
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape 507512 507523
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Prod_1 322072 322090
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/combine_heads/strided_slice_1 119731 119742
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_grad/Sum 1006640 1006647
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_grad/Sum 1020340 1020349
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/add_grad/BroadcastGradientArgs 377284 377296
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Maximum/y 2791 2801
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape 1008816 1008826
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Shape 316029 316035
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Reshape 614080 614091
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Prod_1 400457 400466
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_1/Shape 173488 173495
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/Shape 64059 64067
model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale 3709 3714
model/get_train_op/model/Transformer/decoder_stack/layer_3/self_attention/self_attention/k/kernel/Adam_1 1571 1576
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_1_grad/Shape 98826 98835
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/add_grad/BroadcastGradientArgs 396223 396237
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_2/Shape 201505 201512
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/v/Tensordot 173466 173473
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape 1014257 1014268
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_grad/Reshape_1 613920 613931
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Square_grad/Const 500565 500578
model/loss/pad_to_same_length/strided_slice_1 7865 7929
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/add_grad/Reshape_1 1006880 1006888
model/get_train_op/model/Transformer/decoder_stack/layer_4/encdec_attention/attention/q/kernel/Adam_1 1673 1682
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/combine_heads/strided_slice 174770 174781
model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias 3793 3797
model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias 3658 3662
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/v/Tensordot/Reshape_grad/Shape 22431 22448
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_grad/BroadcastGradientArgs 126698 126710
model/get_train_op/gradients/model/loss/mul_grad/Shape 466585 466592
model/Transformer/decoder_stack/layer_0/encdec_attention/attention/v/kernel 3663 3667
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/Prod_1 392965 392982
model/loss/pad_to_same_length/sub 413339 413345
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/Reshape_grad/Shape 253700 253711
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/add_grad/Reshape 1018592 1018603
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot_grad/Shape 237034 237048
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/re_add_padding/Reshape_grad/Shape 82445 82456
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/dropout/div_grad/Shape 165134 165143
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/add_grad/Reshape 492638 492647
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/add_grad/Shape 154020 154028
model/get_train_op/model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias/Adam_1 6169 6175
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/v/Tensordot/ReadVariableOp 8841 8851
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_grad/BroadcastGradientArgs 295758 295777
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/v/Tensordot/Reshape_grad/Shape 194013 194022
model/get_train_op/model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias/Adam 3112 3121
model/get_train_op/model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias/Adam 7155 7159
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/dropout/div_grad/Sum 476584 476603
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp 12459 12467
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Prod_1 307655 307664
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/mul_grad/Reshape 488386 488398
model/get_train_op/model/Transformer/encoder_stack/layer_2/self_attention/self_attention/q/kernel/Adam 6282 6290
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1 13358 13367
model/Transformer/encode/encoder_stack/layer_1/ffn/dropout/Shape 82483 82490
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/combine_heads/Reshape/shape 361608 361620
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp 11533 11542
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_1/ReadVariableOp 7737 7750
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_grad/Shape 71868 71886
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_1/strided_slice 24014 24032
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/mul_grad/Shape_1 4600 4607
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads/Reshape/shape 384944 384957
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/div_grad/Sum 1008060 1008071
model/get_train_op/model/Transformer/decoder_stack/layer_0/encdec_attention/attention/v/kernel/Adam_1 402 407
model/get_train_op/model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias/Adam 870 876
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/dropout/div_grad/Shape_1 6977 6984
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/dropout/div_grad/Shape 400070 400076
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Shape 45568 45578
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1 184391 184408
model/loss/pad_to_same_length/sub_1 413347 413354
model/get_train_op/model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale/Adam 2152 2158
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/v/Tensordot_grad/Shape 63133 63140
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/stack 98447 98470
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/dropout/div_grad/Reshape 1017387 1017397
model/get_train_op/model/Transformer/decoder_stack/layer_3/self_attention/self_attention/q/kernel/Adam 1590 1595
model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias 6605 6609
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/BiasAdd/ReadVariableOp 9480 9495
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads/Shape 325637 325644
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/tuple/group_deps 1011356 1011358
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/add_grad/Reshape 498444 498453
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1 332819 332840
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/v/Tensordot_grad/Reshape 504227 504239
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_1_grad/Reshape 1016845 1016854
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_2/strided_slice_1 201836 201844
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp_1 13105 13112
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/add_grad/BroadcastGradientArgs 256267 256283
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot 314743 314751
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/v/Tensordot/Reshape_grad/Shape 193972 193980
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/dropout/div_grad/Sum 1005071 1005078
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp 10997 11009
model/get_train_op/gradients/model/loss/smoothing_cross_entropy/sub_grad/Sum 466927 466935
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1 14477 14483
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_grad/Reshape 1020390 1020400
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/add_grad/Sum_1 598502 598510
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/mod 2482 2573
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/dropout/div_grad/Sum 471083 471094
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/ReadVariableOp 10074 10085
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_grad/tuple/group_deps 1009620 1009622
model/get_train_op/model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias/Adam 1763 1768
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/Shape 392781 392791
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/dropout/div_grad/BroadcastGradientArgs 392568 392585
model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias 3439 3443
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/floordiv 384388 384403
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/concat_2 92325 92352
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/v/Tensordot 279790 279798
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/mul_grad/Shape_1 291319 291327
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/mul_grad/Shape_1 256527 256535
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_1_grad/Shape_1 4677 4685
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Maximum 173028 173057
model/Transformer/encoder_stack/layer_4/self_attention/self_attention/output_transform/kernel 5450 5454
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot_grad/Reshape 516651 516662
model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias 313 319
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads/Shape 23890 23915
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/v/Tensordot/transpose_1 15694 15705
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_1_grad/Shape 182399 182414
model/Transformer/encode/encoder_stack/layer_1/self_attention/dropout/Shape 71102 71111
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp 12569 12579
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Maximum/y 6337 6342
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Reshape 1006755 1006764
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_1/strided_slice 201848 201856
model/get_train_op/model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias/Adam_1 6199 6206
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads/strided_slice 90762 90778
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/mul_grad/BroadcastGradientArgs 146214 146231
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/floordiv 279489 279500
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_grad/Shape_1 138624 138636
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/dropout/Shape 280577 280584
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_1_grad/Reshape_1 1016373 1016380
model/get_train_op/model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale/Adam 7166 7170
model/get_train_op/model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_bias/Adam 409 415
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/combine_heads/Reshape_grad/Reshape 1012393 1012406
model/get_train_op/model/Transformer/decoder_stack/layer_normalization/layer_norm_bias/Adam 2225 2233
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads/strided_slice 314813 314827
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/add_grad/Reshape 1010175 1010184
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_1/ReadVariableOp 10769 10781
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Maximum/y 4131 4140
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Prod 377659 377671
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp 11157 11162
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Maximum/y 4991 4996
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/dropout/div_grad/Sum 626553 626561
model/get_train_op/model/Transformer/decoder_stack/layer_3/encdec_attention/attention/k/kernel/Adam 1299 1304
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs 393601 393622
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/dropout/div_grad/BroadcastGradientArgs 192765 192780
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_grad/BroadcastGradientArgs 253274 253301
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/mul_grad/BroadcastGradientArgs 25832 25851
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1 14112 14122
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot 290562 290570
model/get_train_op/model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel/Adam_1 7118 7125
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/sub_1_grad/Reshape_1 506122 506129
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Square_grad/Const 511114 511122
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/floordiv_1 56038 56062
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/dropout/mul_grad/Reshape 497935 497948
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/k/Tensordot 90694 90700
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/mul_grad/Sum 1007811 1007821
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_1/ReadVariableOp 8778 8789
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_1/Reshape/shape 63323 63337
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_1/Shape 201549 201555
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp 11402 11407
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp_1 13790 13796
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Reshape 1015289 1015298
model/get_train_op/model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias/Adam_1 1435 1444
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/Shape 21940 21960
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/Reshape 16836 16845
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/re_add_padding/mul 127477 127487
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/add_grad/Shape_1 192886 192897
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/re_add_padding/mul 182626 182633
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/stack 153603 153634
model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel 5175 5181
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/concat_2 22488 22523
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/combine_heads/strided_slice 361596 361605
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Sum 1004201 1004210
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/dropout/div_grad/BroadcastGradientArgs 245611 245623
model/get_train_op/model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_bias/Adam_1 418 427
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/Maximum 200824 200848
model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel 5472 5476
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/v/Tensordot/Reshape_grad/Reshape 493873 493888
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/BiasAdd/ReadVariableOp 9230 9237
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Shape 26518 26531
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1 307887 307892
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1 12998 13007
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp 12620 12631
model/get_train_op/model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias/Adam_1 2122 2127
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Maximum_1 138234 138246
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/dropout/div_grad/BroadcastGradientArgs 377117 377129
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/Shape 322647 322655
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_1_grad/Shape_1 154134 154147
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1 14187 14192
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_grad/Sum 478726 478741
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_grad/Sum 481178 481195
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_1/Reshape/shape 202017 202028
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Shape 298398 298406
model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel 3594 3599
model/get_train_op/model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale/Adam 6850 6854
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_grad/Shape_1 98988 98998
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/k/Tensordot 279773 279780
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Shape 330856 330862
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp 12093 12103
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/dropout/div_grad/Shape 39010 39024
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_1_grad/Shape 181630 181641
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_grad/Shape 295614 295625
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Shape 99151 99161
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/combine_heads/Reshape_grad/Reshape 1017593 1017607
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/mul_grad/BroadcastGradientArgs 291353 291363
model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_bias 3629 3634
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/floordiv_1 127128 127141
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1 295434 295441
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/transpose_1 15281 15293
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot 349694 349703
model/get_train_op/model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale/Adam 603 610
model/get_train_op/model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale/Adam 7143 7148
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_1_grad/Reshape_1 505610 505616
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1 14679 14689
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Shape 110611 110628
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/sub_grad/Shape 365092 365098
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Maximum 117889 117919
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Reshape 1020208 1020216
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_1/strided_slice 173539 173548
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/add_grad/Shape_1 18330 18344
model/get_train_op/model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias/Adam 3207 3217
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/ReadVariableOp_5 8003 8011
model/get_train_op/gradients/model/Transformer/encode/dropout/div_grad/Reshape 1020645 1020653
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/ReadVariableOp_7 1021122 1021131
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1 14549 14558
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/ReadVariableOp_1 12040 12050
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/GatherNd_grad/Shape 72487 72498
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/ReadVariableOp_3 17115 17133
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/ReadVariableOp_2 7768 7779
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Maximum 332853 332877
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1 14193 14199
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Reshape_grad/Shape 83817 83824
model/get_train_op/model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel/Adam 1486 1494
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Shape 401020 401026
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/Maximum/y 4412 4420
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/ReadVariableOp 10026 10032
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/stack 200730 200752
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Prod 400614 400624
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Shape 138933 138947
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_1_grad/Shape_1 138010 138026
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Reshape 500018 500033
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/concat_2 157517 157536
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1 14386 14395
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/dropout/div_grad/Shape 228261 228272
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Maximum_1 110596 110607
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Maximum 184444 184466
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Sum 491567 491581
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/dropout/div_grad/Reshape 996532 996541
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/combine_heads/Reshape_grad/Shape 361570 361577
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Prod 98959 98971
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1 13295 13304
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_grad/Shape 377674 377686
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_grad/Shape_1 182231 182243
model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/concat/axis 5105 5127
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/concat_2 403652 403671
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/concat_2 226280 226299
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Reshape 502379 502395
model/get_train_op/model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias/Adam 7127 7134
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads/strided_slice 325662 325670
model/get_train_op/model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale/Adam_1 936 945
model/Transformer/decoder_stack/layer_2/encdec_attention/attention/output_transform/kernel 5495 5500
model/get_train_op/model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias/Adam 833 840
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/mul_grad/Shape 146741 146749
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/Reshape_1 72463 72473
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/dropout/div_grad/Sum 990892 990900
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/combine_heads/Reshape 396854 396862
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_grad/Reshape_1 645224 645234
model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_1/ReadVariableOp 8883 8894
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_1_grad/Shape_1 4382 4387
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/floordiv 244409 244421
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/dropout/div_grad/Sum 999870 999879
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/combine_heads/Reshape/shape/2 3609 3622
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/Shape 83676 83692
model/get_train_op/model/Transformer/decoder_stack/layer_0/self_attention/self_attention/k/kernel/Adam_1 627 632
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape 998387 998396
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/stack 376933 376954
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1 14779 14786
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_1_grad/Sum 1009624 1009630
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/add_grad/BroadcastGradientArgs 361074 361089
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/Sum 989311 989320
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/strided_slice 127400 127417
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot 54744 54761
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_1_grad/Sum 644203 644210
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/concat_2 174950 174967
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Reshape_1 611967 611975
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/add_grad/Shape_1 365028 365038
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Maximum/y 5764 5770
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/combine_heads/Reshape 386053 386061
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape 1018356 1018368
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_1_grad/Shape_1 4075 4080
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_2/strided_slice_1 244926 244936
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Square_grad/Const 509371 509378
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/k/Tensordot/ReadVariableOp 9056 9062
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/combine_heads/Reshape_grad/Shape 64574 64585
model/get_train_op/model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale/Adam_1 1855 1863
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/dropout/div_grad/Reshape 490319 490334
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_grad/Reshape 1001557 1001567
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape 1005263 1005277
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_grad/BroadcastGradientArgs 400711 400728
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1 13846 13855
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Reshape_grad/Shape 111356 111366
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/mul_grad/Shape 361183 361191
model/get_train_op/model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias/Adam_1 7161 7165
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Maximum_1 40210 40221
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_grad/Shape_1 4192 4196
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/Maximum/y 7297 7305
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_2/Reshape/shape 201978 201989
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/sub_1_grad/Shape_1 330231 330238
model/Transformer/encode/encoder_stack/layer_0/self_attention/dropout/Shape 39102 39122
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp 11974 11985
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Shape 174808 174814
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/combine_heads/Reshape 281026 281033
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_2/Reshape 314965 314971
model/loss/pad_to_same_length/Pad/paddings 413374 413384
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/tuple/group_deps 993587 993590
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_grad/Shape_1 193602 193615
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/div_grad/Reshape 1018448 1018458
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Prod_1 392157 392176
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/transpose_1 15267 15278
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/k/Tensordot/transpose_1 15748 15759
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_1_grad/Shape 323224 323235
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Maximum 62802 62867
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/v/Tensordot/Reshape_grad/Shape 193956 193963
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot_grad/Shape 360465 360477
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads/strided_slice_1 173525 173535
model/get_train_op/model/Transformer/decoder_stack/layer_1/encdec_attention/attention/v/kernel/Adam 723 729
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/div_grad/BroadcastGradientArgs 326267 326280
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp 11613 11623
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/re_add_padding/Reshape 109994 110005
model/get_train_op/model/Transformer/decoder_stack/layer_1/self_attention/self_attention/q/kernel/Adam 975 981
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Maximum_1 295494 295506
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/dropout/div_grad/Reshape 649257 649265
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_grad/Reshape_1 1004833 1004842
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_1_grad/Reshape 473901 473928
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Reshape 62973 62986
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape 996651 996663
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_1_grad/Shape 393514 393525
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_1_grad/BroadcastGradientArgs 42256 42279
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_1/Reshape/shape 201898 201921
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/add_grad/BroadcastGradientArgs 71360 71374
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/Maximum_1 193250 193262
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/Reshape 329848 329858
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/floordiv 349366 349377
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/dropout/div_grad/Shape_1 7390 7394
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Shape 316037 316044
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/add_1_grad/Reshape_1 636222 636230
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/Reshape 514488 514496
model/Transformer/decoder_stack/layer_1/encdec_attention/attention/q/kernel 5573 5577
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_grad/BroadcastGradientArgs 126979 126996
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/stack 322268 322291
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/floordiv_1 358110 358123
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_grad/Reshape 506111 506120
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/sub_grad/Reshape 500708 500718
model/get_train_op/group_deps 1021435 1025464
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/add_grad/Shape 361005 361016
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/ExpandDims_grad/Shape 182586 182595
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_1_grad/tuple/group_deps 495829 495832
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/combine_heads/Reshape_grad/Shape 350936 350943
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1 13589 13600
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/v/Tensordot_grad/Reshape 1013025 1013036
model/get_train_op/model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias/Adam_1 1516 1524
model/get_train_op/model/Transformer/encoder_stack/layer_0/self_attention/self_attention/v/kernel/Adam_1 5676 5679
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape 994892 994912
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_grad/tuple/group_deps 993997 994000
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1 101686 101702
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/v/Tensordot/transpose_1 16314 16323
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/combine_heads/strided_slice 246011 246024
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_grad/Reshape_1 500283 500299
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp 11281 11292
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp 12080 12091
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/dropout/div_grad/Reshape 971235 971246
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/ReadVariableOp 9527 9538
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Maximum/y 5709 5717
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/dropout/div_grad/Shape_1 2725 2730
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_1_grad/Shape_1 6387 6393
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot 109830 109841
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape 468858 468879
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Shape 92219 92226
model/get_train_op/gradients/model/loss/mul_grad/Reshape 466903 466924
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_1_grad/Sum 1011554 1011560
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_1_grad/Shape 400924 400932
model/get_train_op/model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias/Adam 1466 1475
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape 477869 477885
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/sub_grad/Reshape 645143 645153
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/mul_grad/BroadcastGradientArgs 350075 350089
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_1_grad/Reshape 999309 999320
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/Reshape 294826 294836
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/Reshape_grad/Shape 361641 361648
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/add_1_grad/BroadcastGradientArgs 194041 194052
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Sum 995659 995667
model/get_train_op/model/Transformer/decoder_stack/layer_0/encdec_attention/attention/v/kernel/Adam 395 401
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp 11838 11849
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/stack 279556 279578
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_grad/Reshape_1 1010012 1010021
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/concat_2 83946 83971
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1 14314 14324
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/dropout/div_grad/Shape_1 6675 6679
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Prod_1 272499 272510
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Prod_1 38374 38396
model/get_train_op/model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_bias/Adam_1 2029 2037
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/dropout/div_grad/BroadcastGradientArgs 181440 181457
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/transpose_1 16115 16121
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1 14964 14974
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_1_grad/Shape_1 6069 6074
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_grad/Shape 272684 272694
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/Maximum 290321 290348
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp 12700 12710
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/stack 360362 360384
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/dropout/div_grad/Shape 385548 385557
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/add_grad/Shape_1 260317 260327
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Prod_1 349297 349314
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/dropout/div_grad/Reshape 475333 475342
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads/Reshape/shape 24099 24115
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1 14512 14524
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp_1 13653 13661
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads/strided_slice_1 145923 145935
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs 307990 308001
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Shape 155053 155068
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/floordiv_1 323161 323172
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_1_grad/BroadcastGradientArgs 40463 40488
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot_grad/Shape 71057 71072
model/get_train_op/model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale/Adam_1 1816 1824
model/get_train_op/model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias/Adam 1425 1433
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Shape_1 7190 7209
model/get_train_op/model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias/Adam 6191 6197
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_grad/Reshape 478783 478795
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/strided_slice 72573 72585
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot 101990 102001
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/mul_grad/Shape_1 4169 4173
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_grad/Shape 181656 181663
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/combine_heads/Reshape_grad/Reshape 506782 506795
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/add_grad/Shape 202868 202880
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/mul_grad/Shape_1 64285 64296
model/get_train_op/model/Transformer/decoder_stack/layer_0/self_attention/self_attention/k/kernel/Adam 619 625
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/mul_grad/BroadcastGradientArgs 315113 315127
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_grad/Shape_1 4693 4700
model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias 3699 3703
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_grad/Sum 509236 509245
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_grad/Sum 643711 643720
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/k/Tensordot_grad/Reshape 477419 477436
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/Prod_1 200484 200499
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot_grad/Shape 377017 377028
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/transpose_1 16400 16410
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Reshape 244598 244617
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape 488400 488412
model/get_train_op/gradients/model/loss/pad_to_same_length/Pad_grad/Slice_1 467033 467046
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Shape 40824 40842
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Shape 45551 45566
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/add_grad/Shape 385425 385436
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/concat_2 361778 361796
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/mul_grad/BroadcastGradientArgs 280140 280157
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/BroadcastGradientArgs 226040 226057
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot_grad/Reshape 635735 635749
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape 988320 988332
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/v/Tensordot_grad/Shape 118292 118301
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/div_grad/BroadcastGradientArgs 291166 291178
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/div_grad/Shape 203006 203016
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/strided_slice 155153 155172
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/strided_slice_1 72551 72569
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/mul_grad/BroadcastGradientArgs 118665 118684
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads/strided_slice_1 244859 244869
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/v/Tensordot/ReadVariableOp 10335 10341
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/v/Tensordot 201275 201280
model/get_train_op/gradients/model/loss/mul_grad/Sum 466884 466899
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice/stack_1 6686 6691
model/get_train_op/model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale/Adam_1 612 618
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1 14600 14611
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_2/Reshape 24116 24137
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/mul_1_grad/Shape 17861 17885
model/Transformer/encode/encoder_stack/layer_4/ffn/dropout/Shape 165180 165190
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/floordiv 101772 101784
model/get_train_op/gradients/model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/Reshape_grad/Shape 413471 413480
model/Transformer/decode/add_pos_encoding/ExpandDims_1 3552 3558
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/k/Tensordot_grad/Shape 384799 384807
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Reshape 626235 626244
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/v/Tensordot 384826 384832
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads/Reshape 349890 349897
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_grad/Sum 517399 517408
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_1_grad/Reshape_1 505808 505815
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_2/Shape 314804 314810
model/Transformer/encode/encoder_stack/layer_normalization/mul_1/ReadVariableOp 10642 10654
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice/stack 6680 6685
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_1/strided_slice_1 23964 23984
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/dropout/div_grad/Shape_1 6038 6045
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_2/strided_slice 201671 201680
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/add_grad/Shape 41292 41304
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Shape_1 6867 6872
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/BiasAdd/ReadVariableOp 9196 9203
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1 12974 12984
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/Sum 488840 488854
model/get_train_op/model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias/Adam 2061 2069
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/strided_slice_1 155177 155188
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/add_grad/Reshape_1 994540 994547
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Reshape_grad/Shape 343016 343022
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/add_grad/Sum_1 485983 485991
model/get_train_op/model/Transformer/decoder_stack/layer_0/encdec_attention/attention/q/kernel/Adam 381 387
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/dropout/mul_grad/Reshape 515510 515521
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_1/Shape 349751 349758
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_grad/Reshape_1 470245 470259
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/Reshape 488913 488924
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_grad/Shape_1 4826 4830
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/Reshape_grad/Reshape 513553 513564
model/get_train_op/model/Transformer/encoder_stack/layer_4/self_attention/self_attention/v/kernel/Adam_1 6934 6939
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Square_grad/Const 625756 625767
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/floordiv_1 22086 22110
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp 11294 11303
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_1_grad/Sum 1004474 1004480
model/get_train_op/model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel/Adam 6127 6132
model/get_train_op/model/Transformer/decoder_stack/layer_0/encdec_attention/attention/output_transform/kernel/Adam 366 372
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads/strided_slice 63309 63320
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/div_grad/BroadcastGradientArgs 25501 25529
model/get_train_op/model/Transformer/decoder_stack/layer_4/encdec_attention/attention/k/kernel/Adam 1617 1622
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/add_grad/Reshape 626368 626382
model/loss/smoothing_cross_entropy/Neg 5152 5157
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/floordiv_1 365354 365364
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/dropout/div_grad/Shape_1 4443 4447
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/ReadVariableOp 8031 8038
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_1_grad/tuple/group_deps 513918 513920
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/k/Tensordot/Reshape_grad/Shape 378118 378125
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_1_grad/Reshape_1 1005955 1005962
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_grad/BroadcastGradientArgs 365503 365519
model/get_train_op/model/Transformer/encoder_stack/layer_3/self_attention/self_attention/output_transform/kernel/Adam_1 6600 6604
model/Transformer/decode/add_pos_encoding/ExpandDims 19364 19379
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice/stack 6055 6061
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp_1 13370 13380
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape 1000583 1000595
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_grad/Shape 138183 138194
model/get_train_op/model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_scale/Adam 1401 1412
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads/Shape 90726 90735
model/get_train_op/model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias/Adam_1 1476 1484
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/add_grad/Shape_1 18245 18259
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/Gather_grad/concat/axis 3012 3017
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp 12800 12810
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/attention_weights_grad/Sum/reduction_indices 5984 5990
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/dropout/Shape 315569 315578
model/get_train_op/model/Transformer/encoder_stack/layer_1/self_attention/self_attention/output_transform/kernel/Adam 5938 5946
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/mul_grad/Reshape 992471 992482
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/Reshape 645595 645605
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/GatherNd_grad/Squeeze 18149 18173
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/add_grad/Sum 481773 481788
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/dropout/div_grad/Shape 55069 55088
model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias 6727 6734
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/concat_2 45717 45739
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/sub_1_grad/Reshape_1 468037 468045
model/Transformer/decode/add_pos_encoding/strided_slice 18927 18964
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/dropout/div_grad/Shape 322387 322393
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/add_grad/Shape 260371 260379
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp 11339 11349
model/get_train_op/model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel/Adam 1446 1453
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp 11522 11531
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp 12436 12446
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_grad/BroadcastGradientArgs 56241 56270
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Maximum/y 5771 5775
model/get_train_op/model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel/Adam 6148 6152
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/BiasAdd/ReadVariableOp 10102 10113
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/combine_heads/Reshape 26372 26398
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/Gather_grad/concat 16871 16891
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/dropout/div_grad/Sum 1006950 1006957
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Reshape 45011 45033
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/floordiv 184509 184525
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/floordiv_1 182245 182257
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/dropout/div_grad/Reshape 1000337 1000348
model/Transformer/encoder_stack/layer_0/self_attention/self_attention/q/kernel 4003 4013
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_grad/Reshape 1017115 1017124
model/get_train_op/model/Transformer/encoder_stack/layer_5/self_attention/self_attention/k/kernel/Adam_1 7215 7219
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/dropout/div_grad/Shape_1 5776 5780
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/add_grad/Reshape 490207 490216
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/mul_grad/Shape_1 6631 6636
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/dropout/div_grad/Sum 649220 649235
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/add_grad/Sum_1 994521 994527
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot_grad/Shape 322367 322377
model/get_train_op/model/Transformer/encoder_stack/layer_0/self_attention/self_attention/q/kernel/Adam_1 5649 5653
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Reshape_1 1016560 1016566
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/re_add_padding/mul 99882 99891
model/Transformer/encode/add_pos_encoding/strided_slice 18654 18676
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_grad/Sum 474568 474578
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_1_grad/Reshape_1 513701 513708
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/add_grad/Reshape 1015406 1015416
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/v/Tensordot_grad/Shape 201457 201464
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Square_grad/Const 1015077 1015084
model/get_train_op/model/Transformer/encoder_stack/layer_0/self_attention/self_attention/output_transform/kernel/Adam_1 3320 3324
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/add_1_grad/Reshape_1 467295 467303
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads/Reshape/shape 395734 395746
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/add_grad/Shape_1 19717 19730
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/BiasAdd/ReadVariableOp 10671 10684
model/get_train_op/model/Transformer/decoder_stack/layer_2/self_attention/self_attention/v/kernel/Adam 1286 1291
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/dropout/Shape 298225 298232
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/add_grad/Shape_1 18138 18158
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape 508599 508610
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/Maximum_1 412935 412945
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/BroadcastGradientArgs 56699 56725
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Prod_1 22983 23003
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp 11933 11940
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_grad/BroadcastGradientArgs 330614 330629
model/get_train_op/model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias/Adam_1 1795 1804
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/combine_heads/strided_slice 291628 291641
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_1/strided_slice 145938 145949
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape 993412 993422
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/Prod_1 360209 360249
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/add_grad/Sum 990722 990730
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1 13055 13061
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1 227773 227790
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/div_grad/Reshape 997620 997630
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs 138786 138812
model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_1/ReadVariableOp 8656 8667
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape 501935 501952
model/get_train_op/model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias/Adam_1 1198 1204
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/combine_heads/Reshape 147253 147261
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/Shape 25479 25497
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/ReadVariableOp 10087 10099
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/v/Tensordot/Reshape_grad/Shape 194033 194040
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_1/strided_slice_1 201709 201718
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/Reshape_1 989425 989432
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Reshape 164876 164886
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp 12645 12658
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Maximum 367774 367796
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/ReadVariableOp 10294 10305
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape 1005877 1005887
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_1/strided_slice_1 244887 244896
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/mul_grad/Shape 256414 256422
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_grad/Shape 126713 126722
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Reshape 23265 23294
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/div_grad/Shape_1 4731 4735
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/combine_heads/Reshape_grad/Shape 119706 119713
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/sub_1_grad/Reshape_1 492099 492111
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/concat_2 288749 288771
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/floordiv_1 272902 272929
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_2/strided_slice_1 314866 314875
model/get_train_op/model/Transformer/decoder_stack/layer_4/self_attention/self_attention/q/kernel/Adam 1915 1924
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Reshape_1 489189 489200
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/div_grad/Sum 997607 997618
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/dropout/Shape 350531 350539
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot 329917 329927
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot_grad/Shape 145799 145812
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/Where 17258 17699
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/mul_grad/BroadcastGradientArgs 24469 24501
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Square_grad/Const 514305 514313
model/get_train_op/model/Transformer/decoder_stack/layer_1/self_attention/self_attention/v/kernel/Adam_1 996 1003
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/attention_weights_grad/Sum/reduction_indices 4894 4899
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/mul_grad/Sum 1003554 1003562
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot 129610 129620
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/add_grad/Shape_1 4081 4085
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/stack 101836 101863
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Prod 400388 400398
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape 1019242 1019253
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/Prod_1 325268 325282
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/combine_heads/Reshape_grad/Reshape 626815 626830
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/combine_heads/Reshape 291671 291679
model/get_train_op/model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias/Adam 3239 3244
model/get_train_op/gradients/model/Transformer/encode/dropout/div_grad/Shape 19542 19561
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_grad/Shape 154030 154038
model/get_train_op/model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_bias/Adam_1 750 756
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1 13162 13173
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/Reshape_1 155070 155080
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_grad/Reshape 645155 645164
model/get_train_op/gradients/model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits_grad/ExpandDims/dim 4023 4030
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_grad/Reshape 485419 485434
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp 11899 11917
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/sub_grad/Shape 41252 41266
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/re_add_padding/Squeeze 137511 137521
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/stack 367882 367917
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape 1007977 1007988
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads/Shape 360479 360487
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/stack 181237 181260
model/Transformer/decoder_stack/layer_5/self_attention/self_attention/k/kernel 5294 5299
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1 14759 14764
model/Transformer/decode/decoder_stack/layer_3/ffn/dropout/Shape 342032 342041
model/get_train_op/model/Transformer/decoder_stack/layer_4/encdec_attention/attention/q/kernel/Adam 1664 1671
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/mul_grad/Shape_1 326388 326396
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/floordiv 145494 145511
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp_1 14451 14458
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/mul_grad/Shape 25532 25550
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_1/ReadVariableOp 9253 9264
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/add_grad/Sum 1006850 1006858
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/attention_weights_grad/Sum/reduction_indices 7247 7252
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Prod 342405 342415
model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale 6098 6103
model/Transformer/decode/decoder_stack/layer_0/self_attention/dropout/Shape 40829 40843
model/get_train_op/model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel/Adam_1 6493 6500
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot_grad/Shape 279721 279747
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/floordiv_1 272630 272644
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_1/strided_slice 201748 201757
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/v/Tensordot_grad/Reshape 512335 512346
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_grad/Shape_1 4924 4928
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Maximum_1 21600 21620
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape 997529 997540
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Reshape_1 993773 993780
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Reshape 511041 511050
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp 12183 12188
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot_grad/Shape 173415 173427
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/k/Tensordot/Reshape_grad/Shape 111337 111353
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Shape_1 6578 6584
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1 13747 13758
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot_grad/Reshape 1003786 1003798
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape 1003670 1003678
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp 12353 12362
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/Reshape 508756 508766
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1 330328 330335
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_grad/Shape 342597 342607
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Reshape 994147 994155
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/Unique 17321 23394
model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_1/ReadVariableOp 7709 7720
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1 260621 260631
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/BroadcastGradientArgs 343024 343033
model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale 3583 3588
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/ReadVariableOp 10404 10416
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Shape 377569 377579
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/ReadVariableOp 8507 8518
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot_grad/Shape 357295 357304
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp_1 14820 14830
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1 20574 20584
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/Gather_grad/VariableShape 9292 9312
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp 12166 12174
model/get_train_op/gradients/model/Transformer/decode/add_pos_encoding/add_grad/Sum 991328 991337
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Prod 237441 237457
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/k/Tensordot_grad/Shape 145824 145833
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp 12131 12142
model/Transformer/decode/decoder_stack/layer_normalization/add_1/ReadVariableOp 9732 9742
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/GatherNd_grad/Squeeze 18149 18172
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_grad/Shape_1 82875 82892
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/sub_grad/Reshape 479082 479099
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Maximum_1 237647 237661
model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_1/ReadVariableOp 8723 8735
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_1_grad/Shape 288428 288442
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/stack 228033 228062
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Reshape 490025 490037
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Shape 39867 39879
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Maximum 101743 101769
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/add_grad/Shape 110292 110302
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot 364796 364806
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_grad/Reshape_1 990089 990102
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_grad/Reshape_1 510891 510903
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Shape_1 4861 4866
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/combine_heads/Shape 396788 396798
model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/Reshape_1 466217 466225
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/dropout/div_grad/Shape 333263 333272
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/tuple/group_deps 500052 500057
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/add_grad/Reshape_1 1012104 1012112
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Maximum 314435 314463
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_1_grad/Shape_1 4187 4191
model/loss/pad_to_same_length/Shape 413310 413315
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1 13724 13732
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_1_grad/Sum 484655 484668
model/get_train_op/gradients/model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/Reshape_grad/Reshape 467021 467031
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/Shape 174294 174302
model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_1/ReadVariableOp 9891 9898
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_2/Shape 384849 384855
model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/Reshape_2 466508 466518
model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel 5413 5416
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/dropout/div_grad/Shape_1 4284 4291
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/dropout/div_grad/Shape_1 4491 4495
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/re_add_padding/Reshape/shape 182610 182623
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_1_grad/Reshape_1 989790 989799
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/v/kernel/ResourceApplyAdam/ReadVariableOp 11589 11597
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1 322767 322774
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_1_grad/Sum 467522 467531
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/transpose_1 15945 15951
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/add_grad/Shape_1 18213 18226
model/get_train_op/model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias/Adam 1506 1514
model/get_train_op/model/Transformer/encoder_stack/layer_0/self_attention/self_attention/v/kernel/Adam 5671 5675
model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_1/ReadVariableOp 8738 8747
model/get_train_op/model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel/Adam_1 542 551
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/Shape 155082 155090
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs 165610 165628
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp 11315 11324
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_grad/Reshape 995894 995912
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_grad/Sum 1009925 1009933
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1 13545 13557
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_grad/Reshape 1009976 1009986
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1 13282 13293
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp 10941 10953
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/q/kernel/ResourceApplyAdam/ReadVariableOp 11213 11222
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Maximum_1 260671 260684
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp 10861 10873
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/dropout/div_grad/Shape 181361 181368
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Reshape_1 1011347 1011354
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads/strided_slice 279828 279842
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/Reshape 989412 989423
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/mul_grad/Reshape 513331 513343
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Maximum 117854 117875
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/combine_heads/Shape 174732 174741
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/add_grad/Shape 295268 295278
model/Transformer/decoder_stack/layer_0/encdec_attention/attention/k/kernel 3641 3646
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/sub_1_grad/Shape_1 412491 412498
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/Reshape_grad/Shape 291690 291697
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/floordiv_1 99225 99242
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_1/Reshape 244993 245000
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Reshape_1 480808 480816
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads/Reshape/shape 50412 50425
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_grad/Sum 1011839 1011846
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp 11189 11211
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/sub_grad/Shape 342292 342299
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/combine_heads/Shape 147169 147179
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Prod_1 99045 99057
model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias 5585 5589
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Shape 166414 166422
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Shape 40804 40821
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Maximum/y 7383 7389
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/k/Tensordot/Reshape_grad/Shape 193981 193987
model/get_train_op/model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_scale/Adam 1724 1730
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/k/Tensordot_grad/Shape 201262 201273
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_grad/Reshape 470409 470420
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/v/Tensordot/Reshape_grad/Reshape 627685 627696
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1 14172 14177
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/Gather_grad/strided_slice 15788 15818
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/dropout/div_grad/Shape 294932 294940
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/add_grad/Reshape 494256 494267
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot_grad/Shape 164957 164969
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/Sum 508713 508723
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Shape 238351 238363
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/Reshape 496263 496271
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp 12661 12673
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_grad/Sum 1011474 1011482
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/floordiv 325353 325372
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/dropout/div_grad/Sum 486109 486121
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Shape 377322 377332
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/concat_2 64818 64849
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/add_grad/Sum 467967 467977
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Shape 154040 154047
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp 11942 11948
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/div_grad/Shape_1 4157 4162
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/Shape 40527 40539
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp 11095 11102
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/dropout/div_grad/BroadcastGradientArgs 322458 322472
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/ReadVariableOp 8039 8046
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1 13712 13722
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot 71074 71086
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Reshape 314598 314610
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_2/Shape 349760 349766
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/add_grad/BroadcastGradientArgs 280462 280477
model/get_train_op/gradients/model/Transformer/encode/dropout/div_grad/Sum 1020637 1020643
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/stack 62945 62969
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/v/Tensordot/transpose_1 15566 15577
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/add_grad/Shape 165411 165420
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_grad/Reshape 517433 517443
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/mul_grad/Shape 245116 245128
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/dropout/div_grad/Reshape 514686 514695
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/combine_heads/strided_slice 326696 326705
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/div_grad/BroadcastGradientArgs 203059 203071
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/dropout/div_grad/Shape 252478 252484
model/get_train_op/model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel/Adam_1 6774 6778
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape 971107 971118
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/dropout/div_grad/Reshape 510132 510141
model/get_train_op/train/ReadVariableOp_3 1021396 1021400
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads/strided_slice_1 23928 23944
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/v/Tensordot_grad/Shape 23846 23864
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_grad/Sum 485365 485375
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp 12725 12733
model/get_train_op/gradients/model/Transformer/encode/add_pos_encoding/add_grad/Shape 18374 18391
model/get_train_op/train/ReadVariableOp_2 1021296 1021303
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/combine_heads/strided_slice_1 26434 26448
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/floordiv 395446 395464
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/mul_grad/Reshape 477574 477585
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_grad/Shape 138370 138388
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_grad/Shape 126877 126886
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/sub_1_grad/Reshape_1 474636 474644
model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias 5632 5637
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Shape 157390 157398
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape 1005356 1005368
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Reshape_1 517138 517144
model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/concat_1 466202 466215
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1 13946 13957
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Prod_1 138118 138135
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp 12750 12760
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/v/Tensordot/Reshape_grad/Reshape 504353 504362
model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_1/ReadVariableOp 10688 10702
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp 11676 11687
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Prod_1 330517 330525
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/add_grad/BroadcastGradientArgs 202928 202945
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_1_grad/Sum 1011074 1011082
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/strided_slice 99809 99822
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/ReadVariableOp 8852 8865
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/combine_heads/Reshape/shape 174783 174795
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/transpose_1 16090 16097
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp_1 14262 14273
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/v/Tensordot/ReadVariableOp 10342 10348
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_2/strided_slice_1 201632 201642
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1 43849 43873
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_1_grad/BroadcastGradientArgs 330863 330873
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_grad/Sum 994113 994123
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/add_grad/Shape_1 400267 400276
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_grad/Reshape_1 644191 644201
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_1_grad/Shape 39456 39473
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1 13959 13971
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_1_grad/Reshape_1 485007 485014
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Square_grad/Const 468152 468161
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/sub_1_grad/Reshape_1 485437 485447
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_1/strided_slice_1 201860 201869
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_1_grad/Shape_1 7343 7352
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1 14560 14571
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_1/Shape 201474 201483
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot_grad/Reshape 477737 477748
model/Transformer/encode/encoder_stack/layer_2/ffn/dropout/Shape 110020 110028
model/Transformer/decoder_stack/layer_1/encdec_attention/attention/output_transform/kernel 5562 5567
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/add_grad/Sum_1 999787 999793
model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_1/ReadVariableOp 9083 9090
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Maximum 44530 44557
model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias 5164 5168
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/Shape 111215 111230
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/div_grad/Shape 119154 119164
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/floordiv_1 20775 20800
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/v/Tensordot_grad/Reshape 497920 497932
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/Reshape_grad/Shape 203602 203609
model/get_train_op/model/Transformer/decoder_stack/layer_4/self_attention/self_attention/v/kernel/Adam_1 1943 1948
model/Transformer/decoder_stack/layer_4/self_attention/self_attention/output_transform/kernel 5349 5354
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp 11638 11651
model/Transformer/decoder_stack/layer_1/encdec_attention/attention/k/kernel 3748 3752
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/div_grad/Shape 25372 25392
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/add_grad/BroadcastGradientArgs 237323 237335
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/sub_grad/Shape 20200 20212
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/dropout/div_grad/Reshape 599209 599223
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/mul_grad/Sum 516415 516423
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/combine_heads/Reshape/shape 326708 326720
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/div_grad/Sum 472429 472444
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1 14500 14510
model/get_train_op/model/Transformer/decoder_stack/layer_3/self_attention/self_attention/output_transform/kernel/Adam_1 1584 1589
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot_grad/Reshape 488556 488568
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/add_grad/Sum 648804 648810
model/get_train_op/model/Transformer/decoder_stack/layer_0/encdec_attention/attention/q/kernel/Adam_1 388 394
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/v/Tensordot_grad/Shape 90703 90712
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape 477587 477599
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/mul_grad/BroadcastGradientArgs 63888 63917
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1 13320 13331
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/concat_2 393833 393866
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads/Reshape/shape 314889 314901
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Reshape_grad/Shape 138974 138982
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_1_grad/Reshape_1 502121 502135
model/Transformer/encoder_stack/layer_0/self_attention/self_attention/output_transform/kernel 7177 7182
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/BroadcastGradientArgs 154924 154949
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1 13269 13280
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/k/Tensordot_grad/Shape 90682 90692
model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_1/ReadVariableOp 8605 8616
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/add_grad/Reshape_1 1017320 1017329
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Reshape 90511 90525
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_1/ReadVariableOp 9239 9251
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_grad/Shape_1 126590 126599
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/stack 411992 412019
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/Maximum 395446 395471
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/mul_grad/BroadcastGradientArgs 91097 91115
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_1_grad/Shape 193702 193720
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_grad/Sum 502775 502785
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/stack 357201 357222
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_2/Reshape 90936 90943
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads/Shape 349741 349749
model/get_train_op/model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale/Adam 569 575
model/get_train_op/model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias/Adam 3151 3161
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/concat_2 102414 102434
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/sub_grad/Shape_1 357603 357609
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_grad/Shape_1 261056 261066
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_grad/Shape 20561 20575
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/q/kernel/ResourceApplyAdam/ReadVariableOp 11818 11826
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/BroadcastGradientArgs 378083 378097
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape 506700 506712
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/dropout/div_grad/Shape_1 5044 5049
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice 40690 40715
model/get_train_op/model/Transformer/encoder_stack/layer_2/self_attention/self_attention/v/kernel/Adam_1 6327 6331
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Shape 184986 184993
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_1/strided_slice_1 63246 63258
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot_grad/Reshape 1008942 1008953
model/Transformer/encoder_stack/layer_2/self_attention/self_attention/v/kernel 3759 3764
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/add_grad/Sum 511433 511442
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot_grad/Shape 403275 403291
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/add_grad/Sum_1 503331 503338
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_1_grad/BroadcastGradientArgs 126680 126696
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/add_grad/Sum 644441 644451
model/get_train_op/gradients/model/Sum_grad/Reshape 466720 466729
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Prod_1 40112 40125
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/add_grad/Reshape 1013418 1013427
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot_grad/Shape 40727 40740
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/tuple/group_deps 998985 998987
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/v/Tensordot/Reshape_grad/Shape 378108 378116
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_1_grad/Shape_1 2464 2472
model/get_train_op/model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale/Adam 3252 3260
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_1_grad/Shape 137858 137868
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Prod_1 20554 20571
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_grad/Shape_1 4562 4566
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/combine_heads/strided_slice_1 315977 315990
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Square_grad/Const 1004693 1004700
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/Shape 99720 99728
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/mul_grad/Shape_1 4809 4813
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/dropout/div_grad/Shape_1 4293 4299
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot 384791 384797
model/get_train_op/model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias/Adam 1134 1139
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/dropout/div_grad/Reshape 492744 492753
model/Transformer/decode/decoder_self_attention_bias/MatrixBandPart/num_lower 3463 3471
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/Shape 396308 396315
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp 11117 11123
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/mul_grad/BroadcastGradientArgs 174466 174476
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/Shape 22275 22305
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp_1 14045 14057
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Prod_1 62708 62723
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/dropout/div_grad/Shape 329949 329956
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/transpose_1 16486 16495
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot_grad/Shape 201368 201377
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/Prod 288087 288107
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_1_grad/tuple/group_deps 1005964 1005967
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Shape 307583 307594
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/re_add_padding/Squeeze_grad/Shape 82365 82377
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_1_grad/BroadcastGradientArgs 99060 99073
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_1/Reshape 202070 202077
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot_grad/Shape 298157 298166
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/dropout/div_grad/Sum 515721 515732
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Square_grad/Const 996150 996157
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_grad/Sum 990293 990299
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_grad/Shape 322957 322967
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp 12837 12847
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/concat_2 182772 182797
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/dropout/div_grad/Reshape 496894 496902
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/v/Tensordot/Reshape_grad/Shape 166424 166433
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/floordiv_1 342557 342566
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/sub_grad/Shape_1 41417 41428
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot_grad/Reshape 626577 626587
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/dropout/div_grad/Sum 479493 479502
model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_1/ReadVariableOp 9204 9211
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/floordiv_1 40273 40288
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/BiasAdd/ReadVariableOp 8683 8693
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/sub_grad/Reshape_1 645236 645245
model/get_train_op/model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel/Adam 1775 1780
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/mul_grad/BroadcastGradientArgs 256561 256571
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/ReadVariableOp 10350 10357
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_grad/Shape_1 5023 5027
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_2/Reshape 146054 146061
model/get_train_op/model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel/Adam_1 7085 7092
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_1_grad/Reshape_1 510510 510517
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_1_grad/Reshape_1 1011128 1011135
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/dropout/div_grad/Reshape 487443 487454
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/sub_1_grad/Shape_1 295316 295323
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_grad/Shape 20864 20878
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/floordiv 367761 367774
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_grad/Shape 192970 192978
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/Reshape_grad/Reshape 636123 636134
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/k/Tensordot_grad/Reshape 516401 516413
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_1_grad/Sum 1005890 1005897
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/Prod_1 395361 395377
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp 12495 12505
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/dropout/Shape 364820 364826
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Maximum_1 272840 272852
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot_grad/Shape 384778 384789
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/attention_weights_grad/Sum/reduction_indices 2738 2745
model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias 4431 4435
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Shape_1 4248 4253
model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_1/ReadVariableOp 8750 8762
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Maximum/y 6652 6657
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/Shape 357811 357820
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Reshape 517125 517136
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/add_grad/Sum 470942 470956
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/sub_grad/Reshape 506297 506306
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads/strided_slice_1 50394 50408
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/ReadVariableOp 8021 8029
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_grad/Shape 71399 71407
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/re_add_padding/Reshape_grad/Shape 109980 109992
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Prod_1 154582 154599
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/Shape 203049 203057
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/combine_heads/Reshape 350987 350995
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/dropout/div_grad/Shape 71089 71099
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/add_grad/Shape_1 287588 287598
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/v/Tensordot/transpose_1 16122 16129
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Shape 22323 22347
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp 11457 11465
model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_1/ReadVariableOp 8520 8532
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_grad/Sum 995841 995849
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp 11625 11635
model/Transformer/encoder_stack/layer_2/self_attention/self_attention/q/kernel 3704 3708
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/combine_heads/strided_slice_1 203556 203567
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_grad/Reshape_1 1011932 1011943
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/dropout/div_grad/Shape 224942 224950
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_grad/Sum 1006281 1006289
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Shape 330453 330462
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/add_grad/Sum 999776 999785
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_1_grad/BroadcastGradientArgs 39739 39759
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1 21757 21769
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1 14526 14536
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/Sum 499677 499693
model/Transformer/decode/presoftmax_linear/Reshape 413174 413182
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/attention_weights_grad/Sum/reduction_indices 4448 4453
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/transpose_1 15328 15339
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads/Reshape 255763 255770
model/Transformer/decoder_stack/layer_5/encdec_attention/attention/q/kernel 5197 5202
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/Prod_1 364484 364502
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/floordiv_1 126826 126838
model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale 3810 3818
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/add_grad/Sum 476801 476812
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Reshape 989767 989778
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Maximum_1 165713 165727
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/k/Tensordot/Reshape_grad/Reshape 495051 495059
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_grad/Sum 1016696 1016704
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_1_grad/tuple/group_deps 484743 484745
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_grad/BroadcastGradientArgs 110865 110893
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/combine_heads/strided_slice_1 361579 361593
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/add_grad/Shape_1 237281 237291
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/add_grad/Sum_1 490197 490204
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/k/Tensordot/transpose_1 15775 15785
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/combine_heads/Reshape_grad/Shape 256817 256825
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads/strided_slice 290582 290597
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1 13973 13983
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Maximum/y 4986 4990
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/re_add_padding/Reshape 82458 82469
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape 499241 499254
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/dropout/div_grad/Sum 487428 487441
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/dropout/div_grad/Reshape 507604 507614
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/sub_grad/Reshape_1 468342 468356
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/mul_grad/Shape 350032 350043
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp 12812 12822
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot 244766 244774
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/Reshape_grad/Reshape 471296 471317
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_grad/Reshape 644532 644541
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/add_grad/BroadcastGradientArgs 39430 39452
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Maximum_1 154732 154748
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1 14300 14311
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/concat_2 316143 316164
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/mul_grad/BroadcastGradientArgs 24495 24514
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Prod_1 295627 295637
model/get_train_op/model/Transformer/decoder_stack/layer_4/encdec_attention/attention/v/kernel/Adam 1684 1692
model/get_train_op/model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias/Adam_1 5792 5795
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/add_grad/Sum 483446 483456
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/Shape 119216 119228
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/k/Tensordot_grad/Reshape 513206 513219
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/re_add_padding/Reshape/shape 155264 155278
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads/Reshape 395749 395756
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/re_add_padding/Squeeze_grad/Reshape 994677 994689
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_grad/Shape 165647 165663
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/Maximum/y 4941 4946
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/sub_grad/Reshape 489914 489932
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/mul_grad/Shape_1 4237 4241
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Reshape 153639 153653
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Prod_1 153383 153403
model/get_train_op/model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale/Adam 1525 1530
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp_1 14641 14651
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/transpose_1 15595 15607
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/stack 349473 349501
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1 14539 14547
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads/Shape 290572 290580
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/concat_2 194161 194194
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/v/Tensordot/Reshape_grad/Reshape 472281 472292
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/floordiv_1 261106 261122
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/Reshape_grad/Shape 256887 256894
model/loss/pad_to_same_length/Pad 413413 413423
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_grad/Reshape_1 996294 996303
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_1_grad/tuple/group_deps 637073 637077
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_grad/Reshape 999167 999179
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_1_grad/tuple/group_deps 480552 480554
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/mul_grad/Reshape 1007835 1007845
model/Transformer/encoder_stack/layer_1/self_attention/self_attention/v/kernel 2937 2949
global_step 7532 7537
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/add_grad/Sum 468551 468561
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/mul_grad/Sum 632541 632550
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/tuple/group_deps 1004266 1004268
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_grad/Sum 1011670 1011680
model/Transformer/decoder_stack/layer_0/encdec_attention/attention/q/kernel 3410 3415
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_1_grad/Shape_1 55730 55751
model/Transformer/decoder_stack/layer_2/self_attention/self_attention/q/kernel 5517 5521
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/k/Tensordot 201447 201454
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/ExpandDims_grad/Reshape 987772 987783
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot_grad/Shape 263254 263266
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/tuple/group_deps 1001025 1001028
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs 342979 342991
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads/Reshape/shape 118439 118454
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/k/Tensordot_grad/Reshape 993074 993085
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/ExpandDims_grad/Reshape 1005815 1005827
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape 988628 988637
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_1/Reshape 118494 118501
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp 12239 12249
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Shape_1 6075 6080
model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel 5643 5648
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/add_grad/Reshape 468573 468581
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/sub_1_grad/Reshape_1 517445 517453
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/floordiv_1 295567 295580
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/k/Tensordot/Reshape_grad/Shape 308020 308026
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/floordiv_1 181964 181974
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Maximum_1 342760 342770
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/ReadVariableOp 8072 8083
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/dropout/div_grad/Sum 509736 509744
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot_grad/Reshape 513455 513467
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/transpose_1 16235 16241
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/k/Tensordot/ReadVariableOp 9278 9289
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1 13458 13469
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/transpose_1 15937 15942
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/Shape_1 4459 4464
model/get_train_op/model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias/Adam_1 6507 6511
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/div_grad/Shape 64070 64081
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape 479799 479816
model/get_train_op/model/Transformer/decoder_stack/layer_0/self_attention/self_attention/q/kernel/Adam 649 655
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp 12595 12606
model/get_train_op/model/Transformer/encoder_stack/layer_2/self_attention/self_attention/output_transform/kernel/Adam_1 6264 6271
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads/Shape 279800 279808
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/BiasAdd/ReadVariableOp 8575 8583
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_grad/Reshape_1 1001213 1001221
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/stack 236914 236946
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/div_grad/Sum 483243 483259
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_grad/BroadcastGradientArgs 55893 55927
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_1/ReadVariableOp 7752 7766
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Shape 111305 111315
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/dropout/div_grad/Shape 392513 392522
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_2/Reshape 202148 202154
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/v/Tensordot/transpose_1 16099 16104
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/v/Tensordot_grad/Reshape 627552 627565
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/floordiv_1 307596 307607
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_grad/Shape_1 7364 7370
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/add_grad/Shape_1 7270 7276
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_1/strided_slice_1 314854 314863
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Prod_1 342370 342379
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/ExpandDims 182597 182607
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_1_grad/Reshape_1 469718 469730
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads/Reshape/shape 255747 255760
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Maximum_1 99135 99148
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1 14179 14185
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot_grad/Reshape 471106 471118
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/v/Tensordot/Reshape_grad/Reshape 483072 483087
model/Transformer/decoder_stack/layer_4/encdec_attention/attention/v/kernel 4015 4021
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads/strided_slice 395721 395731
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot_grad/Reshape 993313 993324
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/mul_grad/Reshape 484231 484243
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_grad/Shape 237786 237803
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Square_grad/Const 502998 503007
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/combine_heads/strided_slice 396827 396837
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/floordiv_1 365578 365589
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/add_grad/Reshape 475190 475224
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_1/ReadVariableOp 8558 8565
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/tuple/group_deps 470018 470023
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Maximum_1 272562 272574
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/dropout/div_grad/Sum 468668 468677
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/sub_grad/Reshape_1 598281 598296
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Shape 119780 119787
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Maximum_1 71727 71739
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_1/Reshape 173643 173651
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/mul_grad/Shape_1 17643 17661
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/mul_grad/Reshape 495035 495048
model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale 275 294
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Shape 281044 281051
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_1_grad/Shape_1 2454 2463
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/concat_2 291799 291830
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/Shape 238249 238265
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Reshape 306932 306942
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/dropout/div_grad/Shape_1 4720 4724
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/add_grad/Shape_1 181571 181582
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Maximum 349347 349363
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_2/Reshape/shape 202056 202066
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/add_grad/Shape 20197 20210
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_grad/Reshape_1 1014827 1014836
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/v/Tensordot/ReadVariableOp 9952 9960
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_1_grad/Shape 55442 55458
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/combine_heads/Reshape_grad/Reshape 475605 475619
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/combine_heads/Reshape/shape 350973 350985
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_grad/Shape_1 6646 6651
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads/Shape 23814 23829
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot_grad/Reshape 514699 514707
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/Reshape 1009204 1009215
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/combine_heads/Shape 291607 291617
model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel 5781 5786
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_grad/Sum 1001341 1001351
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/dropout/Shape 157234 157243
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/BiasAdd/ReadVariableOp 10629 10639
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_grad/Sum 492032 492043
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/add_grad/Reshape 468021 468034
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/combine_heads/Reshape 203584 203592
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/transpose_1 16048 16056
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_1/Shape 279809 279817
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/GatherNd_grad/Shape 127343 127350
model/get_train_op/model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale/Adam 888 893
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp_1 14654 14664
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/k/Tensordot/ReadVariableOp 9983 9992
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Prod_1 384341 384357
model/Transformer/decode/presoftmax_linear/Reshape_1/shape 413280 413290
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/dropout/div_grad/Shape 25515 25537
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/stack 263142 263168
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/sub_grad/Reshape 503113 503124
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/sub_grad/Shape 260380 260387
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/Reshape_1 1009218 1009225
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/Reshape_1 508768 508775
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/BiasAdd/ReadVariableOp 8696 8707
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/floordiv 90354 90372
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_grad/Sum 994286 994294
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_grad/Shape_1 154753 154769
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/dropout/div_grad/Shape_1 4220 4224
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_1/Reshape 202106 202112
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_grad/Shape_1 5759 5763
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot 224928 224939
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_grad/BroadcastGradientArgs 72002 72034
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/dropout/div_grad/Reshape 486125 486135
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape 516747 516757
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_2/Shape 63183 63206
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/add_grad/Shape 350373 350384
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Reshape 349506 349522
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Prod_1 70704 70721
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1 13047 13054
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/div_grad/Reshape 629560 629571
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/GatherNd_grad/Squeeze 18247 18266
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Maximum 22398 22444
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/ExpandDims 155238 155248
model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias 3781 3786
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/combine_heads/strided_slice 26283 26308
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/add_grad/Shape 20182 20197
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/stack 244562 244593
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_1_grad/tuple/group_deps 505618 505621
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads/strided_slice 244841 244855
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/stack 341879 341901
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/dropout/div_grad/Sum 511526 511535
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/floordiv 101747 101765
model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias 3775 3780
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_2/Reshape 24224 24236
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/add_grad/Shape_1 19746 19759
model/Transformer/decoder_stack/layer_5/encdec_attention/attention/output_transform/kernel 5182 5186
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/ReadVariableOp 10185 10196
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/ReadVariableOp 9099 9106
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/k/kernel/ResourceApplyAdam/ReadVariableOp 11051 11062
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Shape 127157 127164
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/Shape_1 6226 6232
model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale 320 325
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1 14085 14096
model/Transformer/encoder_stack/layer_3/self_attention/self_attention/q/kernel 3391 3397
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_grad/Sum 489556 489574
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp 10967 10980
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_1_grad/tuple/group_deps 473944 473947
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/Prod_1 44862 44880
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/AssignVariableOp 16669 16685
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp 12919 12929
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/BiasAdd/ReadVariableOp 9047 9054
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/transpose_1 15539 15549
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Reshape 996076 996084
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/dropout/div_grad/BroadcastGradientArgs 368188 368202
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/v/Tensordot_grad/Shape 201358 201366
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot_grad/Shape 272013 272025
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_1_grad/Shape_1 110392 110403
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/k/Tensordot/ReadVariableOp 9784 9794
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1 13858 13868
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/k/Tensordot/ReadVariableOp 8816 8827
model/Transformer/decode/decoder_stack/layer_4/ffn/dropout/Shape 377082 377088
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape 1010529 1010540
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Reshape 129503 129520
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/Maximum 325306 325322
model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel 5039 5043
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_1_grad/Shape_1 165510 165520
model/get_train_op/model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/Adam_1 3105 3111
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Sum 1006099 1006107
model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias 3652 3657
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/add_grad/BroadcastGradientArgs 272301 272313
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/add_grad/Shape_1 252654 252662
model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_1/ReadVariableOp 9212 9220
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/sub_grad/Reshape_1 470737 470748
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/mul_1_grad/Sum 992325 992336
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/ReadVariableOp 10378 10389
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/Maximum_1 288297 288317
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/combine_heads/Reshape_grad/Shape 386001 386008
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/concat_2 273220 273248
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/k/Tensordot/transpose_1 15665 15677
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/div_grad/Shape 91597 91609
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_1/Reshape/shape 201992 202002
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/dropout/div_grad/BroadcastGradientArgs 342109 342122
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/mul_grad/Shape_1 5666 5670
model/get_train_op/model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale/Adam 6546 6553
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/concat_2 368388 368406
model/get_train_op/model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel/Adam 470 478
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/add_grad/Reshape 515893 515902
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs 55862 55889
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1 13176 13187
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot_grad/Shape 400046 400059
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Prod 99267 99279
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Reshape 173216 173235
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Maximum/y 6028 6036
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/dropout/div_grad/BroadcastGradientArgs 272133 272146
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Shape 226152 226161
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/add_grad/Sum_1 514597 514603
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/transpose_1 15315 15325
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp 11664 11674
model/Transformer/encoder_stack/layer_5/self_attention/self_attention/output_transform/kernel 5218 5223
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1 262984 263008
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Shape 56469 56486
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/Maximum 325316 325347
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/transpose_1 16426 16436
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot_grad/Reshape 495214 495229
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_1_grad/BroadcastGradientArgs 72421 72445
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads/Shape 145864 145872
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Maximum/y 2966 2978
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_1_grad/Shape_1 5073 5078
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/Shape 326732 326738
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/Prod_1 322969 322977
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/Shape 166322 166335
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Prod_1 192185 192207
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Prod 365435 365446
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Reshape 491623 491640
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/Maximum 255404 255421
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_1_grad/Reshape 640588 640597
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/div_grad/Sum 629548 629557
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/floordiv_1 288385 288409
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/add_grad/Shape 91464 91476
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/concat_2 401162 401179
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/v/Tensordot/ReadVariableOp 9498 9509
model/get_train_op/model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/Adam 2306 2317
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/dropout/div_grad/Shape_1 4098 4101
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/Gather_grad/strided_slice/stack_1 3004 3010
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Maximum/y 4831 4837
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/k/Tensordot/ReadVariableOp 9135 9145
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/concat_2 326915 326937
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/combine_heads/Shape 361558 361568
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/add_grad/Sum_1 470960 470972
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Maximum_1 182178 182189
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1 14788 14794
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/sub_grad/Reshape 990655 990665
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/floordiv_1 322914 322925
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Maximum_1 342487 342498
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_2/Shape 173497 173504
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/dropout/div_grad/BroadcastGradientArgs 82524 82541
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot 237051 237059
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_1_grad/Shape 165379 165389
model/get_train_op/model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel/Adam_1 1496 1504
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/sub_1_grad/Reshape_1 496250 496261
model/get_train_op/model/Transformer/encoder_stack/layer_0/self_attention/self_attention/k/kernel/Adam 3303 3308
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/dropout/div_grad/Shape 245560 245569
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/mul_grad/Sum 477440 477455
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/Maximum/y 4775 4780
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/dropout/mul_grad/Shape 25693 25708
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_grad/Shape_1 4254 4258
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/k/Tensordot/Reshape_grad/Shape 238375 238384
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_1_grad/Reshape 636439 636450
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1 400831 400837
model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_1/ReadVariableOp 10227 10238
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1 14072 14083
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape 475494 475508
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot 255696 255704
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/re_add_padding/Squeeze_grad/Reshape 1015554 1015565
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_1_grad/Reshape_1 600196 600205
model/get_train_op/model/Transformer/decoder_stack/layer_4/encdec_attention/attention/output_transform/kernel/Adam 1643 1651
model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_1/ReadVariableOp 10704 10716
model/get_train_op/gradients/model/loss/smoothing_cross_entropy/sub_grad/Shape 466520 466529
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Maximum_1 83463 83478
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Reshape 481264 481280
model/get_train_op/gradients/model/Transformer/decode/presoftmax_linear/Reshape_1_grad/Reshape 467051 467065
model/get_train_op/model/Transformer/decoder_stack/layer_5/self_attention/self_attention/k/kernel/Adam 2165 2170
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Maximum/y 4877 4882
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/add_grad/BroadcastGradientArgs 252694 252705
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_grad/Reshape_1 1016759 1016767
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/Reshape 499739 499749
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Reshape 1014610 1014621
model/get_train_op/model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias/Adam_1 5812 5816
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/k/Tensordot/transpose_1 16269 16277
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_grad/Sum 999533 999543
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/dropout/div_grad/Shape 260130 260136
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1 392986 392995
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/mul_grad/BroadcastGradientArgs 255863 255879
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/concat_2 257011 257030
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_grad/Reshape 1001200 1001211
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/combine_heads/Reshape/shape 316006 316016
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Reshape_grad/Shape 22469 22494
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/combine_heads/strided_slice 386026 386036
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_2/strided_slice_1 24006 24019
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Reshape 517456 517463
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_grad/Shape_1 7026 7033
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Prod_1 365405 365413
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/combine_heads/Reshape_grad/Shape 315968 315975
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot_grad/Shape 109814 109828
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/Shape 253686 253697
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice/stack_1 5741 5746
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot_grad/Shape 307004 307013
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_1/strided_slice 118384 118394
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_grad/tuple/group_deps 1004469 1004472
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_grad/Reshape 511020 511029
model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel 5552 5557
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/add_grad/Reshape_1 509676 509683
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Shape 92209 92216
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_1_grad/Shape 82715 82726
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads/strided_slice_1 118368 118380
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/add_grad/Shape 119017 119029
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp 11124 11129
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/tuple/group_deps 1019642 1019645
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/Prod_1 357874 357883
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/add_grad/Reshape_1 492650 492657
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/mul_grad/Shape 360621 360634
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/Reshape_grad/Shape 193997 194005
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Maximum 129300 129333
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Square_grad/Const 990104 990113
model/Transformer/encoder_stack/layer_4/self_attention/self_attention/q/kernel 5461 5466
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads/strided_slice_1 279846 279857
model/get_train_op/model/Transformer/encoder_stack/layer_5/self_attention/self_attention/v/kernel/Adam_1 7264 7268
model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias 3693 3698
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/transpose_1 16205 16215
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice/stack 5735 5740
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/add_grad/Shape_1 19687 19700
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Sum 478289 478302
model/get_train_op/model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale/Adam_1 1240 1245
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/add_grad/Sum_1 1017299 1017306
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Shape 99903 99924
model/Transformer/decoder_stack/layer_0/self_attention/self_attention/k/kernel 3444 3452
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/mul_grad/BroadcastGradientArgs 326610 326622
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Shape 296047 296056
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_2/Reshape 202114 202120
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Prod_1 279394 279413
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/sub_grad/Reshape_1 496556 496569
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/transpose_1 16152 16158
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/add_grad/Reshape 994529 994538
model/Transformer/encoder_stack/layer_3/self_attention/self_attention/v/kernel 3488 3493
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/add_grad/Reshape_1 1005012 1005020
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Reshape 40639 40656
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Reshape_grad/Shape 273122 273129
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/combine_heads/Shape 350923 350934
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/Gather_grad/Reshape 992513 992524
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Reshape 367922 367938
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/sub_1_grad/Shape_1 400400 400407
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape 969897 969927
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/mul_grad/Shape_1 4545 4549
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/combine_heads/strided_slice 92166 92176
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/k/kernel/ResourceApplyAdam/ReadVariableOp 11395 11400
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape 598817 598831
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/ExpandDims_grad/Shape 40723 40738
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/v/Tensordot/ReadVariableOp 8474 8491
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/floordiv 466060 466070
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/Prod 322999 323009
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/add_grad/BroadcastGradientArgs 137842 137855
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/k/Tensordot/Reshape_grad/Shape 194025 194031
model/get_train_op/gradients/concat/axis 3018 3023
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1 400469 400476
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Reshape 384603 384620
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape 1003885 1003897
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_grad/BroadcastGradientArgs 181816 181829
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/combine_heads/strided_slice 64609 64620
model/get_train_op/train/Const 1021402 1021408
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape 1010817 1010829
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/transpose_1 16497 16506
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/concat_2 147387 147407
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/GatherNd_grad/Squeeze 18228 18247
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/div_grad/Reshape 1002871 1002882
model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_1/ReadVariableOp 10318 10325
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/combine_heads/strided_slice_1 281000 281010
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot 306993 307002
model/get_train_op/model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale/Adam 6176 6182
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/ReadVariableOp 10358 10365
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Reshape 126096 126110
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Prod 272421 272433
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/k/Tensordot_grad/Shape 201303 201312
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Reshape 492473 492483
model/Transformer/attention_bias/ExpandDims 17176 17189
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/add_grad/Reshape_1 626385 626393
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/ExpandDims 40741 40754
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/dropout/div_grad/BroadcastGradientArgs 102158 102174
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_grad/Sum 1014760 1014770
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/v/Tensordot_grad/Reshape 992029 992039
model/Transformer/encoder_stack/layer_2/self_attention/self_attention/output_transform/kernel 3668 3672
model/loss/smoothing_cross_entropy/truediv 5146 5151
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/sub_grad/Reshape_1 474969 474981
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Prod 83215 83235
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/Shape 291681 291689
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1 13883 13894
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/add_grad/Reshape 1001749 1001759
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_1/ReadVariableOp 8567 8573
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Reshape 611951 611964
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/combine_heads/Reshape 316019 316027
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_grad/Reshape 999586 999597
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Square_grad/Const 1009854 1009861
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads/strided_slice 145893 145919
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/add_grad/BroadcastGradientArgs 315454 315469
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/Shape 358287 358293
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_2/transpose_grad/InvertPermutation 2319 2399
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Shape 74776 74786
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/k/Tensordot 201342 201349
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_grad/Reshape_1 474461 474473
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_1_grad/Sum 484932 484942
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/Reshape 468406 468415
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/dropout/Shape 385590 385598
model/Transformer/encoder_stack/layer_2/self_attention/self_attention/k/kernel 3743 3747
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/add_grad/Sum 506475 506484
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/mul_grad/Reshape 1020750 1020758
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_grad/Sum 989354 989361
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot_grad/Shape 90654 90667
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/add_grad/Sum_1 506486 506492
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Maximum 349380 349392
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/dropout/div_grad/BroadcastGradientArgs 55112 55138
model/get_train_op/model/Transformer/decoder_stack/layer_3/self_attention/self_attention/k/kernel/Adam 1565 1570
model/get_train_op/model/Transformer/decoder_stack/layer_0/encdec_attention/attention/k/kernel/Adam_1 350 354
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/dropout/div_grad/Sum 490307 490316
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Maximum_1 307776 307784
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1 225963 225970
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/add_grad/Shape_1 18161 18177
model/Transformer/decode/shift_targets/strided_slice/stack_1 3542 3546
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Shape 272577 272586
model/get_train_op/model/Transformer/decoder_stack/layer_1/encdec_attention/attention/output_transform/kernel/Adam_1 702 708
model/loss/smoothing_cross_entropy/one_hot/depth 5128 5133
model/get_train_op/gradients/model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits_grad/ExpandDims 466957 466973
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp 11012 11023
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_grad/Reshape_1 1011536 1011545
model/get_train_op/gradients/model/Transformer/decode/dropout/div_grad/Sum 991252 991264
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_grad/Shape_1 4122 4130
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/Shape 291157 291164
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot 201379 201384
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/re_add_padding/Squeeze_grad/Shape 165026 165038
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_1_grad/Shape 323306 323322
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_1_grad/Reshape_1 467597 467606
model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_bias 1704 1710
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_grad/BroadcastGradientArgs 56438 56465
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_1_grad/BroadcastGradientArgs 127300 127313
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_grad/Sum 496184 496195
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/combine_heads/Reshape 92198 92208
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/mul_grad/Sum 992016 992026
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Prod_1 307410 307420
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/floordiv_1 72198 72215
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/k/Tensordot_grad/Shape 23745 23758
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_grad/Reshape 474621 474634
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/sub_grad/Reshape_1 492416 492433
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/div_grad/Sum 504470 504478
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads/Reshape 314947 314954
model/Transformer/encode/encoder_stack/layer_4/self_attention/dropout/Shape 153792 153803
model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_1/ReadVariableOp 7954 7962
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/Shape 357574 357581
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Square_grad/Const 994226 994234
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Sum 1011292 1011300
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1 14353 14360
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/v/Tensordot/ReadVariableOp 10172 10182
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_grad/Reshape_1 1001595 1001604
FunctionBufferingResourceGetNext 233 259
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Prod_1 126664 126677
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/Reshape 255592 255609
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Maximum_1 56323 56335
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Reshape_1 1006152 1006159
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Maximum 402983 402998
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/sub_grad/Reshape 470679 470692
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_1_grad/Shape_1 4180 4186
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads/strided_slice_1 395701 395717
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp 12315 12326
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_2/strided_slice_1 173564 173572
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_2/Reshape/shape 90889 90899
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1 323237 323242
model/get_train_op/model/Transformer/encoder_stack/layer_0/self_attention/self_attention/k/kernel/Adam_1 3308 3312
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/floordiv_1 41627 41643
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/sub_1_grad/Reshape_1 990281 990290
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/Reshape_1 40509 40524
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/mul_grad/Reshape 512443 512454
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/sub_grad/Shape 307333 307339
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1 14892 14901
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/re_add_padding/Reshape 137598 137608
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_1_grad/BroadcastGradientArgs 296058 296069
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_grad/Sum 1020171 1020183
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Maximum/y 4142 4150
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1 14004 14016
model/get_train_op/model/Transformer/encoder_stack/layer_3/self_attention/self_attention/q/kernel/Adam_1 6615 6619
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1 365224 365230
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Shape 237359 237368
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/sub_grad/Reshape 514402 514412
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/dropout/div_grad/Reshape 1012174 1012184
model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_1/ReadVariableOp 7630 7649
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/concat_2 261461 261475
model/get_train_op/model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias/Adam 1165 1170
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_grad/Shape_1 393413 393425
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/v/Tensordot/transpose_1 16218 16225
model/Transformer/encoder_stack/layer_1/self_attention/self_attention/k/kernel 334 341
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/Shape 412402 412410
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Shape 261134 261144
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Prod 20369 20382
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_1/Reshape/shape 314915 314928
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/tuple/group_deps 516939 516942
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_1/strided_slice 201646 201656
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/mul_grad/Shape_1 119380 119389
model/get_train_op/model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel/Adam_1 3141 3150
model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale 3880 3887
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_grad/Shape 365394 365404
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/dropout/div_grad/Shape 315527 315536
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Sum 989672 989680
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/Gather_grad/concat 16895 16916
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/dropout/div_grad/Sum 496881 496891
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1 13034 13044
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/ReadVariableOp 8048 8056
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot_grad/Reshape 496917 496936
model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_1/ReadVariableOp 7964 7970
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_1/Reshape 202089 202095
model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel 5390 5395
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Shape 298407 298414
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/add_grad/Reshape_1 648851 648859
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Shape 71742 71752
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/add_grad/Sum_1 475181 475187
model/get_train_op/model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel/Adam 7077 7084
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_1_grad/BroadcastGradientArgs 253659 253682
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/k/kernel/ResourceApplyAdam/ReadVariableOp 11788 11800
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/sub_grad/Reshape_1 485761 485774
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Shape 129941 129951
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_2/Reshape/shape 201953 201962
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Shape 365748 365755
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape 509978 509988
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_grad/BroadcastGradientArgs 307757 307773
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Maximum_1 238030 238048
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs 82997 83015
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/dropout/mul_grad/Shape 385613 385620
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/floordiv 403001 403011
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Shape 111089 111102
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_grad/Shape_1 20383 20396
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/transpose_1 16387 16397
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot_grad/Reshape 632553 632563
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/floordiv 22693 22712
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/add_1_grad/Shape 193876 193894
model/get_train_op/model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale/Adam_1 6520 6526
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/re_add_padding/Reshape 55002 55016
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_grad/BroadcastGradientArgs 99075 99088
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/ReadVariableOp 10130 10144
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/Prod 253120 253137
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot_grad/Shape 101968 101988
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_1_grad/Reshape 989711 989722
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1 14854 14863
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/add_grad/Reshape 503340 503350
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Reshape 1009778 1009786
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Shape 351006 351012
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/transpose_1 15296 15305
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/k/Tensordot/ReadVariableOp 8085 8175
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/concat_2 386194 386225
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/floordiv_1 83544 83559
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Maximum/y 6092 6097
model/get_train_op/model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_scale/Adam_1 1731 1736
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/mul_grad/Reshape 505246 505257
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs 110495 110512
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/sub_grad/Reshape 481520 481536
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_grad/Shape 20855 20870
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Maximum 44301 44326
model/get_train_op/model/Transformer/decoder_stack/layer_3/encdec_attention/attention/v/kernel/Adam_1 1371 1379
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_2/strided_slice_1 201786 201795
model/get_train_op/model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias/Adam 7094 7100
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_grad/Reshape 492078 492094
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/k/Tensordot_grad/Reshape 488236 488253
model/get_train_op/gradients/model/loss/pad_to_same_length/Pad_grad/Slice 413399 413410
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_grad/Shape 56129 56148
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_1/strided_slice_1 145952 145963
model/Transformer/encode/add_pos_encoding/range 18816 18831
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1 14976 14987
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/sub_1_grad/Shape_1 392878 392888
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/add_grad/BroadcastGradientArgs 287632 287645
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/mul_grad/Shape_1 4371 4375
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Square_grad/Const 485552 485564
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/concat_2 130079 130100
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice 155207 155222
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot_grad/Shape 349681 349692
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/Gather_grad/strided_slice/stack 2880 2891
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/sub_grad/Shape_1 412500 412506
model/get_train_op/model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias/Adam_1 6845 6849
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/Reshape_1 127325 127332
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot 74477 74490
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/dropout/div_grad/Shape_1 4584 4589
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_2/strided_slice 23989 24002
model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel 5315 5320
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/attention_weights_grad/Sum/reduction_indices 4736 4741
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/mul_grad/Shape 325783 325795
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Shape 64665 64676
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Reshape 1001004 1001014
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1 14200 14207
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/Shape 361633 361639
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Shape 119770 119777
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_1/strided_slice_1 201810 201820
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_2/Shape 201486 201493
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/floordiv_1 71802 71817
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape 987496 987516
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_1_grad/Reshape 502105 502117
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp 11702 11715
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_1_grad/BroadcastGradientArgs 182466 182477
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/v/Tensordot_grad/Reshape 493713 493731
model/Transformer/decode/decoder_stack/layer_5/ffn/dropout/Shape 412187 412193
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/add_grad/Shape_1 18294 18308
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/add_grad/Sum 498431 498441
model/get_train_op/learning_rate/ToFloat_1/ReadVariableOp 15073 15083
model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_1/ReadVariableOp 8670 8681
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Maximum 384362 384385
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_2/strided_slice 201735 201745
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/add_grad/Reshape 992567 992576
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/transpose_1 15899 15917
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_grad/Shape_1 5680 5686
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/add_grad/Reshape_1 1010187 1010195
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Reshape_grad/Shape 238386 238392
model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_1/ReadVariableOp 8181 8200
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/tuple/group_deps 1016568 1016571
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp_1 13408 13419
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/dropout/div_grad/RealDiv_recip 3331 3389
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/dropout/div_grad/Shape_1 4843 4847
model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale 3721 3726
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_grad/Shape 260805 260821
model/get_train_op/model/Transformer/encoder_stack/layer_1/self_attention/self_attention/k/kernel/Adam 5921 5928
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/add_grad/Reshape_1 479402 479410
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/dropout/div_grad/Reshape 479504 479517
model/get_train_op/model/Transformer/decoder_stack/layer_0/self_attention/self_attention/output_transform/kernel/Adam_1 642 648
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_grad/BroadcastGradientArgs 83361 83406
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/combine_heads/Reshape_grad/Shape 326671 326678
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/dropout/div_grad/BroadcastGradientArgs 280586 280598
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Reshape 1004868 1004877
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/sub_grad/Shape_1 307371 307377
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/combine_heads/Reshape/shape 147239 147250
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/v/Tensordot/transpose_1 15735 15745
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Shape 182636 182643
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Reshape 481631 481644
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/Maximum 290352 290377
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_1_grad/Reshape_1 484733 484741
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/dropout/Shape 403377 403384
model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias 3589 3593
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/sub_3 3097 3103
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/sub_2 2291 2303
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/Reshape 485810 485824
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/div_grad/BroadcastGradientArgs 119230 119244
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp_1 13797 13803
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Maximum 173068 173085
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/div_grad/BroadcastGradientArgs 361168 361180
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Reshape 392419 392430
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/dropout/div_grad/BroadcastGradientArgs 25659 25688
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/div_grad/BroadcastGradientArgs 91656 91671
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/sub_grad/Shape 322638 322645
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Shape 225972 225982
model/get_train_op/model/Transformer/encoder_stack/layer_normalization/layer_norm_scale/Adam_1 7419 7426
model/get_train_op/gradients/model/Transformer/decode/presoftmax_linear/Reshape_grad/Shape 413165 413172
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/add_grad/Sum 479359 479375
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1 14362 14372
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/div_grad/Shape_1 4887 4893
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/combine_heads/strided_slice_1 246026 246037
model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale 5477 5482
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Prod_1 181001 181021
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_1_grad/tuple/group_deps 1011138 1011140
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/k/Tensordot_grad/Shape 201406 201414
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Shape 333435 333444
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/re_add_padding/Reshape/shape 127490 127503
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp_1 14442 14449
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/dropout/div_grad/Sum 1015484 1015492
model/get_train_op/model/Transformer/decoder_stack/layer_0/self_attention/self_attention/q/kernel/Adam_1 656 661
model/Transformer/encoder_stack/layer_5/self_attention/self_attention/q/kernel 5300 5304
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/combine_heads/Reshape 26482 26501
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads/Reshape 290630 290636
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Reshape 101868 101884
model/get_train_op/model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel/Adam 1152 1157
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/dropout/div_grad/Reshape 498239 498250
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/Gather_grad/Reshape 1020761 1020768
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/mul_grad/Shape_1 6317 6321
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Shape 71409 71418
model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale 3770 3775
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_grad/Reshape 514209 514218
model/Transformer/encoder_stack/layer_normalization/layer_norm_bias 6665 6668
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/floordiv 384429 384476
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/add_grad/Reshape_1 468583 468591
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/add_grad/BroadcastGradientArgs 295302 295313
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/add_grad/Shape 174133 174145
model/get_train_op/model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_scale/Adam_1 1127 1133
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp 11176 11182
model/get_train_op/gradients/model/Transformer/decode/shift_targets/strided_slice_grad/Shape 18680 18691
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/sub_grad/Shape 392771 392779
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Reshape 990823 990832
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/stack 224772 224810
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/transpose_1 15928 15935
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/re_add_padding/Reshape_grad/Reshape 649268 649277
model/Transformer/decoder_stack/layer_5/self_attention/self_attention/q/kernel 5213 5217
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Reshape_1 989057 989065
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape 1000187 1000199
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/transpose_1 16352 16357
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_2/strided_slice_1 24082 24093
model/get_train_op/model/Transformer/decoder_stack/layer_4/encdec_attention/attention/k/kernel/Adam_1 1623 1631
model/Transformer/decode/decoder_self_attention_bias/mul/x 3453 3461
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/ReadVariableOp 9823 9833
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/dropout/div_grad/Shape_1 5002 5006
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp_1 13087 13095
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Shape 102306 102315
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1 12961 12972
model/get_train_op/model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale/Adam 6208 6215
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/dropout/div_grad/Reshape 1001829 1001838
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Reshape 322294 322304
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/concat_2 41012 41045
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/combine_heads/Reshape 119759 119768
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_grad/tuple/group_deps 1020050 1020052
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Shape 154848 154856
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/add_grad/Shape_1 18312 18327
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Prod 260785 260802
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/Prod_1 288171 288189
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/transpose_1 15525 15536
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads/Reshape 24080 24096
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_grad/Shape_1 138030 138046
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/add_grad/Reshape 483459 483468
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot 341979 341987
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_grad/Shape_1 412947 412955
model/get_train_op/model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_bias/Adam 1092 1102
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp 11305 11313
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/add_grad/Shape 225202 225211
Identity/ReadVariableOp 15060 15071
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads/Reshape/shape/3 5261 5276
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads/Reshape/shape/2 5242 5260
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_1/Reshape 349900 349917
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_1_grad/Shape 20141 20157
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/add_grad/Reshape 512724 512733
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/combine_heads/Reshape_grad/Reshape 1007161 1007173
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/combine_heads/Reshape/shape 26454 26478
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_grad/Reshape 1004609 1004617
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp 11490 11499
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_grad/Sum 514172 514182
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/combine_heads/Shape 315955 315966
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/tuple/group_deps 993782 993785
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/dropout/div_grad/Sum 490807 490818
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/ReadVariableOp 10418 10430
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/add_grad/Sum_1 996439 996445
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_2/Shape 279819 279825
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/stack 44969 45005
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/mul_grad/Shape 91674 91683
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/combine_heads/strided_slice_1 256842 256852
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Maximum_1 110951 110965
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/sub_grad/Shape_1 377425 377432
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_grad/BroadcastGradientArgs 22115 22140
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Shape 39506 39516
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/k/Tensordot/ReadVariableOp 8202 8210
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/Shape 26483 26502
model/get_train_op/model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel/Adam 515 523
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads/Shape 314786 314793
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/floordiv 22460 22482
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/add_grad/Sum 1015388 1015396
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Maximum 62771 62797
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads/Reshape/shape 279919 279933
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp 11467 11476
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/re_add_padding/Reshape 165122 165131
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_grad/Shape 165390 165398
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_1_grad/Sum 999218 999227
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/Gather_grad/strided_slice/stack_1 2893 2902
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot_grad/Shape 118246 118260
model/Transformer/decode/decoder_self_attention_bias/Reshape 19136 19148
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/k/Tensordot 201293 201301
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp 11170 11175
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_grad/BroadcastGradientArgs 83562 83576
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/v/Tensordot/Reshape_grad/Reshape 512457 512465
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_grad/Shape_1 225881 225890
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/floordiv 117923 117934
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/combine_heads/strided_slice_1/stack_1 3600 3608
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/dropout/div_grad/BroadcastGradientArgs 157245 157260
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/BroadcastGradientArgs 40370 40386
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/dropout/div_grad/Sum 971089 971104
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/mul_grad/Shape_1 4899 4910
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Maximum/y 6019 6027
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_1_grad/Reshape_1 1006486 1006495
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/transpose_1 16138 16143
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/Prod_1 253230 253246
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1 295424 295432
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/v/Tensordot 201431 201437
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_grad/BroadcastGradientArgs 377767 377785
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/add_grad/Sum 492619 492629
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp 12067 12077
model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale 3647 3651
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_grad/Shape 55461 55475
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Prod_1 110828 110842
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads/Reshape 146036 146044
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/attention_weights_grad/Sum/reduction_indices 4163 4168
model/get_train_op/train/AssignVariableOp_1 1021383 1021388
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot_grad/Shape 63160 63170
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/dropout/div_grad/Shape 157187 157198
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads/Shape 63209 63220
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/v/kernel/ResourceApplyAdam/ReadVariableOp 11081 11088
model/get_train_op/gradients/model/Sum_grad/Shape 466635 466643
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Shape 56763 56778
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/Prod_1 357646 357658
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/k/Tensordot_grad/Shape 201331 201340
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/BiasAdd/ReadVariableOp 10061 10072
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/concat_2 155417 155437
model/get_train_op/model/Transformer/encoder_stack/layer_5/self_attention/self_attention/k/kernel/Adam 7210 7214
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/k/Tensordot/transpose_1 16106 16113
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1 13421 13432
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/k/Tensordot/Reshape_grad/Shape 22452 22466
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1 13434 13444
model/get_train_op/model/Transformer/decoder_stack/layer_3/encdec_attention/attention/v/kernel/Adam 1358 1366
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/Prod_1 322719 322729
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/v/Tensordot/transpose_1 15501 15511
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_1/strided_slice_1 90815 90826
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/sub_grad/Reshape_1 500761 500771
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/mul_grad/Reshape 998373 998385
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads/Reshape/shape 145991 146005
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/add_grad/Sum 626349 626358
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/k/kernel/ResourceApplyAdam/ReadVariableOp 11183 11188
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/floordiv 290353 290369
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_1/ReadVariableOp 9023 9035
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot_grad/Reshape 486138 486148
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1 13700 13709
model/get_train_op/model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel/Adam_1 6153 6159
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_grad/Shape_1 2769 2775
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/sub_grad/Shape 330202 330209
model/get_train_op/model/Transformer/decoder_stack/layer_2/encdec_attention/attention/k/kernel/Adam_1 1017 1027
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/dropout/div_grad/Shape_1 4102 4107
model/get_train_op/model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias/Adam 1737 1743
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/combine_heads/Shape 119693 119704
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/add_grad/Shape 181644 181653
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/k/Tensordot/transpose_1 16292 16302
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Shape 308004 308010
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/div_grad/Sum 1002858 1002869
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/v/Tensordot/transpose_1 16304 16312
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/add_grad/Shape_1 322574 322583
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_grad/Shape_1 4758 4762
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/add_grad/Sum_1 468564 468570
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/add_grad/Reshape 1006868 1006878
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/combine_heads/Reshape/shape 281013 281023
model/get_train_op/model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel/Adam_1 1158 1163
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_2/strided_slice_1 349824 349833
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Shape 26402 26415
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/add_grad/Sum 500961 500970
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/concat_2 263638 263664
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/dropout/Shape 260176 260187
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/v/Tensordot/transpose_1 15884 15897
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/sub_1_grad/Reshape_1 509288 509296
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/ReadVariableOp 10448 10458
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/k/kernel/ResourceApplyAdam/ReadVariableOp 10814 10823
model/get_train_op/model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale/Adam 3227 3231
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot 325613 325623
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_1_grad/Shape_1 4556 4561
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_2/Shape 23847 23862
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_1/strided_slice 244873 244884
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp 11802 11815
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_1_grad/Reshape 1001306 1001315
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/ReadVariableOp_8 1021253 1021262
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/floordiv 244433 244445
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_grad/Shape_1 166087 166103
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/dropout/div_grad/Reshape 506572 506581
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads/strided_slice 50364 50389
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/add_grad/BroadcastGradientArgs 64037 64056
model/get_train_op/model/Transformer/decoder_stack/layer_5/encdec_attention/attention/output_transform/kernel/Adam 1961 1969
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Prod 330549 330559
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/add_grad/Shape_1 377241 377251
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot 287378 287389
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/transpose_1 15984 15995
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_2/strided_slice_1 384920 384930
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/v/Tensordot_grad/Shape 173457 173465
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Shape_1 4820 4825
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/v/Tensordot 201351 201356
model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel 5547 5551
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/div_grad/BroadcastGradientArgs 256400 256412
model/get_train_op/model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias/Adam_1 562 568
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/Reshape 468048 468055
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/combine_heads/Reshape/shape 291658 291668
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_1_grad/BroadcastGradientArgs 155026 155049
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads/strided_slice_1 325646 325659
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_grad/Shape 110759 110771
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp_1 13506 13513
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/add_grad/Sum 1008205 1008213
model/get_train_op/model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel/Adam 6449 6455
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/mul_grad/Reshape 993184 993196
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/combine_heads/strided_slice 350961 350971
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_grad/Reshape 1006336 1006348
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice 99826 99839
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/add_1_grad/tuple/group_deps 467307 467312
model/get_train_op/model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_bias/Adam 740 749
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_grad/Shape_1 6332 6336
model/Transformer/decoder_stack/layer_4/encdec_attention/attention/output_transform/kernel 5321 5326
model/get_train_op/model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias/Adam 6161 6168
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1 14327 14338
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/q/kernel/ResourceApplyAdam/ReadVariableOp 11409 11416
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Square_grad/Const 644714 644720
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/combine_heads/Reshape 246054 246062
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Reshape 1006507 1006515
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/combine_heads/strided_slice 256827 256839
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/add_grad/Sum_1 1015398 1015404
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_1_grad/Reshape 1016360 1016371
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/floordiv 200563 200573
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1 307458 307465
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1 377897 377914
model/Transformer/encode/encoder_stack/layer_normalization/add_1/ReadVariableOp 10720 10732
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Reshape_1 500037 500049
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Maximum_1 295781 295791
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/re_add_padding/Reshape_grad/Shape 137585 137596
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Reshape 1016548 1016558
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/dropout/div_grad/BroadcastGradientArgs 333339 333353
model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_1/ReadVariableOp 8593 8603
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/stack 255559 255587
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/Shape 322892 322902
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/dropout/Shape 368106 368114
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/add_grad/Sum 648785 648794
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_1_grad/Sum 495745 495755
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/k/Tensordot 145835 145840
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/combine_heads/Reshape/shape 92180 92194
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot 157111 157119
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_1_grad/Reshape_1 474209 474215
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/Maximum_1 412619 412629
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Maximum/y 4347 4352
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/v/Tensordot 118303 118310
model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_1/ReadVariableOp 8995 9006
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp_1 14250 14260
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/dropout/div_grad/Shape_1 6046 6053
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/dropout/div_grad/BroadcastGradientArgs 71150 71168
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/add_grad/Sum 1017289 1017297
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/floordiv_1 330689 330700
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/re_add_padding/Reshape_grad/Shape 165108 165120
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_1/Reshape 202140 202146
model/get_train_op/model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel/Adam_1 1455 1464
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1 13149 13160
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/sub_grad/Shape_1 20401 20412
model/get_train_op/model/Transformer/decoder_stack/layer_1/encdec_attention/attention/v/kernel/Adam_1 731 737
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_grad/Shape_1 83482 83498
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice 182568 182581
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/floordiv 62873 62890
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_grad/Reshape_1 994372 994382
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1 260604 260618
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/mul_grad/BroadcastGradientArgs 290726 290741
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/add_grad/Shape 326104 326114
model/get_train_op/gradients/concat 1020770 1020847
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_1_grad/Reshape_1 480541 480549
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/Reshape_grad/Reshape 492898 492922
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Shape 110281 110290
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/combine_heads/Shape 92125 92136
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_grad/Shape 20160 20173
model/get_train_op/model/Transformer/decoder_stack/layer_5/self_attention/self_attention/q/kernel/Adam_1 2196 2203
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/Maximum_1 393053 393070
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp_1 13241 13253
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp 11150 11155
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/concat_2 343144 343164
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/transpose_1 16083 16089
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/add_1_grad/Shape 413094 413101
model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_1/ReadVariableOp 9222 9229
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/floordiv 173088 173100
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/tuple/group_deps 1009418 1009420
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/Reshape 200756 200783
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp 12341 12351
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/k/Tensordot_grad/Reshape 494876 494887
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_grad/Sum 1015145 1015153
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/sub_grad/Reshape 474903 474924
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Reshape 1010048 1010057
model/get_train_op/model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale/Adam 1845 1853
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp 12264 12274
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/tuple/group_deps 491662 491665
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp 11717 11729
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/Shape 273029 273038
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp 11689 11700
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot_grad/Shape 244751 244763
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_1_grad/Reshape_1 1009757 1009766
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Prod 307689 307700
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/combine_heads/strided_slice_1 350945 350958
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/Prod 392864 392875
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1 14404 14411
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1 295917 295925
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/concat_2 127639 127682
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_1_grad/Reshape 484993 485005
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/dropout/div_grad/Reshape 469204 469219
model/get_train_op/model/Transformer/encoder_stack/layer_5/self_attention/self_attention/output_transform/kernel/Adam 7220 7224
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/BroadcastGradientArgs 273076 273092
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs 273009 273026
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/BiasAdd/ReadVariableOp 9173 9185
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_1_grad/BroadcastGradientArgs 365756 365765
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp_1 12945 12958
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_grad/BroadcastGradientArgs 40291 40306
model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel 5170 5174
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot_grad/Shape 392486 392499
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/sub_1_grad/Reshape_1 470423 470436
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/re_add_padding/Squeeze 109893 109914
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/attention_weights_grad/Sum/reduction_indices 4957 4962
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Prod_1 110477 110492
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_1/Shape 384842 384848
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp 11451 11456
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp 12874 12884
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/add_grad/Reshape_1 503352 503360
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/add_grad/Shape 82751 82759
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/add_grad/Reshape 996447 996458
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot_grad/Reshape 499391 499403
model/get_train_op/model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_scale/Adam 757 763
model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias 4209 4213
model/get_train_op/gradients/model/loss/pad_to_same_length/Pad_grad/Shape 413302 413308
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/Shape 41567 41577
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/dropout/mul_grad/Reshape 507386 507394
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/add_grad/Shape 357554 357563
model/get_train_op/model/Transformer/decoder_stack/layer_5/encdec_attention/attention/v/kernel/Adam_1 2009 2017
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Shape 342301 342309
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Maximum 279465 279486
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/concat_2 296163 296187
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/ReadVariableOp 10034 10045
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Shape 155291 155298
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot 90669 90679
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Prod_1 165959 165973
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_grad/Sum 1017068 1017075
model/get_train_op/gradients/model/Transformer/encode/dropout/div_grad/Shape_1 2980 2988
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Prod_1 357017 357033
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/k/Tensordot/Reshape_grad/Reshape 484246 484255
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_1/Shape 201495 201503
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/add_grad/Reshape 476815 476825
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/GatherNd_grad/Shape 155092 155100
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_grad/Sum 993914 993926
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Prod_1 225735 225753
model/get_train_op/model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale/Adam_1 1532 1537
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Reshape 412023 412037
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Shape 55478 55494
model/Transformer/decode/shift_targets/strided_slice/stack_2 3547 3551
model/get_train_op/model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias/Adam 7063 7069
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/combine_heads/strided_slice_1 92148 92162
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/v/kernel/ResourceApplyAdam/ReadVariableOp 10840 10846
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/k/Tensordot_grad/Shape 173438 173447
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Prod_1 271738 271758
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_1_grad/tuple/group_deps 600208 600211
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/tuple/group_deps 998775 998778
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/div_grad/Reshape 483262 483274
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_1_grad/tuple/group_deps 1016382 1016384
model/Transformer/decoder_stack/layer_5/self_attention/self_attention/output_transform/kernel 5208 5212
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_grad/Sum 510984 510994
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/dropout/div_grad/Shape_1 4788 4792
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1 13574 13586
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/floordiv_1 193328 193338
model/get_train_op/model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel/Adam_1 3182 3190
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Shape 350997 351004
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_1_grad/Sum 1006367 1006373
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot 294916 294929
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/Reshape_grad/Reshape 626719 626732
model/get_train_op/model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_scale/Adam_1 1414 1424
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Reshape 996332 996340
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape 510275 510288
model/get_train_op/gradients/model/Transformer/decode/dropout/div_grad/Shape_1 2846 2856
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/Shape_1 4242 4247
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/floordiv_1 253082 253094
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_2/Reshape 245002 245008
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/add_grad/Sum 987758 987769
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Reshape_grad/Shape 308027 308033
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_grad/Shape 126468 126477
model/Transformer/encode/encoder_stack/layer_0/ffn/dropout/Shape 55092 55109
model/get_train_op/model/Transformer/decoder_stack/layer_2/self_attention/self_attention/k/kernel/Adam 1247 1252
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/v/Tensordot 349724 349730
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/Maximum_1 323099 323108
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/add_grad/Sum_1 509657 509663
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Prod 40022 40044
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_1/Reshape 202122 202129
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1 13471 13483
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/sub_grad/Shape_1 400409 400416
model/get_train_op/model/Transformer/encoder_stack/layer_4/self_attention/self_attention/k/kernel/Adam 6873 6877
model/get_train_op/model/Transformer/decoder_stack/layer_4/self_attention/self_attention/v/kernel/Adam 1935 1942
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/Prod 322755 322765
model/get_train_op/gradients/model/Transformer/encode/dropout/mul_grad/Shape 19790 19803
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_1/Reshape 314956 314963
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Prod 165494 165507
model/get_train_op/train/AssignVariableOp 1021372 1021381
model/get_train_op/model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias/Adam_1 1769 1774
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/floordiv_1 393473 393497
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape 1000734 1000746
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/v/Tensordot_grad/Reshape 482894 482921
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/Maximum/y 4573 4578
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/add_grad/Shape_1 18229 18242
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot_grad/Reshape 508496 508508
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Shape 98861 98870
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/add_grad/Sum_1 496759 496770
model/get_train_op/model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias/Adam 1787 1794
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/transpose_1 15551 15563
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_1_grad/Shape 253573 253587
model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale 3422 3426
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/concat_2 111477 111493
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/mul_grad/Sum 997374 997383
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/BroadcastGradientArgs 138895 138929
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_2/Reshape 279981 279986
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/floordiv 44994 45026
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot_grad/Reshape 996543 996552
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/add_grad/Reshape 472658 472667
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp_1 13097 13103
model/get_train_op/model/Transformer/encoder_stack/layer_1/self_attention/self_attention/output_transform/kernel/Adam_1 5947 5955
model/get_train_op/model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale/Adam 1805 1813
model/get_train_op/gradients/Cast 3025 3032
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_1/Reshape 24100 24113
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Prod_1 181747 181758
model/get_train_op/model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias/Adam 586 594
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/dropout/Shape 263377 263385
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/combine_heads/Reshape/shape 256855 256866
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_1_grad/Shape_1 5747 5752
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape 993198 993207
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/attention_weights_grad/Sum/reduction_indices 5061 5066
model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias 5489 5494
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Shape 330733 330742
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/dropout/div_grad/Sum 514676 514683
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/dropout/div_grad/Sum 503425 503434
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/mul_grad/Reshape 997400 997409
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/v/Tensordot/ReadVariableOp 9811 9821
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/add_grad/Sum 996429 996437
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/k/Tensordot 384809 384815
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/Reshape_grad/Reshape 503562 503575
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_1/Shape 201568 201574
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/dropout/div_grad/Shape 153741 153751
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/add_grad/Shape_1 39355 39370
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Prod_1 71614 71631
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/Prod 193422 193436
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Shape 147263 147270
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Maximum 297930 297956
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/strided_slice_1 182533 182550
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/v/Tensordot_grad/Reshape 970860 970873
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/dropout/div_grad/Reshape 598629 598639
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Shape 26534 26548
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Prod_1 138464 138484
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/dropout/div_grad/Shape 342043 342049
model/Transformer/decode/decoder_stack/layer_1/self_attention/dropout/Shape 252524 252534
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_2/Reshape/shape 24164 24186
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/combine_heads/Reshape 326722 326730
model/get_train_op/model/Transformer/decoder_stack/layer_2/encdec_attention/attention/k/kernel/Adam 1005 1014
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/dropout/div_grad/Shape_1 6361 6366
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp_1 13783 13789
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/ReadVariableOp_4 1021043 1021053
model/Transformer/decode/presoftmax_linear/Reshape_1 413293 413300
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1 13009 13019
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/dropout/div_grad/BroadcastGradientArgs 98632 98650
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_grad/BroadcastGradientArgs 41778 41800
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Reshape 990339 990349
model/get_train_op/model/Transformer/decoder_stack/layer_5/encdec_attention/attention/q/kernel/Adam 1980 1988
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp 12190 12195
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp 12328 12339
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_2/strided_slice_1 201684 201695
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape 998606 998617
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Reshape 98473 98484
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_1_grad/Shape_1 4911 4917
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Maximum 279438 279467
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot 181326 181337
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Prod_1 109507 109523
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/floordiv_1 138680 138697
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Shape 182433 182442
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/BroadcastGradientArgs 111285 111303
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_2/Reshape/shape 384974 384984
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot 40743 40757
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/v/Tensordot/transpose_1 16438 16449
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/sub_grad/Shape_1 237481 237496
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/add_grad/Shape 137891 137900
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_grad/Shape_1 6400 6404
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/add_grad/BroadcastGradientArgs 291043 291058
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/k/Tensordot 63111 63118
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Prod_1 172949 172966
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Prod 20337 20360
model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias 5596 5604
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/dropout/div_grad/Shape_1 6670 6674
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1 13114 13123
model/get_train_op/model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_scale/Adam_1 439 448
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/combine_heads/Reshape_grad/Reshape 503650 503663
model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias 327 333
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1 13493 13499
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_1/Reshape/shape 24044 24058
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Shape 228472 228482
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot 23783 23800
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Prod_1 52666 52686
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Shape_1 7016 7025
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/combine_heads/strided_slice 203539 203553
model/get_train_op/model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias/Adam_1 3245 3250
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Shape_1 4464 4469
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_1_grad/Reshape 505796 505806
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/add_grad/Shape 71388 71397
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_grad/BroadcastGradientArgs 182150 182175
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads/strided_slice_1 384874 384884
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads/Shape 118313 118323
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_1_grad/Reshape 1014924 1014935
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/mul_grad/Shape 50512 50530
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Maximum_1 127068 127079
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Reshape_grad/Shape 56748 56761
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_grad/Shape 307641 307653
model/get_train_op/model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias/Adam 6502 6506
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/transpose_1 16160 16166
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp_1 14222 14234
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_1_grad/BroadcastGradientArgs 401004 401018
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/stack 392391 392415
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/concat_2 351118 351133
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Maximum_1 166072 166083
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1 14098 14109
model/get_train_op/model/Transformer/encoder_stack/layer_3/self_attention/self_attention/v/kernel/Adam_1 6641 6645
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape 1010430 1010443
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/concat_2 358417 358448
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Reshape 489656 489668
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_grad/Reshape_1 491900 491926
model/get_train_op/learning_rate/ToFloat 7538 7543
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/add_grad/Shape_1 342229 342238
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/BroadcastGradientArgs 22265 22317
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/dropout/div_grad/Sum 1010246 1010252
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape 490481 490498
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_grad/Reshape 1001364 1001372
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape 501386 501399
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp 12777 12786
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/dropout/div_grad/Reshape 990942 990954
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Shape 181951 181962
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1 342426 342431
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Shape 400838 400846
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Prod_1 145403 145428
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/sub_grad/Shape 287658 287667
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/floordiv 297961 297975
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/ReadVariableOp 8013 8019
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_grad/BroadcastGradientArgs 260959 260987
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_1_grad/Sum 491281 491300
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Reshape 470788 470803
model/get_train_op/model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias/Adam 6117 6121
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_2/Shape 201522 201529
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/mul_grad/Sum 472126 472134
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Shape 174816 174823
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Maximum_1 181882 181892
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/sub_grad/Shape_1 260500 260515
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_1_grad/Reshape 513888 513898
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/floordiv_1 154815 154830
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Shape 182295 182306
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1 14588 14598
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/dropout/div_grad/Sum 481926 481936
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1 13932 13943
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot_grad/Shape 82302 82315
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Shape 22144 22157
model/get_train_op/model/Transformer/encoder_stack/layer_0/self_attention/self_attention/q/kernel/Adam 3326 3330
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/dropout/div_grad/Reshape 476606 476616
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/add_grad/Reshape 631170 631181
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/add_grad/Shape_1 272259 272270
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1 14691 14701
model/get_train_op/model/Transformer/decoder_stack/layer_4/self_attention/self_attention/k/kernel/Adam 1864 1873
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Square_grad/Const 492226 492236
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Prod_1 22721 22735
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/add_grad/Sum_1 1004993 1004998
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot_grad/Shape 314729 314741
model/Transformer/encoder_stack/layer_5/self_attention/self_attention/v/kernel 5360 5364
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot_grad/Shape 287363 287376
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/div_grad/Reshape 472448 472461
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/sub_grad/Reshape_1 503151 503161
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/add_grad/Shape_1 18279 18292
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/Prod_1 399686 399703
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/Reshape 360388 360397
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_1_grad/Reshape_1 491369 491382
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1 14842 14852
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_grad/Shape_1 56338 56350
model/Transformer/decoder_stack/layer_1/encdec_attention/attention/v/kernel 3753 3758
model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias 5423 5427
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/k/Tensordot/transpose_1 15610 15619
model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_1/ReadVariableOp 9540 9552
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/mul_grad/Shape 315072 315082
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_grad/Shape_1 4508 4512
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/Reshape_grad/Shape 326739 326746
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/add_grad/Sum_1 1001741 1001747
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/combine_heads/strided_slice_1 174753 174766
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/mul_grad/Reshape 627670 627682
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape 1002780 1002791
model/get_train_op/model/Transformer/decoder_stack/layer_3/encdec_attention/attention/q/kernel/Adam_1 1348 1356
model/get_train_op/model/Transformer/decoder_stack/layer_5/encdec_attention/attention/v/kernel/Adam 2000 2008
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp 11600 11611
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/mul_grad/Sum 513222 513229
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/dropout/div_grad/Reshape 995053 995063
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/mul_grad/Shape_1 361294 361302
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp_1 13804 13809
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/floordiv 117879 117892
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/dropout/div_grad/Reshape 515735 515744
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/combine_heads/Reshape/shape 246040 246051
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1 237602 237609
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/k/Tensordot_grad/Reshape 1013900 1013922
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_2/Reshape 118503 118510
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/concat_2 166575 166595
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/re_add_padding/Reshape_grad/Shape 54978 54999
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/Shape 323341 323347
model/get_train_op/model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale/Adam_1 895 903
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/Maximum 360202 360227
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_1/strided_slice_1 173551 173561
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_2/Reshape/shape 244971 244981
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/dropout/div_grad/BroadcastGradientArgs 298307 298321
model/get_train_op/model/Transformer/decoder_stack/layer_3/encdec_attention/attention/output_transform/kernel/Adam 1317 1327
model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias 6417 6422
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice/stack_1 6063 6067
model/Transformer/decoder_stack/layer_3/self_attention/self_attention/q/kernel 5445 5449
model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias 3679 3684
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_1_grad/Shape_1 39624 39641
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape 1000489 1000502
model/Transformer/decoder_stack/layer_4/self_attention/self_attention/k/kernel 5377 5382
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Maximum_1 330396 330407
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp 11089 11094
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/floordiv 145466 145488
FunctionBufferingResource 195 230
model/get_train_op/model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias/Adam 775 785
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice 127435 127448
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/floordiv 332899 332920
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_1/Reshape/shape 146008 146019
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/transpose_1 16326 16335
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp 11248 11257
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/strided_slice 26511 26531
model/get_train_op/model/Transformer/encoder_stack/layer_2/self_attention/self_attention/k/kernel/Adam 6241 6245
model/get_train_op/model/Transformer/decoder_stack/layer_3/self_attention/self_attention/q/kernel/Adam_1 1597 1602
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_1_grad/Reshape_1 1001353 1001361
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/ReadVariableOp 9921 9934
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/transpose_1 16373 16384
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_grad/BroadcastGradientArgs 193145 193167
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp_1 15026 15034
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/dropout/div_grad/Shape_1 5007 5011
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp 12770 12775
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Shape 165730 165743
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/mul_grad/Sum 1013925 1013932
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_1/strided_slice_1 118398 118409
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/combine_heads/Reshape/shape 203569 203581
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_grad/Shape_1 4388 4392
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Reshape 252377 252391
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/div_grad/Shape 256343 256353
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_grad/Shape 193230 193246
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/k/Tensordot/ReadVariableOp 10281 10291
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1 13560 13572
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/ExpandDims 99855 99864
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/attention_weights_grad/Sum/reduction_indices 4539 4544
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Prod_1 237564 237582
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/mul_grad/Reshape 988608 988620
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp_1 13663 13673
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/ReadVariableOp 10367 10375
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_2/Shape 201576 201583
model/Transformer/encoder_stack/layer_1/self_attention/self_attention/q/kernel 3910 3915
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/dropout/div_grad/BroadcastGradientArgs 110060 110078
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp 12932 12942
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/mul_grad/BroadcastGradientArgs 146893 146915
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/floordiv 200853 200862
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_grad/Sum 989755 989765
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/add_grad/Sum_1 1006860 1006866
model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_1/ReadVariableOp 9994 10000
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/Reshape 290483 290493
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/ReadVariableOp 10002 10008
model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_1/ReadVariableOp 7652 7664
model/Transformer/encode/embedding_shared_weights/embedding_1/ExpandDims 16860 16869
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/Maximum/y 4091 4097
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/v/Tensordot_grad/Shape 23775 23792
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_grad/tuple/group_deps 1006362 1006365
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/floordiv_1 400816 400828
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_1_grad/Reshape 1000794 1000804
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/mul_grad/Reshape 1013038 1013047
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_1/strided_slice_1 201760 201770
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/add_grad/Reshape 506494 506503
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot_grad/Reshape 990985 990997
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/dropout/div_grad/Shape_1 4437 4441
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Reshape 263171 263182
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs 83646 83672
model/get_train_op/model/Transformer/decoder_stack/layer_3/encdec_attention/attention/output_transform/kernel/Adam_1 1329 1337
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp_1 15047 15058
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/sub_1_grad/Shape_1 357594 357601
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Shape 403551 403559
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1 13835 13844
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/k/Tensordot/transpose_1 16413 16423
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/transpose_1 15652 15663
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/ReadVariableOp 9663 9675
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1 14151 14161
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_1_grad/tuple/group_deps 474217 474220
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_2/strided_slice 118424 118436
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/tuple/group_deps 508777 508780
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot_grad/Shape 260105 260116
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Prod 272669 272681
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/v/Tensordot_grad/Reshape 1007823 1007833
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Prod_1 244342 244357
model/get_train_op/model/Transformer/decoder_stack/layer_2/encdec_attention/attention/q/kernel/Adam_1 1062 1069
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/mul_grad/BroadcastGradientArgs 119417 119428
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/ReadVariableOp 9065 9072
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/re_add_padding/Squeeze_grad/Shape 109878 109891
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_2/Reshape 202166 202172
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Shape_1 3294 3302
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/combine_heads/Shape 26351 26372
