_SOURCE	model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale	model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias	model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias	model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias	model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale	model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias	model/Transformer/encoder_stack/layer_1/self_attention/self_attention/k/kernel	model/get_train_op/model/Transformer/decoder_stack/layer_0/encdec_attention/attention/k/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_0/encdec_attention/attention/k/kernel/Adam_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/transpose_1_grad/InvertPermutation	model/get_train_op/model/Transformer/decoder_stack/layer_0/encdec_attention/attention/output_transform/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_0/encdec_attention/attention/output_transform/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_0/encdec_attention/attention/q/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_0/encdec_attention/attention/q/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_0/encdec_attention/attention/v/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_0/encdec_attention/attention/v/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_bias/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_scale/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_0/self_attention/self_attention/k/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_0/self_attention/self_attention/k/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_0/self_attention/self_attention/output_transform/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_0/self_attention/self_attention/output_transform/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_0/self_attention/self_attention/q/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_0/self_attention/self_attention/q/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_0/self_attention/self_attention/v/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_0/self_attention/self_attention/v/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_1/encdec_attention/attention/k/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_1/encdec_attention/attention/k/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_1/encdec_attention/attention/output_transform/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_1/encdec_attention/attention/output_transform/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_1/encdec_attention/attention/q/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_1/encdec_attention/attention/q/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_1/encdec_attention/attention/v/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_1/encdec_attention/attention/v/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_bias/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_scale/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_1/self_attention/self_attention/k/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_1/self_attention/self_attention/k/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_1/self_attention/self_attention/output_transform/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_1/self_attention/self_attention/output_transform/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_1/self_attention/self_attention/q/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_1/self_attention/self_attention/q/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_1/self_attention/self_attention/v/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_1/self_attention/self_attention/v/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_2/encdec_attention/attention/k/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_2/encdec_attention/attention/k/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_2/encdec_attention/attention/output_transform/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_2/encdec_attention/attention/output_transform/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_2/encdec_attention/attention/q/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_2/encdec_attention/attention/q/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_2/encdec_attention/attention/v/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_2/encdec_attention/attention/v/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_bias/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_scale/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_2/self_attention/self_attention/k/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_2/self_attention/self_attention/k/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_2/self_attention/self_attention/output_transform/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_2/self_attention/self_attention/output_transform/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_2/self_attention/self_attention/q/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_2/self_attention/self_attention/q/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_2/self_attention/self_attention/v/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_2/self_attention/self_attention/v/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_3/encdec_attention/attention/k/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_3/encdec_attention/attention/k/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_3/encdec_attention/attention/output_transform/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_3/encdec_attention/attention/output_transform/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_3/encdec_attention/attention/q/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_3/encdec_attention/attention/q/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_3/encdec_attention/attention/v/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_3/encdec_attention/attention/v/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_bias/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_scale/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_3/self_attention/self_attention/k/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_3/self_attention/self_attention/k/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_3/self_attention/self_attention/output_transform/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_3/self_attention/self_attention/output_transform/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_3/self_attention/self_attention/q/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_3/self_attention/self_attention/q/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_3/self_attention/self_attention/v/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_3/self_attention/self_attention/v/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_4/encdec_attention/attention/k/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_4/encdec_attention/attention/k/kernel/Adam_1	model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_scale	model/get_train_op/model/Transformer/decoder_stack/layer_4/encdec_attention/attention/output_transform/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_4/encdec_attention/attention/output_transform/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_4/encdec_attention/attention/q/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_4/encdec_attention/attention/q/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_4/encdec_attention/attention/v/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_4/encdec_attention/attention/v/kernel/Adam_1	model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_bias	model/get_train_op/model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_bias/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_scale/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_4/self_attention/self_attention/k/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_4/self_attention/self_attention/k/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_4/self_attention/self_attention/output_transform/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_4/self_attention/self_attention/output_transform/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_4/self_attention/self_attention/q/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_4/self_attention/self_attention/q/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_4/self_attention/self_attention/v/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_4/self_attention/self_attention/v/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_5/encdec_attention/attention/k/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_5/encdec_attention/attention/k/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_5/encdec_attention/attention/output_transform/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_5/encdec_attention/attention/output_transform/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_5/encdec_attention/attention/q/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_5/encdec_attention/attention/q/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_5/encdec_attention/attention/v/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_5/encdec_attention/attention/v/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_bias/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_scale/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_5/self_attention/self_attention/k/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_5/self_attention/self_attention/k/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_5/self_attention/self_attention/output_transform/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_5/self_attention/self_attention/output_transform/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_5/self_attention/self_attention/q/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_5/self_attention/self_attention/q/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_5/self_attention/self_attention/v/kernel/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_5/self_attention/self_attention/v/kernel/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_normalization/layer_norm_bias/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/model/Transformer/decoder_stack/layer_normalization/layer_norm_scale/Adam	model/get_train_op/model/Transformer/decoder_stack/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/sub/x	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/sub_2	model/get_train_op/model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/Adam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_2/transpose_grad/InvertPermutation	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/v/Tensordot/transpose_grad/InvertPermutation	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/mod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/Fill	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/attention_weights_grad/Sum/reduction_indices	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_grad/Shape_1	model/Transformer/decoder_stack/layer_3/encdec_attention/attention/k/kernel	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Maximum/y	model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Maximum/y	model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias	model/get_train_op/gradients/model/Transformer/decode/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/shift_targets/Pad_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/Gather_grad/strided_slice/stack	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/Gather_grad/strided_slice/stack_1	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/Gather_grad/concat/axis	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_grad/Shape_1	model/Transformer/encoder_stack/layer_1/self_attention/self_attention/v/kernel	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/encode/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/Gather_grad/strided_slice/stack	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/Gather_grad/strided_slice/stack_1	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/Gather_grad/concat/axis	model/get_train_op/gradients/concat/axis	model/get_train_op/gradients/Cast	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/strided_slice/stack	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/sub_3	model/get_train_op/model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/model/Transformer/encoder_stack/layer_0/self_attention/self_attention/k/kernel/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_0/self_attention/self_attention/k/kernel/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_0/self_attention/self_attention/output_transform/kernel/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_0/self_attention/self_attention/output_transform/kernel/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_0/self_attention/self_attention/q/kernel/Adam	_SINK	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/dropout/div_grad/RealDiv_recip	model/Transformer/encoder_stack/layer_3/self_attention/self_attention/q/kernel	model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel	model/Transformer/decoder_stack/layer_0/encdec_attention/attention/output_transform/kernel	model/Transformer/decoder_stack/layer_0/encdec_attention/attention/q/kernel	model/Transformer/decoder_stack/layer_0/self_attention/self_attention/output_transform/kernel	model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale	model/Transformer/decoder_stack/layer_0/self_attention/self_attention/q/kernel	model/Transformer/encoder_stack/layer_3/self_attention/self_attention/k/kernel	model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias	model/Transformer/decoder_stack/layer_0/self_attention/self_attention/k/kernel	model/Transformer/decode/decoder_self_attention_bias/mul/x	model/Transformer/decode/decoder_self_attention_bias/MatrixBandPart/num_lower	model/Transformer/decode/decoder_self_attention_bias/MatrixBandPart/num_upper	model/Transformer/decode/decoder_self_attention_bias/Reshape/shape/0	model/Transformer/encoder_stack/layer_3/self_attention/self_attention/v/kernel	model/Transformer/decoder_stack/layer_0/self_attention/self_attention/v/kernel	ConstantFolding/model/get_train_op/learning_rate/truediv_recip	model/Transformer/encode/embedding_shared_weights/embedding_1/ExpandDims/dim	model/Transformer/encode/embedding_shared_weights/embedding_1/mul_1/y	model/Transformer/decode/shift_targets/Pad/paddings	model/Transformer/decode/shift_targets/strided_slice/stack	model/Transformer/decode/shift_targets/strided_slice/stack_1	model/Transformer/decode/shift_targets/strided_slice/stack_2	model/Transformer/decode/add_pos_encoding/ExpandDims_1	model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel	model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add/y	model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale	model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias	model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/combine_heads/strided_slice_1/stack_1	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/combine_heads/Reshape/shape/2	model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_scale	model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_bias	model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias	model/Transformer/decoder_stack/layer_0/encdec_attention/attention/k/kernel	model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale	model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias	model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias	model/Transformer/decoder_stack/layer_0/encdec_attention/attention/v/kernel	model/Transformer/encoder_stack/layer_2/self_attention/self_attention/output_transform/kernel	model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale	model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Const_2	model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias	model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias	model/Transformer/encoder_stack/layer_2/self_attention/self_attention/q/kernel	model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale	model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias	model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale	model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias	model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_scale	model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_bias	model/Transformer/encoder_stack/layer_2/self_attention/self_attention/k/kernel	model/Transformer/decoder_stack/layer_1/encdec_attention/attention/k/kernel	model/Transformer/decoder_stack/layer_1/encdec_attention/attention/v/kernel	model/Transformer/encoder_stack/layer_2/self_attention/self_attention/v/kernel	model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel	model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale	model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias	model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias	model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale	model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias	model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel	model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias	model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale	model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias	model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias	model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_scale	model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_bias	model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias	model/Transformer/decoder_stack/layer_2/encdec_attention/attention/k/kernel	model/Transformer/encoder_stack/layer_1/self_attention/self_attention/output_transform/kernel	model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale	model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias	model/Transformer/decoder_stack/layer_2/encdec_attention/attention/v/kernel	model/Transformer/encoder_stack/layer_1/self_attention/self_attention/q/kernel	IteratorToStringHandle/_3415	IteratorGetDevice/_3417	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/GatherV2_1/_3465	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/GatherV2/_3467	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/GatherV2/_3469	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/GatherV2_1/_3477	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/GatherV2/_3479	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/GatherV2/_3481	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/GatherV2_1/_3491	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/GatherV2/_3493	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/GatherV2/_3495	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/GatherV2_1/_3497	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/GatherV2/_3499	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/GatherV2/_3501	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/GatherV2_1/_3537	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/GatherV2/_3539	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/GatherV2/_3541	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2_1/_3549	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2/_3551	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2/_3553	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/GatherV2_1/_3561	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/GatherV2/_3563	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/GatherV2/_3565	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/GatherV2_1/_3585	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/GatherV2/_3587	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/GatherV2/_3589	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/GatherV2/_3597	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/GatherV2/_3599	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/GatherV2_1/_3601	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2_1/_3621	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2/_3623	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2/_3625	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/GatherV2_1/_3633	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/GatherV2/_3635	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/GatherV2/_3637	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/GatherV2_1/_3657	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/GatherV2/_3659	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/GatherV2/_3661	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/GatherV2/_3669	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/GatherV2/_3671	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/GatherV2_1/_3673	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2_1/_3693	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2/_3695	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2/_3697	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/GatherV2_1/_3705	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/GatherV2/_3707	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/GatherV2/_3709	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/GatherV2_1/_3729	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/GatherV2/_3731	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/GatherV2/_3733	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/GatherV2_1/_3741	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/GatherV2/_3743	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/GatherV2/_3745	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2_1/_3765	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2/_3767	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2/_3769	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/GatherV2_1/_3777	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/GatherV2/_3779	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/GatherV2/_3781	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/GatherV2_1/_3801	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/GatherV2/_3803	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/GatherV2/_3805	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/GatherV2_1/_3813	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/GatherV2/_3815	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/GatherV2/_3817	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2_1/_3837	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2/_3839	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2/_3841	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/GatherV2_1/_3849	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/GatherV2/_3851	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/GatherV2/_3853	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/GatherV2_1/_3873	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/GatherV2/_3875	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/GatherV2/_3877	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/GatherV2/_3885	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/GatherV2/_3887	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/GatherV2_1/_3889	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2_1/_3909	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2/_3911	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2/_3913	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/GatherV2_1/_3921	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/GatherV2/_3923	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/GatherV2/_3925	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/GatherV2_1/_3945	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/GatherV2/_3947	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/GatherV2/_3949	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/GatherV2_1/_3957	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/GatherV2/_3959	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/GatherV2/_3961	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2_1/_3981	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2/_3983	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2/_3985	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/GatherV2_1/_3993	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/GatherV2/_3995	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/GatherV2/_3997	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/GatherV2_1/_4017	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/GatherV2/_4019	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/GatherV2/_4021	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/GatherV2_1/_4029	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/GatherV2/_4031	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/GatherV2/_4033	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/GatherV2_1/_4053	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/GatherV2/_4055	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/GatherV2/_4057	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/GatherV2_1/_4065	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/GatherV2/_4067	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/GatherV2/_4069	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2_1/_4089	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2/_4091	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2/_4093	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/GatherV2_1/_4101	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/GatherV2/_4103	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/GatherV2/_4105	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/GatherV2_1/_4125	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/GatherV2/_4127	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/GatherV2/_4129	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/GatherV2_1/_4137	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/GatherV2/_4139	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/GatherV2/_4141	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/GatherV2_1/_4161	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/GatherV2/_4163	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/GatherV2/_4165	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/GatherV2_1/_4173	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/GatherV2/_4175	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/GatherV2/_4177	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2/_4197	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2/_4199	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2_1/_4201	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/GatherV2/_4209	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/GatherV2/_4211	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/GatherV2_1/_4213	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/GatherV2_1/_4233	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/GatherV2/_4235	model/get_train_op/train/beta2	model/get_train_op/train/epsilon	model/Transformer/encoder_stack/layer_0/self_attention/self_attention/q/kernel	model/Transformer/decoder_stack/layer_4/encdec_attention/attention/v/kernel	model/get_train_op/gradients/model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits_grad/ExpandDims/dim	model/get_train_op/gradients/model/Sum_grad/Reshape/shape	model/get_train_op/gradients/model/loss/smoothing_cross_entropy/sub_grad/Shape_1	model/get_train_op/gradients/model/loss/pad_to_same_length/Pad_grad/Slice/begin	model/get_train_op/gradients/model/loss/pad_to_same_length/Pad_grad/stack	model/get_train_op/gradients/model/loss/pad_to_same_length/Pad_grad/Reshape/shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/attention_weights_grad/Sum/reduction_indices	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/mul_grad/Shape_1	model/Transformer/encoder_stack/layer_0/self_attention/self_attention/k/kernel	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/Maximum/y	model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale	model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/attention_weights_grad/Sum/reduction_indices	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_grad/Shape_1	model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_grad/Shape_1	model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Maximum/y	model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/attention_weights_grad/Sum/reduction_indices	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_grad/Shape_1	model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/Maximum/y	model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale	model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/attention_weights_grad/Sum/reduction_indices	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_grad/Shape_1	model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/attention_weights_grad/Sum/reduction_indices	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/attention_weights_grad/Sum/reduction_indices	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_grad/Shape_1	model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_scale	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Maximum/y	model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_bias	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/dropout/div_grad/Shape_1	model/Transformer/encoder_stack/layer_0/self_attention/self_attention/v/kernel	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/attention_weights_grad/Sum/reduction_indices	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/Maximum/y	model/Transformer/decoder_stack/layer_5/encdec_attention/attention/k/kernel	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/Maximum/y	model/Transformer/embedding_shared_weights/embedding_and_softmax/weights	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/dropout/div_grad/Shape_1	model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/attention_weights_grad/Sum/reduction_indices	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/attention_weights_grad/Sum/reduction_indices	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/Maximum/y	model/Transformer/decoder_stack/layer_5/encdec_attention/attention/v/kernel	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/attention_weights_grad/Sum/reduction_indices	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Maximum/y	model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Maximum/y	model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/dropout/div_grad/Shape_1	model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/attention_weights_grad/Sum/reduction_indices	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_1_grad/Shape_1	model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/concat/values_0	model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/concat/axis	model/loss/smoothing_cross_entropy/one_hot/depth	model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias	model/loss/pad_to_same_length/Pad/paddings/0_1	model/loss/smoothing_cross_entropy/truediv	model/loss/smoothing_cross_entropy/Neg	model/Transformer/decode/presoftmax_linear/Reshape/shape	model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias	model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel	model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel	model/Transformer/decoder_stack/layer_5/encdec_attention/attention/output_transform/kernel	model/Transformer/decoder_stack/layer_normalization/layer_norm_scale	model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias	model/Transformer/decoder_stack/layer_5/encdec_attention/attention/q/kernel	model/Transformer/decoder_stack/layer_normalization/layer_norm_bias	model/Transformer/decoder_stack/layer_5/self_attention/self_attention/output_transform/kernel	model/Transformer/decoder_stack/layer_5/self_attention/self_attention/q/kernel	model/Transformer/encoder_stack/layer_5/self_attention/self_attention/output_transform/kernel	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Const_2	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads/Reshape/shape/2	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads/Reshape/shape/3	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/mul/y	model/Transformer/decoder_stack/layer_5/self_attention/self_attention/k/kernel	model/Transformer/encoder_stack/layer_5/self_attention/self_attention/q/kernel	model/Transformer/decoder_stack/layer_5/self_attention/self_attention/v/kernel	model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel	model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel	model/Transformer/decoder_stack/layer_4/encdec_attention/attention/output_transform/kernel	model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale	model/Transformer/encoder_stack/layer_5/self_attention/self_attention/k/kernel	model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias	model/Transformer/decoder_stack/layer_4/encdec_attention/attention/q/kernel	model/Transformer/decoder_stack/layer_4/self_attention/self_attention/output_transform/kernel	model/Transformer/decoder_stack/layer_4/self_attention/self_attention/q/kernel	model/Transformer/encoder_stack/layer_5/self_attention/self_attention/v/kernel	model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale	model/Transformer/decoder_stack/layer_4/self_attention/self_attention/k/kernel	model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias	model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel	model/Transformer/decoder_stack/layer_4/self_attention/self_attention/v/kernel	model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel	model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel	model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel	model/Transformer/decoder_stack/layer_3/encdec_attention/attention/output_transform/kernel	model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias	model/Transformer/decoder_stack/layer_3/encdec_attention/attention/q/kernel	model/Transformer/decoder_stack/layer_3/self_attention/self_attention/output_transform/kernel	model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias	model/Transformer/decoder_stack/layer_3/self_attention/self_attention/q/kernel	model/Transformer/encoder_stack/layer_4/self_attention/self_attention/output_transform/kernel	model/Transformer/decoder_stack/layer_3/self_attention/self_attention/k/kernel	model/Transformer/encoder_stack/layer_4/self_attention/self_attention/q/kernel	model/Transformer/decoder_stack/layer_3/self_attention/self_attention/v/kernel	model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel	model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale	model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel	model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias	model/Transformer/decoder_stack/layer_2/encdec_attention/attention/output_transform/kernel	model/Transformer/decoder_stack/layer_2/encdec_attention/attention/q/kernel	model/Transformer/decoder_stack/layer_2/self_attention/self_attention/output_transform/kernel	model/Transformer/encoder_stack/layer_4/self_attention/self_attention/k/kernel	model/Transformer/decoder_stack/layer_2/self_attention/self_attention/q/kernel	model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale	model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias	model/Transformer/decoder_stack/layer_2/self_attention/self_attention/k/kernel	model/Transformer/encoder_stack/layer_4/self_attention/self_attention/v/kernel	model/Transformer/decoder_stack/layer_2/self_attention/self_attention/v/kernel	model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel	model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel	model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel	model/Transformer/decoder_stack/layer_1/encdec_attention/attention/output_transform/kernel	model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel	model/Transformer/decoder_stack/layer_1/encdec_attention/attention/q/kernel	model/Transformer/decoder_stack/layer_1/self_attention/self_attention/output_transform/kernel	model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias	model/Transformer/decoder_stack/layer_1/self_attention/self_attention/q/kernel	model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias	model/Transformer/decoder_stack/layer_1/self_attention/self_attention/k/kernel	model/Transformer/encoder_stack/layer_3/self_attention/self_attention/output_transform/kernel	model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale	model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias	model/Transformer/decoder_stack/layer_1/self_attention/self_attention/v/kernel	model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/GatherV2/_4237	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/GatherV2/_4245	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/GatherV2/_4247	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/GatherV2_1/_4249	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/GatherV2/_4269	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/GatherV2/_4271	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/GatherV2_1/_4273	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/GatherV2/_4281	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/GatherV2/_4283	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/GatherV2_1/_4285	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2/_4305	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2/_4307	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2_1/_4309	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/GatherV2/_4317	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/GatherV2/_4319	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/GatherV2_1/_4321	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/GatherV2_1/_4341	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/GatherV2/_4343	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/GatherV2/_4345	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/GatherV2/_4353	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/GatherV2/_4355	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/GatherV2_1/_4357	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/GatherV2/_4377	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/GatherV2/_4379	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/GatherV2_1/_4381	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/GatherV2/_4389	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/GatherV2/_4391	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/GatherV2_1/_4393	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2/_4413	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2/_4415	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2_1/_4417	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/GatherV2/_4425	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/GatherV2/_4427	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/GatherV2_1/_4429	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/GatherV2_1/_4449	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/GatherV2/_4451	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/GatherV2/_4453	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/GatherV2/_4461	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/GatherV2/_4463	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/GatherV2_1/_4465	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/GatherV2/_4485	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/GatherV2/_4487	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/GatherV2_1/_4489	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/GatherV2/_4497	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/GatherV2/_4499	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/GatherV2_1/_4501	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2/_4521	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2/_4523	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2_1/_4525	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/GatherV2/_4533	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/GatherV2/_4535	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/GatherV2_1/_4537	model/loss/pad_to_same_length/Pad_1/_4559	_SINK	model/get_train_op/model/Transformer/encoder_stack/layer_0/self_attention/self_attention/q/kernel/Adam_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/attention_weights_grad/Sum/reduction_indices	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/mul_grad/Shape_1	model/get_train_op/model/Transformer/encoder_stack/layer_0/self_attention/self_attention/v/kernel/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_0/self_attention/self_attention/v/kernel/Adam_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Maximum/y	model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Maximum/y	model/Transformer/decoder_stack/layer_3/encdec_attention/attention/v/kernel	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice/stack	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice/stack_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/dropout/div_grad/Shape_1	model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel	model/get_train_op/model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/model/Transformer/encoder_stack/layer_1/self_attention/self_attention/k/kernel/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_1/self_attention/self_attention/k/kernel/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_1/self_attention/self_attention/output_transform/kernel/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_1/self_attention/self_attention/output_transform/kernel/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_1/self_attention/self_attention/q/kernel/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_1/self_attention/self_attention/q/kernel/Adam_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/attention_weights_grad/Sum/reduction_indices	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/mul_grad/Shape_1	model/get_train_op/model/Transformer/encoder_stack/layer_1/self_attention/self_attention/v/kernel/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_1/self_attention/self_attention/v/kernel/Adam_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice/stack	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice/stack_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Maximum/y	model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/dropout/div_grad/Shape_1	model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias	model/get_train_op/model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/model/Transformer/encoder_stack/layer_2/self_attention/self_attention/k/kernel/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_2/self_attention/self_attention/k/kernel/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_2/self_attention/self_attention/output_transform/kernel/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_2/self_attention/self_attention/output_transform/kernel/Adam_1	model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias	model/get_train_op/model/Transformer/encoder_stack/layer_2/self_attention/self_attention/q/kernel/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_2/self_attention/self_attention/q/kernel/Adam_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/attention_weights_grad/Sum/reduction_indices	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/mul_grad/Shape_1	model/get_train_op/model/Transformer/encoder_stack/layer_2/self_attention/self_attention/v/kernel/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_2/self_attention/self_attention/v/kernel/Adam_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/dropout/div_grad/Shape_1	model/Transformer/encoder_stack/layer_normalization/layer_norm_scale	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice/stack	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice/stack_1	model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Maximum/y	model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/dropout/div_grad/Shape_1	model/get_train_op/model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale/Adam_1	model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/model/Transformer/encoder_stack/layer_3/self_attention/self_attention/k/kernel/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_3/self_attention/self_attention/k/kernel/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_3/self_attention/self_attention/output_transform/kernel/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_3/self_attention/self_attention/output_transform/kernel/Adam_1	model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias	model/get_train_op/model/Transformer/encoder_stack/layer_3/self_attention/self_attention/q/kernel/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_3/self_attention/self_attention/q/kernel/Adam_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/attention_weights_grad/Sum/reduction_indices	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/mul_grad/Shape_1	model/get_train_op/model/Transformer/encoder_stack/layer_3/self_attention/self_attention/v/kernel/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_3/self_attention/self_attention/v/kernel/Adam_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Maximum/y	model/Transformer/encoder_stack/layer_normalization/layer_norm_bias	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice/stack	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice/stack_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Maximum/y	model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/dropout/div_grad/Shape_1	model/get_train_op/model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/model/Transformer/encoder_stack/layer_4/self_attention/self_attention/k/kernel/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_4/self_attention/self_attention/k/kernel/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_4/self_attention/self_attention/output_transform/kernel/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_4/self_attention/self_attention/output_transform/kernel/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_4/self_attention/self_attention/q/kernel/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_4/self_attention/self_attention/q/kernel/Adam_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/attention_weights_grad/Sum/reduction_indices	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/mul_grad/Shape_1	model/get_train_op/model/Transformer/encoder_stack/layer_4/self_attention/self_attention/v/kernel/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_4/self_attention/self_attention/v/kernel/Adam_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Maximum/y	model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_scale	model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_bias	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice/stack	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice/stack_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/dropout/div_grad/Shape_1	model/get_train_op/model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale/Adam_1	model/Transformer/encoder_stack/layer_0/self_attention/self_attention/output_transform/kernel	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/model/Transformer/encoder_stack/layer_5/self_attention/self_attention/k/kernel/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_5/self_attention/self_attention/k/kernel/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_5/self_attention/self_attention/output_transform/kernel/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_5/self_attention/self_attention/output_transform/kernel/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_5/self_attention/self_attention/q/kernel/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_5/self_attention/self_attention/q/kernel/Adam_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/attention_weights_grad/Sum/reduction_indices	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/mul_grad/Shape_1	model/get_train_op/model/Transformer/encoder_stack/layer_5/self_attention/self_attention/v/kernel/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_5/self_attention/self_attention/v/kernel/Adam_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/Maximum/y	model/Transformer/decoder_stack/layer_4/encdec_attention/attention/k/kernel	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice/stack	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice/stack_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/dropout/div_grad/Shape_1	model/get_train_op/model/Transformer/encoder_stack/layer_normalization/layer_norm_bias/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/model/Transformer/encoder_stack/layer_normalization/layer_norm_scale/Adam	model/get_train_op/model/Transformer/encoder_stack/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/beta1_power	model/get_train_op/beta2_power	model/get_train_op/learning_rate/mul/x	global_step	model/get_train_op/learning_rate/ToFloat	model/get_train_op/train/beta1	
_SINK	
model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale	model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias	model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/BiasAdd/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/BiasAdd/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale	model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias	model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_1/self_attention/self_attention/k/kernel	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/k/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_0/encdec_attention/attention/k/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/k/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_0/encdec_attention/attention/k/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/k/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/transpose_1_grad/InvertPermutation	model/Sum_1	model/Sum	
model/get_train_op/model/Transformer/decoder_stack/layer_0/encdec_attention/attention/output_transform/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_0/encdec_attention/attention/output_transform/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_0/encdec_attention/attention/q/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/q/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_0/encdec_attention/attention/q/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/q/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_0/encdec_attention/attention/v/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/v/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_0/encdec_attention/attention/v/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/v/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_bias/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_scale/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_0/self_attention/self_attention/k/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_0/self_attention/self_attention/k/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_0/self_attention/self_attention/output_transform/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_0/self_attention/self_attention/output_transform/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_0/self_attention/self_attention/q/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_0/self_attention/self_attention/q/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_0/self_attention/self_attention/v/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_0/self_attention/self_attention/v/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_1/encdec_attention/attention/k/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/k/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_1/encdec_attention/attention/k/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/k/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_1/encdec_attention/attention/output_transform/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_1/encdec_attention/attention/output_transform/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_1/encdec_attention/attention/q/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/q/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_1/encdec_attention/attention/q/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/q/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_1/encdec_attention/attention/v/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/v/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_1/encdec_attention/attention/v/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/v/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_bias/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_scale/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_1/self_attention/self_attention/k/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_1/self_attention/self_attention/k/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_1/self_attention/self_attention/output_transform/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_1/self_attention/self_attention/output_transform/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_1/self_attention/self_attention/q/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_1/self_attention/self_attention/q/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_1/self_attention/self_attention/v/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_1/self_attention/self_attention/v/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_2/encdec_attention/attention/k/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/k/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_2/encdec_attention/attention/k/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/k/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_2/encdec_attention/attention/output_transform/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_2/encdec_attention/attention/output_transform/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_2/encdec_attention/attention/q/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/q/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_2/encdec_attention/attention/q/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/q/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_2/encdec_attention/attention/v/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/v/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_2/encdec_attention/attention/v/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/v/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_bias/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_scale/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_2/self_attention/self_attention/k/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_2/self_attention/self_attention/k/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_2/self_attention/self_attention/output_transform/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_2/self_attention/self_attention/output_transform/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_2/self_attention/self_attention/q/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_2/self_attention/self_attention/q/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_2/self_attention/self_attention/v/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_2/self_attention/self_attention/v/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_3/encdec_attention/attention/k/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/k/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_3/encdec_attention/attention/k/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/k/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_3/encdec_attention/attention/output_transform/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_3/encdec_attention/attention/output_transform/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_3/encdec_attention/attention/q/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/q/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_3/encdec_attention/attention/q/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/q/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_3/encdec_attention/attention/v/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/v/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_3/encdec_attention/attention/v/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/v/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_bias/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_scale/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_3/self_attention/self_attention/k/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_3/self_attention/self_attention/k/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_3/self_attention/self_attention/output_transform/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_3/self_attention/self_attention/output_transform/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_3/self_attention/self_attention/q/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_3/self_attention/self_attention/q/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_3/self_attention/self_attention/v/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_3/self_attention/self_attention/v/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_4/encdec_attention/attention/k/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/k/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_4/encdec_attention/attention/k/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/k/kernel/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_scale	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_4/encdec_attention/attention/output_transform/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_4/encdec_attention/attention/output_transform/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_4/encdec_attention/attention/q/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/q/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_4/encdec_attention/attention/q/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/q/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_4/encdec_attention/attention/v/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/v/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_4/encdec_attention/attention/v/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/v/kernel/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_bias	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_bias/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_scale/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_4/self_attention/self_attention/k/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_4/self_attention/self_attention/k/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_4/self_attention/self_attention/output_transform/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_4/self_attention/self_attention/output_transform/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_4/self_attention/self_attention/q/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_4/self_attention/self_attention/q/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_4/self_attention/self_attention/v/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_4/self_attention/self_attention/v/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_5/encdec_attention/attention/k/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/k/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_5/encdec_attention/attention/k/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/k/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_5/encdec_attention/attention/output_transform/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_5/encdec_attention/attention/output_transform/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_5/encdec_attention/attention/q/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/q/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_5/encdec_attention/attention/q/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/q/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_5/encdec_attention/attention/v/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/v/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_5/encdec_attention/attention/v/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/v/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_bias/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_scale/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_5/self_attention/self_attention/k/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_5/self_attention/self_attention/k/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_5/self_attention/self_attention/output_transform/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_5/self_attention/self_attention/output_transform/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_5/self_attention/self_attention/q/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_5/self_attention/self_attention/q/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_5/self_attention/self_attention/v/kernel/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_5/self_attention/self_attention/v/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_normalization/layer_norm_bias/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_normalization/layer_norm_scale/Adam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/decoder_stack/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/sub/x	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/random_uniform/mul	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/random_uniform/mul	model/Transformer/decode/decoder_self_attention_bias/ones	model/Transformer/decode/decoder_self_attention_bias/sub	model/Transformer/encode/dropout/random_uniform/mul	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/random_uniform/mul	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/random_uniform/mul	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/random_uniform/mul	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/random_uniform/mul	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/sub_1	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/sub	model/get_train_op/learning_rate/Minimum	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/random_uniform/mul	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/random_uniform/mul	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/random_uniform/mul	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/random_uniform/mul	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/random_uniform/mul	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/random_uniform/mul	
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/sub_2	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/mul_1	
model/get_train_op/model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/Adam	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/AssignVariableOp	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/ReadVariableOp_3	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/ResourceScatterAdd	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/ReadVariableOp_4	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_2/transpose_grad/InvertPermutation	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads/transpose_grad/transpose	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads/transpose	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_1/transpose	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_2/transpose	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/combine_heads/transpose	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads/transpose	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_1/transpose	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_2/transpose	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/combine_heads/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/combine_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_2/transpose_grad/transpose	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_1/transpose	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_2/transpose	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads/transpose	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/combine_heads/transpose	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads/transpose	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_1/transpose	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_2/transpose	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/combine_heads/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/combine_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/combine_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/combine_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/combine_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/combine_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_2/transpose_grad/transpose	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads/transpose	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/combine_heads/transpose	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads/transpose	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_1/transpose	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_2/transpose	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_1/transpose	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_2/transpose	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_1/transpose	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_2/transpose	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_1/transpose	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_2/transpose	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_1/transpose	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_2/transpose	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_1/transpose	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_2/transpose	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/combine_heads/transpose	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads/transpose	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_1/transpose	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_2/transpose	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/combine_heads/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/combine_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads/transpose_grad/transpose	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads/transpose	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_1/transpose	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_2/transpose	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads/transpose	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/combine_heads/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads/transpose_grad/transpose	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/combine_heads/transpose	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads/transpose	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_1/transpose	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_2/transpose	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/combine_heads/transpose	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/combine_heads/transpose	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads/transpose	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/combine_heads/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/combine_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/combine_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/combine_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/combine_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/combine_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/combine_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/combine_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/combine_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads/transpose_grad/transpose	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads/transpose	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_1/transpose	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_2/transpose	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/combine_heads/transpose	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/combine_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads/transpose_grad/transpose	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads/transpose	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_1/transpose	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_2/transpose	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/combine_heads/transpose	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads/transpose	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/combine_heads/transpose	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads/transpose	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_1/transpose	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_2/transpose	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads/transpose	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_1/transpose	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_2/transpose	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/combine_heads/transpose	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/combine_heads/transpose	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads/transpose	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_1/transpose	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_2/transpose	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/combine_heads/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/combine_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/combine_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads/transpose_grad/transpose	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/v/Tensordot/transpose_grad/InvertPermutation	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/mul_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/mod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads/strided_slice_1	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_1/strided_slice_1	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/combine_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_1/strided_slice_1	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_1/strided_slice_1	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_1/strided_slice_1	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_1/strided_slice_1	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_1/strided_slice_1	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_1/strided_slice_1	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_1/strided_slice_1	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/combine_heads/strided_slice_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_1/strided_slice_1	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads/strided_slice_1	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/combine_heads/strided_slice_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/DynamicStitch	model/Transformer/decode/add_pos_encoding/strided_slice	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads/strided_slice_1	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_1/strided_slice_1	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/combine_heads/strided_slice_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/DynamicStitch	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/strided_slice_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads/strided_slice_1	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_1/strided_slice_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/DynamicStitch	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/strided_slice_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/combine_heads/strided_slice_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/DynamicStitch	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/strided_slice_1	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads/strided_slice_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/combine_heads/strided_slice_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_1/strided_slice_1	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/combine_heads/strided_slice_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads/strided_slice_1	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_1/strided_slice_1	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_2/strided_slice_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/combine_heads/strided_slice_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/DynamicStitch	model/loss/pad_to_same_length/strided_slice_1	model/Transformer/encode/add_pos_encoding/strided_slice	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/combine_heads/strided_slice_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/DynamicStitch	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/strided_slice_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_1/strided_slice_1	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/combine_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/combine_heads/strided_slice_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/combine_heads/strided_slice_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/DynamicStitch	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/combine_heads/strided_slice_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/DynamicStitch	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/strided_slice_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_1/strided_slice_1	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_1/strided_slice_1	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/combine_heads/strided_slice_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/combine_heads/strided_slice_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/combine_heads/strided_slice_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/DynamicStitch	model/Transformer/decode/presoftmax_linear/strided_slice_1	model/loss/pad_to_same_length/strided_slice	model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/Slice	model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/Slice_2	model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/Slice_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/mod/_3460	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads/strided_slice_1	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_1/strided_slice_1	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_1/strided_slice_1	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/combine_heads/strided_slice_1	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/combine_heads/strided_slice_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/DynamicStitch	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/strided_slice_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/Fill	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads/strided_slice_1	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads/strided_slice_1	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_1/strided_slice_1	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_1/strided_slice_1	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/combine_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_1/strided_slice_1	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_1/strided_slice_1	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_1/strided_slice_1	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_1/strided_slice_1	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_1/strided_slice_1	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_1/strided_slice_1	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_1/strided_slice_1	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_1/strided_slice_1	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_1/strided_slice_1	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_1/strided_slice_1	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_1/strided_slice_1	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_1/strided_slice_1	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_1/strided_slice_1	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_1/strided_slice_1	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/combine_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_1/strided_slice_1	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_1/strided_slice_1	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads/strided_slice_1	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads/strided_slice_1	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/combine_heads/strided_slice_1	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/decode/add_pos_encoding/strided_slice	model/Transformer/decode/add_pos_encoding/strided_slice	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/Fill/_3434	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads/strided_slice_1	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads/strided_slice_1	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_1/strided_slice_1	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_1/strided_slice_1	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/combine_heads/strided_slice_1	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/strided_slice_1	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/strided_slice_1	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/strided_slice	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/strided_slice	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads/strided_slice_1	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads/strided_slice_1	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_1/strided_slice_1	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/strided_slice_1	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/strided_slice_1	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/strided_slice	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/strided_slice	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/combine_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/combine_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/combine_heads/strided_slice_1	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/strided_slice	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/strided_slice	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/strided_slice_1	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/strided_slice_1	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/combine_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/combine_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/combine_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_1/strided_slice_1	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_1/strided_slice_1	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/combine_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads/strided_slice_1	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads/strided_slice_1	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_1/strided_slice_1	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_1/strided_slice_1	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/combine_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/combine_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/combine_heads/strided_slice	model/loss/pad_to_same_length/strided_slice_1	model/loss/pad_to_same_length/strided_slice_1	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/strided_slice	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/strided_slice	model/Transformer/encode/add_pos_encoding/strided_slice	model/Transformer/encode/add_pos_encoding/strided_slice	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/combine_heads/strided_slice_1	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/strided_slice	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/strided_slice	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/strided_slice_1	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/strided_slice_1	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_1/strided_slice_1	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_1/strided_slice_1	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/combine_heads/strided_slice_1	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/combine_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/combine_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/combine_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/combine_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/combine_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/combine_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/combine_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/combine_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/strided_slice	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/strided_slice	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/strided_slice_1	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/strided_slice_1	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_1/strided_slice_1	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_1/strided_slice_1	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_1/strided_slice_1	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_1/strided_slice_1	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/combine_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/combine_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/combine_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/combine_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/combine_heads/strided_slice	model/Transformer/decode/presoftmax_linear/strided_slice	model/Transformer/decode/presoftmax_linear/strided_slice	model/Transformer/decode/presoftmax_linear/strided_slice_1	model/Transformer/decode/presoftmax_linear/strided_slice_1	model/loss/pad_to_same_length/strided_slice	model/loss/pad_to_same_length/strided_slice	model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/Slice	model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/Slice_1	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads/strided_slice_1	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads/strided_slice_1	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_1/strided_slice_1	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_1/strided_slice_1	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_1/strided_slice_1	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_1/strided_slice_1	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_1/strided_slice_1	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/combine_heads/strided_slice_1	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/strided_slice_1	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/strided_slice_1	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/strided_slice	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/strided_slice	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/attention_weights_grad/Sum/reduction_indices	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/attention_weights_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/mul_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_grad/BroadcastGradientArgs	
model/Transformer/decoder_stack/layer_3/encdec_attention/attention/k/kernel	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/k/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/k/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Maximum_1	
model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale	model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Maximum_1	
model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias	model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/shift_targets/Pad_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/shift_targets/Pad_grad/Slice_1	
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/mul_1_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/Gather_grad/strided_slice/stack	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/Gather_grad/strided_slice	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/Gather_grad/strided_slice	
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/Gather_grad/strided_slice/stack_1	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/Gather_grad/strided_slice	
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/Gather_grad/concat/axis	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/Gather_grad/ExpandDims	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/Gather_grad/concat	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_grad/BroadcastGradientArgs	
model/Transformer/encoder_stack/layer_1/self_attention/self_attention/v/kernel	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/v/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/encode/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/mul_1_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/Gather_grad/strided_slice/stack	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/Gather_grad/strided_slice	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/Gather_grad/strided_slice	
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/Gather_grad/strided_slice/stack_1	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/Gather_grad/strided_slice	
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/Gather_grad/concat/axis	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/Gather_grad/ExpandDims	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/Gather_grad/concat	
model/get_train_op/gradients/concat/axis	model/get_train_op/gradients/concat_1	model/get_train_op/gradients/concat	
model/get_train_op/gradients/Cast	model/get_train_op/gradients/concat_1	
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/strided_slice/stack	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Prod	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Prod	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Prod	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Prod	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Prod	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/strided_slice	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Prod	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Prod	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Prod	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/strided_slice	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Prod	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/combine_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/Prod	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/strided_slice	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/Prod	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/combine_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Prod	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Prod	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/combine_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/Prod_1	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/strided_slice	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Prod	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/strided_slice	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Prod	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/combine_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/combine_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/strided_slice	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Prod	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/combine_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Prod_1	model/Transformer/decode/presoftmax_linear/strided_slice	model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/Slice_2	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Prod	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Prod	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/strided_slice	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Prod	
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/sub_3	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/mul_3	
model/get_train_op/model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/Adam_1	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/AssignVariableOp_1	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/ReadVariableOp_6	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/ResourceScatterAdd_1	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/ReadVariableOp_7	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/ReadVariableOp_5	
model/get_train_op/model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/model/Transformer/encoder_stack/layer_0/self_attention/self_attention/k/kernel/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_0/self_attention/self_attention/k/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_0/self_attention/self_attention/output_transform/kernel/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_0/self_attention/self_attention/output_transform/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_0/self_attention/self_attention/q/kernel/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_0/self_attention/self_attention/q/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/attention_weights_grad/Sum/reduction_indices	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/attention_weights_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/mul_grad/BroadcastGradientArgs	
model/get_train_op/model/Transformer/encoder_stack/layer_0/self_attention/self_attention/v/kernel/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_0/self_attention/self_attention/v/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Maximum_1	
model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Maximum_1	
model/Transformer/decoder_stack/layer_3/encdec_attention/attention/v/kernel	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/v/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/v/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice/stack	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice/stack_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/dropout/div_grad/BroadcastGradientArgs	
model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/model/Transformer/encoder_stack/layer_1/self_attention/self_attention/k/kernel/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_1/self_attention/self_attention/k/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_1/self_attention/self_attention/output_transform/kernel/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_1/self_attention/self_attention/output_transform/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_1/self_attention/self_attention/q/kernel/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_1/self_attention/self_attention/q/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/attention_weights_grad/Sum/reduction_indices	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/attention_weights_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/mul_grad/BroadcastGradientArgs	
model/get_train_op/model/Transformer/encoder_stack/layer_1/self_attention/self_attention/v/kernel/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_1/self_attention/self_attention/v/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice/stack	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice/stack_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Maximum_1	
model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale	model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/dropout/div_grad/BroadcastGradientArgs	
model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias	model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/model/Transformer/encoder_stack/layer_2/self_attention/self_attention/k/kernel/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_2/self_attention/self_attention/k/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_2/self_attention/self_attention/output_transform/kernel/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_2/self_attention/self_attention/output_transform/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/BiasAdd/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_2/self_attention/self_attention/q/kernel/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_2/self_attention/self_attention/q/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/attention_weights_grad/Sum/reduction_indices	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/attention_weights_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/mul_grad/BroadcastGradientArgs	
model/get_train_op/model/Transformer/encoder_stack/layer_2/self_attention/self_attention/v/kernel/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_2/self_attention/self_attention/v/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/dropout/div_grad/BroadcastGradientArgs	
model/Transformer/encoder_stack/layer_normalization/layer_norm_scale	model/Transformer/encode/encoder_stack/layer_normalization/mul_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice/stack	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice/stack_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice	
model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/BiasAdd/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Maximum_1	
model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/BiasAdd/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale	model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/model/Transformer/encoder_stack/layer_3/self_attention/self_attention/k/kernel/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_3/self_attention/self_attention/k/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_3/self_attention/self_attention/output_transform/kernel/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_3/self_attention/self_attention/output_transform/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias	model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_3/self_attention/self_attention/q/kernel/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_3/self_attention/self_attention/q/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/attention_weights_grad/Sum/reduction_indices	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/attention_weights_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/mul_grad/BroadcastGradientArgs	
model/get_train_op/model/Transformer/encoder_stack/layer_3/self_attention/self_attention/v/kernel/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_3/self_attention/self_attention/v/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Maximum_1	
model/Transformer/encoder_stack/layer_normalization/layer_norm_bias	model/Transformer/encode/encoder_stack/layer_normalization/add_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice/stack	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice/stack_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Maximum_1	
model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/BiasAdd/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/model/Transformer/encoder_stack/layer_4/self_attention/self_attention/k/kernel/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_4/self_attention/self_attention/k/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_4/self_attention/self_attention/output_transform/kernel/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_4/self_attention/self_attention/output_transform/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_4/self_attention/self_attention/q/kernel/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_4/self_attention/self_attention/q/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/attention_weights_grad/Sum/reduction_indices	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/attention_weights_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/mul_grad/BroadcastGradientArgs	
model/get_train_op/model/Transformer/encoder_stack/layer_4/self_attention/self_attention/v/kernel/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_4/self_attention/self_attention/v/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Maximum_1	
model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_scale	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_bias	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice/stack	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice/stack_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_0/self_attention/self_attention/output_transform/kernel	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/model/Transformer/encoder_stack/layer_5/self_attention/self_attention/k/kernel/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_5/self_attention/self_attention/k/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_5/self_attention/self_attention/output_transform/kernel/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_5/self_attention/self_attention/output_transform/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_5/self_attention/self_attention/q/kernel/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_5/self_attention/self_attention/q/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/attention_weights_grad/Sum/reduction_indices	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/attention_weights_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/mul_grad/BroadcastGradientArgs	
model/get_train_op/model/Transformer/encoder_stack/layer_5/self_attention/self_attention/v/kernel/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_5/self_attention/self_attention/v/kernel/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/add_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/Maximum	
model/Transformer/decoder_stack/layer_4/encdec_attention/attention/k/kernel	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/k/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/k/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/Maximum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice/stack	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice/stack_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Maximum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Maximum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/model/Transformer/encoder_stack/layer_normalization/layer_norm_bias/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_normalization/layer_norm_bias/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_normalization/layer_norm_scale/Adam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/model/Transformer/encoder_stack/layer_normalization/layer_norm_scale/Adam_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/beta1_power	model/get_train_op/train/AssignVariableOp	model/get_train_op/train/ReadVariableOp_1	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/k/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/q/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/v/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/k/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/q/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/v/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/k/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/q/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/v/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/k/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/q/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/v/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/k/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/q/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/v/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/k/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/q/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/v/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	
model/get_train_op/beta2_power	model/get_train_op/train/ReadVariableOp_2	model/get_train_op/train/AssignVariableOp_1	model/get_train_op/train/ReadVariableOp_3	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp_1	
model/get_train_op/learning_rate/mul/x	model/get_train_op/learning_rate/mul	
global_step	Identity/ReadVariableOp	model/get_train_op/learning_rate/ToFloat_1/ReadVariableOp	model/get_train_op/train/AssignAddVariableOp	
model/get_train_op/learning_rate/ToFloat	model/get_train_op/learning_rate/Maximum	
model/get_train_op/train/beta1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/Transformer/encode/encoder_stack/layer_3/ffn/dropout/add	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/add	model/get_train_op/train/mul	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/dropout/add	model/Transformer/decode/decoder_stack/layer_5/self_attention/dropout/add	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/add	model/Transformer/encode/encoder_stack/layer_1/self_attention/dropout/add	model/Transformer/encode/dropout/add	model/Transformer/decode/dropout/add	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/add	model/Transformer/encode/encoder_stack/layer_5/self_attention/dropout/add	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/dropout/add	model/Transformer/encode/encoder_stack/layer_1/ffn/dropout/add	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/dropout/add	model/Transformer/encode/encoder_stack/layer_5/ffn/dropout/add	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/v/kernel/ResourceApplyAdam	model/Transformer/decode/decoder_stack/layer_1/self_attention/dropout/add	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/add	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/dropout/add	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/dropout/add	model/Transformer/encode/encoder_stack/layer_0/ffn/dropout/add	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/add	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/dropout/add	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/dropout/add	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/mul_2	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/dropout/add	model/Transformer/decode/decoder_stack/layer_1/ffn/dropout/add	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/dropout/add	model/Transformer/decode/decoder_stack/layer_3/self_attention/dropout/add	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/dropout/add	model/Transformer/encode/encoder_stack/layer_2/ffn/dropout/add	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/add	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/dropout/add	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/add	model/Transformer/encode/encoder_stack/layer_3/self_attention/dropout/add	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/dropout/add	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/dropout/add	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/dropout/add	model/Transformer/decode/decoder_stack/layer_4/ffn/dropout/add	model/Transformer/decode/decoder_stack/layer_0/ffn/dropout/add	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/dropout/add	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/Transformer/encode/encoder_stack/layer_0/self_attention/dropout/add	model/Transformer/decode/decoder_stack/layer_0/self_attention/dropout/add	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/add	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/dropout/add	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/dropout/add	model/Transformer/decode/decoder_stack/layer_2/ffn/dropout/add	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/add	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/dropout/add	model/Transformer/encode/encoder_stack/layer_4/self_attention/dropout/add	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/dropout/add	model/Transformer/encode/encoder_stack/layer_4/ffn/dropout/add	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/dropout/add	model/Transformer/decode/decoder_stack/layer_3/ffn/dropout/add	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/dropout/add	model/Transformer/decode/decoder_stack/layer_2/self_attention/dropout/add	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/dropout/add	model/Transformer/decode/decoder_stack/layer_4/self_attention/dropout/add	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/add	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/dropout/add	model/Transformer/decode/decoder_stack/layer_5/ffn/dropout/add	model/loss/smoothing_cross_entropy/one_hot	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/add	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/dropout/add	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/add	model/Transformer/encode/encoder_stack/layer_2/self_attention/dropout/add	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/beta2	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/mul_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/mul_5	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/epsilon	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/Less	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/add	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_0/self_attention/self_attention/q/kernel	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_4/encdec_attention/attention/v/kernel	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/v/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/v/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits_grad/ExpandDims/dim	model/get_train_op/gradients/model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits_grad/ExpandDims	
model/get_train_op/gradients/model/Sum_grad/Reshape/shape	model/get_train_op/gradients/model/Sum_grad/Reshape	
model/get_train_op/gradients/model/loss/smoothing_cross_entropy/sub_grad/Shape_1	model/get_train_op/gradients/model/loss/smoothing_cross_entropy/sub_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/loss/pad_to_same_length/Pad_grad/Slice/begin	model/get_train_op/gradients/model/loss/pad_to_same_length/Pad_grad/Slice	
model/get_train_op/gradients/model/loss/pad_to_same_length/Pad_grad/stack	model/get_train_op/gradients/model/loss/pad_to_same_length/Pad_grad/Slice	
model/get_train_op/gradients/model/loss/pad_to_same_length/Pad_grad/Reshape/shape	model/get_train_op/gradients/model/loss/pad_to_same_length/Pad_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/add_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/attention_weights_grad/Sum/reduction_indices	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/attention_weights_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/mul_grad/BroadcastGradientArgs	
model/Transformer/encoder_stack/layer_0/self_attention/self_attention/k/kernel	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/k/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/Maximum_1	
model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale	model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias	model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/attention_weights_grad/Sum/reduction_indices	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/attention_weights_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/mul_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_grad/BroadcastGradientArgs	
model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/BiasAdd/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_grad/BroadcastGradientArgs	
model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale	model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Maximum	
model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/BiasAdd/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Maximum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/attention_weights_grad/Sum/reduction_indices	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/attention_weights_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/mul_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_grad/BroadcastGradientArgs	
model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias	model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/Maximum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/Maximum	
model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale	model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias	model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/attention_weights_grad/Sum/reduction_indices	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/attention_weights_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/mul_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Maximum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Maximum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_grad/BroadcastGradientArgs	
model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/BiasAdd/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Maximum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Maximum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/attention_weights_grad/Sum/reduction_indices	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/attention_weights_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/mul_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/Maximum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/Maximum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/attention_weights_grad/Sum/reduction_indices	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/attention_weights_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/mul_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_grad/BroadcastGradientArgs	
model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_scale	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Maximum	
model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_bias	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Maximum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Maximum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Maximum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/dropout/div_grad/BroadcastGradientArgs	
model/Transformer/encoder_stack/layer_0/self_attention/self_attention/v/kernel	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/v/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/attention_weights_grad/Sum/reduction_indices	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/attention_weights_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/mul_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/Maximum_1	
model/Transformer/decoder_stack/layer_5/encdec_attention/attention/k/kernel	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/k/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/k/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/Maximum_1	
model/Transformer/embedding_shared_weights/embedding_and_softmax/weights	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/Gather_grad/VariableShape	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/Gather_grad/VariableShape	model/Transformer/decode/presoftmax_linear/MatMul/ReadVariableOp	model/Transformer/encode/embedding_shared_weights/embedding/Gather	model/Transformer/encode/embedding_shared_weights/embedding_1/Gather	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/AssignSubVariableOp	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/ReadVariableOp_8	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/dropout/div_grad/BroadcastGradientArgs	
model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/BiasAdd/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/attention_weights_grad/Sum/reduction_indices	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/attention_weights_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/mul_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/attention_weights_grad/Sum/reduction_indices	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/attention_weights_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/mul_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/Maximum_1	
model/Transformer/decoder_stack/layer_5/encdec_attention/attention/v/kernel	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/v/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/v/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/attention_weights_grad/Sum/reduction_indices	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/attention_weights_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/mul_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Maximum_1	
model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Maximum/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Maximum_1	
model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/dropout/div_grad/BroadcastGradientArgs	
model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale	model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/div_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/div_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/attention_weights_grad/Sum/reduction_indices	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/attention_weights_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/add_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_1_grad/Reshape_1	
model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/concat/values_0	model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean	model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1	model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean	model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1	model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean	model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean	model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1	model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1	model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1	model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean	model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean	model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1	model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1	model/Transformer/encode/encoder_stack/layer_normalization/Mean	model/Transformer/encode/encoder_stack/layer_normalization/Mean_1	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1	model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean	model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean	model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1	model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean	model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1	model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1	model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean	model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1	model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean	model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean	model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1	model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean	model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/Reshape	model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean	model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1	model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean	model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1	model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean	model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1	model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean	model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1	model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean	model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1	model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean	model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1	model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean	model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean	model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1	model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean	model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1	model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean	model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean	model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1	model/Transformer/decode/decoder_stack/layer_normalization/Mean	model/Transformer/decode/decoder_stack/layer_normalization/Mean_1	model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/concat	model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/concat_1	model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean	model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1	
model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/concat/axis	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/concat_2	model/Transformer/decode/add_pos_encoding/range	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/ExpandDims	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/ExpandDims	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/ExpandDims	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/concat_2	model/Transformer/encode/add_pos_encoding/range	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/ExpandDims	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/ExpandDims	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/concat_2	model/loss/pad_to_same_length/Pad/paddings/1	model/loss/pad_to_same_length/Pad_1/paddings/1	model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/concat	model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/concat_1	model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/concat/axis/_3462	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/ExpandDims	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/concat_2	
model/loss/smoothing_cross_entropy/one_hot/depth	model/Transformer/decode/presoftmax_linear/Reshape_1/shape	model/loss/smoothing_cross_entropy/one_hot	
model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias	model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/loss/pad_to_same_length/Pad/paddings/0_1	model/loss/pad_to_same_length/Pad/paddings	model/loss/pad_to_same_length/Pad/paddings	model/loss/pad_to_same_length/Pad_1/paddings	
model/loss/smoothing_cross_entropy/truediv	model/loss/smoothing_cross_entropy/one_hot	
model/loss/smoothing_cross_entropy/Neg	model/loss/smoothing_cross_entropy/sub	
model/Transformer/decode/presoftmax_linear/Reshape/shape	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/Reshape_1	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/Reshape_1	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/Reshape_1	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/Reshape_1	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/Reshape_1	model/Transformer/decode/presoftmax_linear/Reshape	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/Reshape_1	
model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/BiasAdd/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_5/encdec_attention/attention/output_transform/kernel	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_normalization/layer_norm_scale	model/Transformer/decode/decoder_stack/layer_normalization/mul_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/BiasAdd/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_5/encdec_attention/attention/q/kernel	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/q/kernel/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_normalization/layer_norm_bias	model/Transformer/decode/decoder_stack/layer_normalization/add_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_5/self_attention/self_attention/output_transform/kernel	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_5/self_attention/self_attention/q/kernel	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_5/self_attention/self_attention/output_transform/kernel	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Const_2	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/concat_2	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads/Reshape/shape/2	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads/Reshape/shape	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_1/Reshape/shape	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_2/Reshape/shape	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_1/Reshape/shape	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_2/Reshape/shape	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_1/Reshape/shape	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_2/Reshape/shape	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_1/Reshape/shape	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_2/Reshape/shape	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_1/Reshape/shape	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_2/Reshape/shape	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_1/Reshape/shape	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_2/Reshape/shape	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_1/Reshape/shape	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_2/Reshape/shape	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_1/Reshape/shape	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_2/Reshape/shape	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_1/Reshape/shape	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_2/Reshape/shape	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads/Reshape/shape	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads/Reshape/shape	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_1/Reshape/shape	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_2/Reshape/shape	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_1/Reshape/shape	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_2/Reshape/shape	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads/Reshape/shape	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_1/Reshape/shape	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_2/Reshape/shape	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_1/Reshape/shape	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_2/Reshape/shape	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_1/Reshape/shape	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_2/Reshape/shape	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_1/Reshape/shape	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_2/Reshape/shape	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads/Reshape/shape	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads/Reshape/shape	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_1/Reshape/shape	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_2/Reshape/shape	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_1/Reshape/shape	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_2/Reshape/shape	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads/Reshape/shape	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_1/Reshape/shape	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_2/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads/Reshape/shape/3	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads/Reshape/shape	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_1/Reshape/shape	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_2/Reshape/shape	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_1/Reshape/shape	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_2/Reshape/shape	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_1/Reshape/shape	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_2/Reshape/shape	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_1/Reshape/shape	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_2/Reshape/shape	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_1/Reshape/shape	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_2/Reshape/shape	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_1/Reshape/shape	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_2/Reshape/shape	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_1/Reshape/shape	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_2/Reshape/shape	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_1/Reshape/shape	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_2/Reshape/shape	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_1/Reshape/shape	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_2/Reshape/shape	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads/Reshape/shape	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads/Reshape/shape	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_1/Reshape/shape	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_2/Reshape/shape	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_1/Reshape/shape	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_2/Reshape/shape	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads/Reshape/shape	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_1/Reshape/shape	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_2/Reshape/shape	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_1/Reshape/shape	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_2/Reshape/shape	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_1/Reshape/shape	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_2/Reshape/shape	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_1/Reshape/shape	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_2/Reshape/shape	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads/Reshape/shape	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads/Reshape/shape	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_1/Reshape/shape	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_2/Reshape/shape	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_1/Reshape/shape	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_2/Reshape/shape	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads/Reshape/shape	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_1/Reshape/shape	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_2/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/mul/y	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/mul_grad/Mul	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/mul	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/mul	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/mul	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/mul_grad/Mul	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/mul	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/mul	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/mul_grad/Mul	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/mul	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/mul_grad/Mul	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/mul	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/mul_grad/Mul	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/mul	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/mul_grad/Mul	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/mul	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/mul	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/mul	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/mul	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/mul_grad/Mul	
model/Transformer/decoder_stack/layer_5/self_attention/self_attention/k/kernel	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/k/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_5/self_attention/self_attention/q/kernel	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_5/self_attention/self_attention/v/kernel	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/v/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_4/encdec_attention/attention/output_transform/kernel	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale	model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_5/self_attention/self_attention/k/kernel	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/k/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias	model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_4/encdec_attention/attention/q/kernel	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/q/kernel/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_4/self_attention/self_attention/output_transform/kernel	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_4/self_attention/self_attention/q/kernel	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_5/self_attention/self_attention/v/kernel	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/v/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale	model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_4/self_attention/self_attention/k/kernel	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/k/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias	model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_4/self_attention/self_attention/v/kernel	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/v/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_3/encdec_attention/attention/output_transform/kernel	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/BiasAdd/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_3/encdec_attention/attention/q/kernel	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/q/kernel/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_3/self_attention/self_attention/output_transform/kernel	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/BiasAdd/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_3/self_attention/self_attention/q/kernel	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_4/self_attention/self_attention/output_transform/kernel	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_3/self_attention/self_attention/k/kernel	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/k/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_4/self_attention/self_attention/q/kernel	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_3/self_attention/self_attention/v/kernel	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/v/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale	model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias	model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_2/encdec_attention/attention/output_transform/kernel	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_2/encdec_attention/attention/q/kernel	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/q/kernel/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_2/self_attention/self_attention/output_transform/kernel	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_4/self_attention/self_attention/k/kernel	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/k/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_2/self_attention/self_attention/q/kernel	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale	model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias	model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_2/self_attention/self_attention/k/kernel	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/k/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_4/self_attention/self_attention/v/kernel	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/v/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_2/self_attention/self_attention/v/kernel	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/v/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_1/encdec_attention/attention/output_transform/kernel	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_1/encdec_attention/attention/q/kernel	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/q/kernel/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_1/self_attention/self_attention/output_transform/kernel	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/BiasAdd/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_1/self_attention/self_attention/q/kernel	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/BiasAdd/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_1/self_attention/self_attention/k/kernel	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/k/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_3/self_attention/self_attention/output_transform/kernel	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale	model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias	model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_1/self_attention/self_attention/v/kernel	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/v/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/dropout/div_grad/RealDiv_recip	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/dropout/div_grad/RealDiv	model/Transformer/encode/encoder_stack/layer_3/ffn/dropout/div	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/div	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/dropout/div	model/Transformer/decode/decoder_stack/layer_5/self_attention/dropout/div	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/dropout/div_grad/RealDiv	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/div	model/Transformer/encode/encoder_stack/layer_1/self_attention/dropout/div	model/Transformer/encode/dropout/div	model/Transformer/decode/dropout/div	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/div	model/Transformer/encode/encoder_stack/layer_5/self_attention/dropout/div	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/dropout/div	model/Transformer/encode/encoder_stack/layer_1/ffn/dropout/div	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/div_grad/RealDiv	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/dropout/div	model/Transformer/encode/encoder_stack/layer_5/ffn/dropout/div	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/dropout/div_grad/RealDiv	model/Transformer/decode/decoder_stack/layer_1/self_attention/dropout/div	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/div	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/dropout/div	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/dropout/div	model/Transformer/encode/encoder_stack/layer_0/ffn/dropout/div	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/div	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/dropout/div	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/dropout/div	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/dropout/div	model/Transformer/decode/decoder_stack/layer_1/ffn/dropout/div	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/dropout/div	model/Transformer/decode/decoder_stack/layer_3/self_attention/dropout/div	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/div_grad/RealDiv	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/dropout/div	model/Transformer/encode/encoder_stack/layer_2/ffn/dropout/div	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/div	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/div	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/dropout/div	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/dropout/div_grad/RealDiv	model/Transformer/encode/encoder_stack/layer_3/self_attention/dropout/div	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/dropout/div	model/get_train_op/gradients/model/Transformer/encode/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/dropout/div_grad/RealDiv	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/dropout/div	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/dropout/div	model/Transformer/decode/decoder_stack/layer_4/ffn/dropout/div	model/Transformer/decode/decoder_stack/layer_0/ffn/dropout/div	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/dropout/div	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/dropout/div_grad/RealDiv	model/Transformer/encode/encoder_stack/layer_0/self_attention/dropout/div	model/Transformer/decode/decoder_stack/layer_0/self_attention/dropout/div	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/div	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/dropout/div	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/dropout/div	model/Transformer/decode/decoder_stack/layer_2/ffn/dropout/div	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/div	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/dropout/div	model/Transformer/encode/encoder_stack/layer_4/self_attention/dropout/div	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/dropout/div	model/Transformer/encode/encoder_stack/layer_4/ffn/dropout/div	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/div_grad/RealDiv	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/dropout/div	model/Transformer/decode/decoder_stack/layer_3/ffn/dropout/div	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/dropout/div_grad/RealDiv	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/dropout/div	model/Transformer/decode/decoder_stack/layer_2/self_attention/dropout/div	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/dropout/div_grad/RealDiv	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/dropout/div	model/Transformer/decode/decoder_stack/layer_4/self_attention/dropout/div	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/div	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/dropout/div	model/Transformer/decode/decoder_stack/layer_5/ffn/dropout/div	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/div	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/dropout/div	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/div	model/Transformer/encode/encoder_stack/layer_2/self_attention/dropout/div	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/div_grad/RealDiv	
model/Transformer/encoder_stack/layer_3/self_attention/self_attention/q/kernel	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_0/encdec_attention/attention/output_transform/kernel	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_0/encdec_attention/attention/q/kernel	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/q/kernel/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_0/self_attention/self_attention/output_transform/kernel	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale	model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_0/self_attention/self_attention/q/kernel	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_3/self_attention/self_attention/k/kernel	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/k/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias	model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_0/self_attention/self_attention/k/kernel	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/k/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/Transformer/decode/decoder_self_attention_bias/mul/x	model/Transformer/attention_bias/mul	model/Transformer/decode/decoder_self_attention_bias/mul	
model/Transformer/decode/decoder_self_attention_bias/MatrixBandPart/num_lower	model/Transformer/decode/decoder_self_attention_bias/MatrixBandPart/num_lower/_3428	
model/Transformer/decode/decoder_self_attention_bias/MatrixBandPart/num_upper	model/Transformer/decode/decoder_self_attention_bias/MatrixBandPart/num_upper/_3430	model/Transformer/encode/padding/Equal	model/Transformer/encode/embedding_shared_weights/embedding/NotEqual	model/Transformer/encode/embedding_shared_weights/embedding_1/NotEqual	model/loss/NotEqual	
model/Transformer/decode/decoder_self_attention_bias/Reshape/shape/0	model/Transformer/encode/add_pos_encoding/ExpandDims	model/Transformer/decode/decoder_self_attention_bias/Reshape/shape	model/Transformer/decode/decoder_self_attention_bias/Reshape/shape	model/Transformer/decode/add_pos_encoding/range	model/Transformer/decode/add_pos_encoding/ExpandDims	model/Transformer/encode/add_pos_encoding/concat	model/Transformer/decode/add_pos_encoding/concat	model/Transformer/attention_bias/ExpandDims	model/Transformer/attention_bias/ExpandDims_1	model/Transformer/encode/add_pos_encoding/range	
model/Transformer/encoder_stack/layer_3/self_attention/self_attention/v/kernel	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/v/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_0/self_attention/self_attention/v/kernel	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/v/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/v/kernel/ResourceApplyAdam	
ConstantFolding/model/get_train_op/learning_rate/truediv_recip	model/get_train_op/learning_rate/truediv	
model/Transformer/encode/embedding_shared_weights/embedding_1/ExpandDims/dim	model/Transformer/encode/embedding_shared_weights/embedding/ExpandDims	model/Transformer/encode/embedding_shared_weights/embedding_1/ExpandDims	
model/Transformer/encode/embedding_shared_weights/embedding_1/mul_1/y	model/Transformer/encode/embedding_shared_weights/embedding/mul_1	model/Transformer/encode/embedding_shared_weights/embedding_1/mul_1	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/mul_1_grad/Mul	
model/Transformer/decode/shift_targets/Pad/paddings	model/Transformer/decode/shift_targets/Pad	
model/Transformer/decode/shift_targets/strided_slice/stack	model/Transformer/decode/shift_targets/strided_slice	model/get_train_op/gradients/model/Transformer/decode/shift_targets/strided_slice_grad/StridedSliceGrad	
model/Transformer/decode/shift_targets/strided_slice/stack_1	model/Transformer/decode/shift_targets/strided_slice	model/get_train_op/gradients/model/Transformer/decode/shift_targets/strided_slice_grad/StridedSliceGrad	
model/Transformer/decode/shift_targets/strided_slice/stack_2	model/Transformer/decode/shift_targets/strided_slice	model/get_train_op/gradients/model/Transformer/decode/shift_targets/strided_slice_grad/StridedSliceGrad	
model/Transformer/decode/add_pos_encoding/ExpandDims_1	model/Transformer/encode/add_pos_encoding/mul_2	model/Transformer/decode/add_pos_encoding/mul_2	
model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add/y	model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add	model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add	model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add	model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add	model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add	model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add	model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add	model/Transformer/encode/encoder_stack/layer_normalization/add	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add	model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add	model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add	model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add	model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add	model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add	model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add	model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add	model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add	model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add	model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add	model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add	model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add	model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add	model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add	model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add	model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add	model/Transformer/decode/decoder_stack/layer_normalization/add	model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add	
model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale	model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias	model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/combine_heads/strided_slice_1/stack_1	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/combine_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/combine_heads/strided_slice_1	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/combine_heads/strided_slice_1	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/combine_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/combine_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/combine_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/combine_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/combine_heads/strided_slice_1	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/combine_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/combine_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/combine_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/combine_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/combine_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/combine_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/combine_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/combine_heads/strided_slice_1	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/combine_heads/strided_slice_1	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/combine_heads/strided_slice_1	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/combine_heads/Reshape/shape/2	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/combine_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/combine_heads/Reshape/shape	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/combine_heads/Reshape/shape	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/combine_heads/Reshape/shape	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/re_add_padding/Reshape/shape	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/re_add_padding/ScatterNd/shape	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/re_add_padding/Reshape/shape	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/re_add_padding/ScatterNd/shape	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/combine_heads/Reshape/shape	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/re_add_padding/Reshape/shape	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/re_add_padding/ScatterNd/shape	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/combine_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/combine_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/combine_heads/Reshape/shape	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/combine_heads/Reshape/shape	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/re_add_padding/Reshape/shape	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/re_add_padding/ScatterNd/shape	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/combine_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/combine_heads/Reshape/shape	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/combine_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/combine_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/combine_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/combine_heads/Reshape/shape	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/re_add_padding/Reshape/shape	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/re_add_padding/ScatterNd/shape	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/combine_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/combine_heads/Reshape/shape	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/combine_heads/Reshape/shape	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/re_add_padding/Reshape/shape	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/re_add_padding/ScatterNd/shape	
model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_scale	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_bias	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/BiasAdd/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_0/encdec_attention/attention/k/kernel	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/k/kernel/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale	model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias	model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/BiasAdd/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_0/encdec_attention/attention/v/kernel	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/v/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/v/kernel/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_2/self_attention/self_attention/output_transform/kernel	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale	model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias	model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Const_2	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/concat_2	
model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/BiasAdd/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/BiasAdd/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_2/self_attention/self_attention/q/kernel	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale	model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias	model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale	model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias	model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_scale	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_bias	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_2/self_attention/self_attention/k/kernel	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/k/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_1/encdec_attention/attention/k/kernel	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/k/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/k/kernel/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_1/encdec_attention/attention/v/kernel	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/v/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/v/kernel/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_2/self_attention/self_attention/v/kernel	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/v/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale	model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias	model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/BiasAdd/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale	model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/BiasAdd/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias	model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale	model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias	model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/BiasAdd/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_scale	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_bias	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/BiasAdd/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_2/encdec_attention/attention/k/kernel	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/k/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/k/kernel/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_1/self_attention/self_attention/output_transform/kernel	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale	model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias	model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_1/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/Transformer/decoder_stack/layer_2/encdec_attention/attention/v/kernel	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/v/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/v/kernel/ResourceApplyAdam	
model/Transformer/encoder_stack/layer_1/self_attention/self_attention/q/kernel	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_1/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Mul	
model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_1/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_1	
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/BiasAdd/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/BiasAdd	
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/BiasAdd/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/BiasAdd	
model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_1/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Mul	
model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_1/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_1	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/k/Tensordot/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/k/Tensordot/transpose_1	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_1/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_1_grad/Mul	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_1/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_1	
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/ReadVariableOp_2	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/mul_2	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/k/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/k/Tensordot/transpose_1	
model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_1/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Mul	
model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_1/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_1	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/v/Tensordot/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/v/Tensordot/transpose_1	
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/ReadVariableOp_5	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/mul_5	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/transpose_1	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/v/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/v/Tensordot/transpose_1	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/transpose_1	
model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_1/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Mul	
model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_1/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_1	
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/BiasAdd/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/BiasAdd	
model/Transformer/encode/encoder_stack/layer_normalization/mul_1/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_1_grad/Mul	
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/BiasAdd/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/BiasAdd	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/BiasAdd/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/BiasAdd	
model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_1/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Mul	
model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_1/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_1	
model/Transformer/encode/encoder_stack/layer_normalization/add_1/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_normalization/add_1	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/BiasAdd/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/BiasAdd	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_1/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_1_grad/Mul	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_1/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_1	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/transpose_1	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/k/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/k/Tensordot/transpose_1	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/k/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/k/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/q/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/q/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/v/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/v/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/k/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/k/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/q/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/q/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/v/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/v/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/k/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/k/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/q/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/q/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/v/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/v/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/k/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/k/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/q/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/q/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/v/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/v/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/k/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/k/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/q/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/q/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/v/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/v/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/k/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/k/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/q/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/q/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/v/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/v/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/sub_1	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/k/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/q/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/v/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/k/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/q/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/v/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/k/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/q/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/v/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/k/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/q/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/v/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/k/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/q/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/v/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/k/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/q/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/v/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/ReadVariableOp	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/sub	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/k/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/q/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/v/kernel/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_normalization/layer_norm_bias/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_normalization/layer_norm_scale/ResourceApplyAdam/ReadVariableOp_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_normalization/layer_norm_scale/ResourceApplyAdam	
Identity/ReadVariableOp	Identity	
model/get_train_op/learning_rate/ToFloat_1/ReadVariableOp	model/get_train_op/learning_rate/ToFloat_1	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/transpose_1	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/v/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/v/Tensordot/transpose_1	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/k/Tensordot/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/k/Tensordot/transpose_1	
model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_1/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Mul	
model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_1/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_1	
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/BiasAdd/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/BiasAdd	
model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_1/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Mul	
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/BiasAdd/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/BiasAdd	
model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_1/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_1	
model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_1/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Mul	
model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_1/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_1	
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/BiasAdd/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/BiasAdd	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_1/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_1_grad/Mul	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_1/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_1	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/v/Tensordot/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/v/Tensordot/transpose_1	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/k/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/k/Tensordot/transpose_1	
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/Gather_grad/VariableShape	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/Gather_grad/strided_slice	
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/Gather_grad/VariableShape	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/Gather_grad/strided_slice	
model/Transformer/decode/presoftmax_linear/MatMul/ReadVariableOp	model/Transformer/decode/presoftmax_linear/MatMul	model/get_train_op/gradients/model/Transformer/decode/presoftmax_linear/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/BiasAdd/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/BiasAdd	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/v/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/v/Tensordot/transpose_1	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/transpose_1	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/transpose_1	
model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_1/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Mul	
model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_1/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_1	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/BiasAdd/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/BiasAdd	
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/transpose_1	
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/transpose_1	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/transpose_1	
model/Transformer/decode/decoder_stack/layer_normalization/mul_1/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_1_grad/Mul	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/BiasAdd/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/BiasAdd	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/transpose_1	
model/Transformer/decode/decoder_stack/layer_normalization/add_1/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_normalization/add_1	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/transpose_1	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/transpose_1	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/transpose_1	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/k/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/k/Tensordot/transpose_1	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/transpose_1	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/v/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/v/Tensordot/transpose_1	
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/transpose_1	
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/transpose_1	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/transpose_1	
model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_1/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Mul	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/k/Tensordot/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/k/Tensordot/transpose_1	
model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_1/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_1	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/transpose_1	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/transpose_1	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/transpose_1	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/v/Tensordot/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/v/Tensordot/transpose_1	
model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_1/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Mul	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/k/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/k/Tensordot/transpose_1	
model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_1/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_1	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/transpose_1	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/v/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/v/Tensordot/transpose_1	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/transpose_1	
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/transpose_1	
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/transpose_1	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/transpose_1	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/BiasAdd/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/BiasAdd	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/transpose_1	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/transpose_1	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/BiasAdd/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/BiasAdd	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/transpose_1	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/transpose_1	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/k/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/k/Tensordot/transpose_1	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/transpose_1	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/v/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/v/Tensordot/transpose_1	
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/transpose_1	
model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_1/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Mul	
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/transpose_1	
model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_1/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_1	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/transpose_1	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/transpose_1	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/transpose_1	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/k/Tensordot/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/k/Tensordot/transpose_1	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/transpose_1	
model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_1/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Mul	
model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_1/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_1	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/k/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/k/Tensordot/transpose_1	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/v/Tensordot/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/v/Tensordot/transpose_1	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/v/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/v/Tensordot/transpose_1	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/transpose_1	
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/transpose_1	
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/transpose_1	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/transpose_1	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/transpose_1	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/transpose_1	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/transpose_1	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/BiasAdd/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/BiasAdd	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/transpose_1	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/BiasAdd/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/BiasAdd	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/k/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/k/Tensordot/transpose_1	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/transpose_1	
model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_1/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Mul	
model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_1/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_1	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/v/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/v/Tensordot/transpose_1	
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/transpose_1	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/transpose_1	
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/transpose_1	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/transpose_1	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/transpose_1	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/transpose_1	
model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_1/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Mul	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/transpose_1	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/k/Tensordot/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/k/Tensordot/transpose_1	
model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_1/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_1	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/k/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/k/Tensordot/transpose_1	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/v/Tensordot/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/v/Tensordot/transpose_1	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/v/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/v/Tensordot/transpose_1	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/transpose_1	
model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_1/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Mul	
model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_1/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_1	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/transpose_1	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_1/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_1_grad/Mul	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_1/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_1	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/BiasAdd/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/BiasAdd	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/transpose_1	
model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_1/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Mul	
model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_1/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_1	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/BiasAdd/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/BiasAdd	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/v/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/v/Tensordot/transpose_1	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/transpose_1	
model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_1/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Mul	
model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_1/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_1	
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/BiasAdd/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/BiasAdd	
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/BiasAdd/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/BiasAdd	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/transpose_1	
model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_1/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Mul	
model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_1/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_1	
model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_1/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Mul	
model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_1/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_1	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_1/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_1_grad/Mul	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_1/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_1	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/k/Tensordot/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/k/Tensordot/transpose_1	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/k/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/k/Tensordot/transpose_1	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/v/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/v/Tensordot/transpose_1	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/v/Tensordot/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/v/Tensordot/transpose_1	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/transpose_1	
model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_1/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Mul	
model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_1/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_1	
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/BiasAdd/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/BiasAdd	
model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_1/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Mul	
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/BiasAdd/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/BiasAdd	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/transpose_1	
model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_1/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_1	
model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_1/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Mul	
model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_1/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_1	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/BiasAdd/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/BiasAdd	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_1/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_1_grad/Mul	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_1/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_1	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/BiasAdd/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/BiasAdd	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/k/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/k/Tensordot/transpose_1	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/transpose_1	
model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_1/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Mul	
model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_1/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_1	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/v/Tensordot/ReadVariableOp	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/v/Tensordot/transpose_1	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/ReadVariableOp	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/transpose_1	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/k/Tensordot/transpose_1	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/k/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul	
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/mul_2	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/AssignVariableOp	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/k/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/k/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/k/Tensordot/MatMul_grad/MatMul	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/v/Tensordot/transpose_1	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/v/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul	
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/mul_5	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/AssignVariableOp_1	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/transpose_1	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/v/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/v/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/v/Tensordot/MatMul_grad/MatMul	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/transpose_1	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/transpose_1	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/k/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/k/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/k/Tensordot/MatMul_grad/MatMul	
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/sub_1	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/truediv	
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/sub	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/Sqrt	
Identity	Identity/_4574	
model/get_train_op/learning_rate/ToFloat_1	model/get_train_op/learning_rate/truediv	model/get_train_op/learning_rate/Maximum	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/transpose_1	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/v/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/v/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/v/Tensordot/MatMul_grad/MatMul	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/k/Tensordot/transpose_1	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/k/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/v/Tensordot/transpose_1	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/v/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/k/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/k/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/k/Tensordot/MatMul_grad/MatMul	
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/Gather_grad/strided_slice	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/Gather_grad/concat	
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/Gather_grad/strided_slice	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/Gather_grad/concat	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/v/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/v/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/v/Tensordot/MatMul_grad/MatMul	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/transpose_1	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/transpose_1	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/transpose_1	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/k/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/k/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/transpose_1	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/v/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/v/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul	
IteratorToStringHandle/_3415	FunctionBufferingResource	
IteratorGetDevice/_3417	FunctionBufferingResource	
FunctionBufferingResource	FunctionBufferingResourceGetNext	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/MatMul_grad/MatMul	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/k/Tensordot/transpose_1	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/k/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/v/Tensordot/transpose_1	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/v/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/k/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/k/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/transpose_1	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/v/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/v/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/transpose_1	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/transpose_1	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/k/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/k/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/transpose_1	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/v/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/v/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/k/Tensordot/transpose_1	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/k/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/k/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/k/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/v/Tensordot/transpose_1	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/v/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/v/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/v/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/transpose_1	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/MatMul_grad/MatMul	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/transpose_1	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/k/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/k/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/transpose_1	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/v/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/v/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/transpose_1	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/k/Tensordot/transpose_1	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/k/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/k/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/k/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/v/Tensordot/transpose_1	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/v/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/v/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/v/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/transpose_1	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/transpose_1	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/v/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/v/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/v/Tensordot/MatMul_grad/MatMul	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/transpose_1	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/transpose_1	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/k/Tensordot/transpose_1	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/k/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/k/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/k/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/k/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/v/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/v/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/v/Tensordot/MatMul_grad/MatMul	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/v/Tensordot/transpose_1	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/v/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/transpose_1	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/transpose_1	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/k/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/k/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/k/Tensordot/MatMul_grad/MatMul	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/transpose_1	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/v/Tensordot/transpose_1	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/v/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/v/Tensordot/MatMul_grad/MatMul	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/transpose_1	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul	
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/AssignVariableOp	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/ReadVariableOp_3	
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/AssignVariableOp_1	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/ReadVariableOp_6	
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/Sqrt	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/mul	
model/get_train_op/learning_rate/truediv	model/get_train_op/learning_rate/Minimum	
model/get_train_op/learning_rate/Maximum	model/get_train_op/learning_rate/Rsqrt	
FunctionBufferingResourceGetNext	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/Gather_grad/Size	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/Gather_grad/Size	model/Transformer/encode/padding/Equal	model/Transformer/encode/embedding_shared_weights/embedding/Gather	model/Transformer/encode/embedding_shared_weights/embedding/NotEqual	model/loss/pad_to_same_length/Shape_1	model/Transformer/encode/embedding_shared_weights/embedding_1/Gather	model/Transformer/encode/embedding_shared_weights/embedding_1/NotEqual	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/Gather_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/Gather_grad/Reshape_1	FunctionBufferingResourceGetNext/_4554	
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/ReadVariableOp_3	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/ResourceScatterAdd	
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/ReadVariableOp_6	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/ResourceScatterAdd_1	
model/get_train_op/learning_rate/Minimum	model/get_train_op/learning_rate/mul	
model/get_train_op/learning_rate/Rsqrt	model/get_train_op/learning_rate/mul_1	
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/Gather_grad/Size	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/Gather_grad/ExpandDims	
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/Gather_grad/Size	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/Gather_grad/ExpandDims	
model/Transformer/encode/padding/Equal	model/Transformer/encode/padding/ToFloat	
model/Transformer/encode/embedding_shared_weights/embedding/Gather	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/mul_grad/Shape	model/Transformer/encode/embedding_shared_weights/embedding/mul	
model/Transformer/encode/embedding_shared_weights/embedding/NotEqual	model/Transformer/encode/embedding_shared_weights/embedding/ToFloat	
model/loss/pad_to_same_length/Shape_1	model/loss/pad_to_same_length/strided_slice_1	
model/Transformer/encode/embedding_shared_weights/embedding_1/Gather	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/mul_grad/Shape	model/Transformer/encode/embedding_shared_weights/embedding_1/mul	
model/Transformer/encode/embedding_shared_weights/embedding_1/NotEqual	model/Transformer/encode/embedding_shared_weights/embedding_1/ToFloat	
model/get_train_op/learning_rate/mul	model/get_train_op/learning_rate/mul_1	
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/Gather_grad/ExpandDims	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/Gather_grad/concat	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/Gather_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/Gather_grad/ExpandDims	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/Gather_grad/concat	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/Gather_grad/Reshape_1	
model/Transformer/encode/padding/ToFloat	model/Transformer/attention_bias/mul	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/Reshape	
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/mul_grad/Reshape	
model/Transformer/encode/embedding_shared_weights/embedding/ToFloat	model/Transformer/encode/embedding_shared_weights/embedding/ExpandDims	
model/loss/pad_to_same_length/strided_slice_1	model/loss/pad_to_same_length/Maximum	model/loss/pad_to_same_length/sub_1	
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/mul_grad/Reshape	
model/Transformer/encode/embedding_shared_weights/embedding_1/ToFloat	model/Transformer/encode/embedding_shared_weights/embedding_1/ExpandDims	
model/get_train_op/learning_rate/mul_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/mul	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/Gather_grad/concat	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/Gather_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/Gather_grad/Reshape_1	model/get_train_op/gradients/concat_1	
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/Gather_grad/concat	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/Gather_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/Gather_grad/Reshape_1	model/get_train_op/gradients/concat_1	
model/Transformer/attention_bias/mul	model/Transformer/attention_bias/ExpandDims	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/Reshape	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/Less	
model/Transformer/encode/embedding_shared_weights/embedding/ExpandDims	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/mul_grad/Shape_1	model/Transformer/encode/embedding_shared_weights/embedding/mul	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/mul_grad/Mul	
model/Transformer/encode/embedding_shared_weights/embedding_1/ExpandDims	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/mul_grad/Shape_1	model/Transformer/encode/embedding_shared_weights/embedding_1/mul	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/mul_grad/Mul	
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/mul	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/truediv	
model/get_train_op/gradients/concat_1	model/get_train_op/gradients/concat_1/_3418	
model/Transformer/attention_bias/ExpandDims	model/Transformer/attention_bias/ExpandDims_1	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/Less	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/Where	
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/mul_grad/BroadcastGradientArgs	
model/Transformer/encode/embedding_shared_weights/embedding/mul	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/mul_1_grad/Shape	model/Transformer/encode/embedding_shared_weights/embedding/mul_1	
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/mul_grad/BroadcastGradientArgs	
model/Transformer/encode/embedding_shared_weights/embedding_1/mul	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/mul_1_grad/Shape	model/Transformer/encode/embedding_shared_weights/embedding_1/mul_1	
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/truediv	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/mul_6	
model/get_train_op/gradients/concat_1/_3418	model/get_train_op/gradients/concat_1/_3419	
model/get_train_op/gradients/concat_1/_3419	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/Unique	
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/Unique	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/Unique/_3420	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/Unique/_4572	
model/Transformer/attention_bias/ExpandDims_1	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/add	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/add	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/add	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/add	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/add	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/add	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/add	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/add_grad/Shape_1	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/add	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/add	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/add	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/add	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/add	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/Where	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/ToInt32	
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/mul_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/mul_1_grad/Reshape	
model/Transformer/encode/embedding_shared_weights/embedding/mul_1	model/get_train_op/gradients/model/Transformer/encode/add_pos_encoding/add_grad/Shape	model/Transformer/encode/add_pos_encoding/Shape	model/Transformer/encode/add_pos_encoding/add	
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/mul_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/mul_1_grad/Reshape	
model/Transformer/encode/embedding_shared_weights/embedding_1/mul_1	model/get_train_op/gradients/model/Transformer/decode/shift_targets/Pad_grad/Shape	model/Transformer/decode/shift_targets/Pad	
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/Unique/_3420	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/Unique/_3421	
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/Unique/_3421	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/Shape	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/ResourceScatterAdd	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/ResourceScatterAdd_1	
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/Shape	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/strided_slice	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/add_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/add_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/add_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/add_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/add_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/add_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/add_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/add_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/add_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/add_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/add_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/add_grad/BroadcastGradientArgs	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/ToInt32	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/re_add_padding/ScatterNd_grad/GatherNd	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/GatherNd	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/re_add_padding/ScatterNd	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/re_add_padding/ScatterNd_grad/GatherNd	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/GatherNd	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/re_add_padding/ScatterNd	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/re_add_padding/ScatterNd_grad/GatherNd	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/GatherNd	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/re_add_padding/ScatterNd	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/re_add_padding/ScatterNd_grad/GatherNd	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/re_add_padding/ScatterNd	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/re_add_padding/ScatterNd_grad/GatherNd	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/ToInt32/_3422	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/GatherNd	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/re_add_padding/ScatterNd	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/GatherNd	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/re_add_padding/ScatterNd	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/re_add_padding/ScatterNd_grad/GatherNd	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/GatherNd	
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/mul_1_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/add_pos_encoding/add_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/add_pos_encoding/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/add_pos_encoding/add_grad/Reshape	
model/Transformer/encode/add_pos_encoding/Shape	model/Transformer/encode/add_pos_encoding/strided_slice	
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/mul_1_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/shift_targets/Pad_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/shift_targets/Pad_grad/Slice_1	
model/Transformer/decode/shift_targets/Pad	model/get_train_op/gradients/model/Transformer/decode/shift_targets/strided_slice_grad/Shape	model/Transformer/decode/shift_targets/strided_slice	
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/strided_slice	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/UnsortedSegmentSum	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/ToInt32/_3422	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/ToInt32/_3423	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/ToInt32/_3423	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/GatherNd_grad/Squeeze	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/GatherNd_grad/Squeeze	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/GatherNd_grad/Squeeze	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/GatherNd_grad/Squeeze	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/GatherNd_grad/Squeeze	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/GatherNd_grad/Squeeze	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/GatherNd_grad/Squeeze	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/GatherNd_grad/Squeeze/_4570	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/GatherNd_grad/Squeeze	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/GatherNd_grad/Squeeze/_4568	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/GatherNd_grad/Squeeze	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/GatherNd_grad/Squeeze/_4566	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/GatherNd_grad/Squeeze	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/GatherNd_grad/Squeeze/_4564	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/GatherNd_grad/Squeeze	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/GatherNd_grad/Squeeze/_4562	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/GatherNd_grad/Squeeze	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/GatherNd_grad/Squeeze/_4560	
model/Transformer/encode/add_pos_encoding/strided_slice	model/Transformer/encode/add_pos_encoding/range	
model/get_train_op/gradients/model/Transformer/decode/shift_targets/strided_slice_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/shift_targets/strided_slice_grad/StridedSliceGrad	
model/Transformer/decode/shift_targets/strided_slice	model/get_train_op/gradients/model/Transformer/decode/add_pos_encoding/add_grad/Shape	model/Transformer/decode/add_pos_encoding/Shape	model/Transformer/decode/add_pos_encoding/add	
model/Transformer/encode/add_pos_encoding/range	model/Transformer/encode/add_pos_encoding/range/_3424	
model/get_train_op/gradients/model/Transformer/decode/add_pos_encoding/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/add_pos_encoding/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/add_pos_encoding/add_grad/Reshape	
model/Transformer/decode/add_pos_encoding/Shape	model/Transformer/decode/add_pos_encoding/strided_slice	
model/Transformer/encode/add_pos_encoding/range/_3424	model/Transformer/encode/add_pos_encoding/range/_3425	
model/Transformer/encode/add_pos_encoding/range/_3425	model/Transformer/encode/add_pos_encoding/ToFloat	
model/Transformer/encode/add_pos_encoding/ToFloat	model/Transformer/encode/add_pos_encoding/ExpandDims	
model/Transformer/decode/add_pos_encoding/strided_slice	model/Transformer/decode/decoder_self_attention_bias/ones/packed	model/Transformer/decode/decoder_self_attention_bias/ones/packed	model/Transformer/decode/decoder_self_attention_bias/Reshape/shape	model/Transformer/decode/decoder_self_attention_bias/Reshape/shape	model/Transformer/decode/add_pos_encoding/range	
model/Transformer/encode/add_pos_encoding/ExpandDims	model/Transformer/encode/add_pos_encoding/mul_2	
model/Transformer/decode/decoder_self_attention_bias/ones/packed	model/Transformer/decode/decoder_self_attention_bias/ones	
model/Transformer/decode/decoder_self_attention_bias/Reshape/shape	model/Transformer/decode/decoder_self_attention_bias/Reshape	
model/Transformer/decode/add_pos_encoding/range	model/Transformer/decode/add_pos_encoding/range/_3426	
model/Transformer/encode/add_pos_encoding/mul_2	model/Transformer/encode/add_pos_encoding/Sin	model/Transformer/encode/add_pos_encoding/Cos	
model/Transformer/decode/decoder_self_attention_bias/ones	model/Transformer/decode/decoder_self_attention_bias/MatrixBandPart	
model/Transformer/decode/add_pos_encoding/range/_3426	model/Transformer/decode/add_pos_encoding/range/_3427	
model/Transformer/decode/add_pos_encoding/range/_3427	model/Transformer/decode/add_pos_encoding/ToFloat	
model/Transformer/decode/add_pos_encoding/ToFloat	model/Transformer/decode/add_pos_encoding/ExpandDims	
model/Transformer/encode/add_pos_encoding/Sin	model/Transformer/encode/add_pos_encoding/concat	
model/Transformer/encode/add_pos_encoding/Cos	model/Transformer/encode/add_pos_encoding/concat	
model/Transformer/decode/decoder_self_attention_bias/MatrixBandPart/num_lower/_3428	model/Transformer/decode/decoder_self_attention_bias/MatrixBandPart/num_lower/_3429	
model/Transformer/decode/decoder_self_attention_bias/MatrixBandPart/num_lower/_3429	model/Transformer/decode/decoder_self_attention_bias/MatrixBandPart	
model/Transformer/decode/decoder_self_attention_bias/MatrixBandPart/num_upper/_3430	model/Transformer/decode/decoder_self_attention_bias/MatrixBandPart/num_upper/_3431	
model/Transformer/decode/decoder_self_attention_bias/MatrixBandPart/num_upper/_3431	model/Transformer/decode/decoder_self_attention_bias/MatrixBandPart	
model/Transformer/decode/decoder_self_attention_bias/MatrixBandPart	model/Transformer/decode/decoder_self_attention_bias/Reshape	
model/Transformer/decode/add_pos_encoding/ExpandDims	model/Transformer/decode/add_pos_encoding/mul_2	
model/Transformer/encode/add_pos_encoding/concat	model/get_train_op/gradients/model/Transformer/encode/add_pos_encoding/add_grad/Shape_1	model/Transformer/encode/add_pos_encoding/add	
model/Transformer/decode/decoder_self_attention_bias/Reshape	model/Transformer/decode/decoder_self_attention_bias/sub	
model/Transformer/decode/add_pos_encoding/mul_2	model/Transformer/decode/add_pos_encoding/Sin	model/Transformer/decode/add_pos_encoding/Cos	
model/get_train_op/gradients/model/Transformer/encode/add_pos_encoding/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/add_pos_encoding/add_grad/BroadcastGradientArgs	
model/Transformer/encode/add_pos_encoding/add	model/get_train_op/gradients/model/Transformer/encode/dropout/div_grad/Shape	model/Transformer/encode/dropout/div	model/Transformer/encode/dropout/Shape	
model/Transformer/decode/decoder_self_attention_bias/sub	model/Transformer/decode/decoder_self_attention_bias/mul	
model/Transformer/decode/add_pos_encoding/Sin	model/Transformer/decode/add_pos_encoding/concat	
model/Transformer/decode/add_pos_encoding/Cos	model/Transformer/decode/add_pos_encoding/concat	
model/get_train_op/gradients/model/Transformer/encode/add_pos_encoding/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/add_pos_encoding/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/dropout/div_grad/Reshape	
model/Transformer/encode/dropout/div	model/get_train_op/gradients/model/Transformer/encode/dropout/mul_grad/Shape	model/Transformer/encode/dropout/mul	
model/Transformer/encode/dropout/Shape	model/Transformer/encode/dropout/random_uniform/RandomUniform	
model/Transformer/decode/decoder_self_attention_bias/mul	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/add	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/add_grad/Shape_1	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/add	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/add	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/add	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/add	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/add	
model/Transformer/decode/add_pos_encoding/concat	model/get_train_op/gradients/model/Transformer/decode/add_pos_encoding/add_grad/Shape_1	model/Transformer/decode/add_pos_encoding/add	
model/get_train_op/gradients/model/Transformer/encode/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/dropout/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/dropout/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/dropout/mul_grad/Reshape	
model/Transformer/encode/dropout/random_uniform/RandomUniform	model/Transformer/encode/dropout/random_uniform/mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/add_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/add_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/add_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/add_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/add_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/add_grad/BroadcastGradientArgs	
model/get_train_op/gradients/model/Transformer/decode/add_pos_encoding/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/add_pos_encoding/add_grad/BroadcastGradientArgs	
model/Transformer/decode/add_pos_encoding/add	model/get_train_op/gradients/model/Transformer/decode/dropout/div_grad/Shape	model/Transformer/decode/dropout/div	model/Transformer/decode/dropout/Shape	
model/Transformer/encode/dropout/random_uniform/mul	model/Transformer/encode/dropout/add	
model/get_train_op/gradients/model/Transformer/decode/add_pos_encoding/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/add_pos_encoding/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/dropout/div_grad/Reshape	
model/Transformer/decode/dropout/div	model/Transformer/decode/dropout/mul	
model/Transformer/decode/dropout/Shape	model/Transformer/decode/dropout/random_uniform/RandomUniform	
model/Transformer/encode/dropout/add	model/Transformer/encode/dropout/Floor	
model/get_train_op/gradients/model/Transformer/decode/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/dropout/div_grad/Sum	
model/Transformer/decode/dropout/random_uniform/RandomUniform	model/Transformer/decode/dropout/add	
model/Transformer/encode/dropout/Floor	model/get_train_op/gradients/model/Transformer/encode/dropout/mul_grad/Shape_1	model/Transformer/encode/dropout/mul	model/get_train_op/gradients/model/Transformer/encode/dropout/mul_grad/Mul	
model/Transformer/decode/dropout/add	model/Transformer/decode/dropout/Floor	
model/get_train_op/gradients/model/Transformer/encode/dropout/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/dropout/mul_grad/BroadcastGradientArgs	
model/Transformer/encode/dropout/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/add_grad/Shape	model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Prod	model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_1	model/Transformer/encode/encoder_stack/layer_0/self_attention/add	
model/Transformer/decode/dropout/Floor	model/Transformer/decode/dropout/mul	model/get_train_op/gradients/model/Transformer/decode/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/dropout/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/dropout/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Shape/_3432	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/floordiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/add_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/add_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_grad/Shape_1	model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Prod_1	
model/Transformer/decode/dropout/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/sub_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Shape	model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Prod	model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/sub_1	model/Transformer/decode/decoder_stack/layer_0/self_attention/add	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Shape/_3432	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Shape/_3433	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Shape/_3433	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/Fill/_3434	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/Fill/_3435	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/Fill/_3435	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/DynamicStitch/_3436	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_grad/Reshape_1	
model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_grad/Shape	model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Square	model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Prod_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/sub_grad/Shape	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Shape/_3438	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/floordiv	
model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/sub_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/sub_grad/Shape_1	model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/DynamicStitch/_3436	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/DynamicStitch/_3437	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/DynamicStitch/_3437	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/floordiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Square	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Shape	model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Prod	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Shape/_3438	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Shape/_3439	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Shape/_3439	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/DynamicStitch/_3440	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/sub_1_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/sub_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/sub_grad/Reshape_1	
model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/sub_1	model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Square	model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Prod_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/floordiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Shape/_3442	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/floordiv	
model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_grad/Shape	model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/floordiv_1/_3444	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/DynamicStitch/_3440	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/DynamicStitch/_3441	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/DynamicStitch/_3441	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/floordiv	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/sub_1_grad/Sum_1	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/sub_grad/Sum_1	
model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Square	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Shape	model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Prod	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Shape/_3442	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Shape/_3443	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Shape/_3443	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/DynamicStitch/_3446	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add	model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Rsqrt	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Prod_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/floordiv_1/_3444	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/floordiv_1/_3445	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/floordiv_1/_3445	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Cast	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Cast	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/floordiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Shape/_3448	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/floordiv	
model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_grad/Shape	model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/floordiv_1/_3450	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/DynamicStitch/_3446	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/DynamicStitch/_3447	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/DynamicStitch/_3447	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/floordiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_grad/Sum	
model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Rsqrt	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_grad/Shape_1	model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Shape/_3448	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Shape/_3449	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Shape/_3449	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/DynamicStitch/_3452	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add	model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Rsqrt	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Prod_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/floordiv_1/_3450	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/floordiv_1/_3451	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/floordiv_1/_3451	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Cast	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Cast	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/floordiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_grad/Reshape_1	
model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Shape	model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/floordiv_1/_3454	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/DynamicStitch/_3452	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/DynamicStitch/_3453	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/DynamicStitch/_3453	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/floordiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_grad/Sum	
model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Rsqrt	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_grad/Shape_1	model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/Shape	model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/floordiv_1/_3454	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/floordiv_1/_3455	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/floordiv_1/_3455	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Cast	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Cast	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/floordiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_grad/Reshape_1	
model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Shape	model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/floordiv_1/_3456	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_1	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/v/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/k/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Reshape_grad/Shape	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Reshape	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/Shape	model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/floordiv_1/_3456	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/floordiv_1/_3457	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/floordiv_1/_3457	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Cast	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Cast	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/Sum_1	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Shape	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Shape/_3458	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/v/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/k/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_1	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/v/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/k/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Reshape_grad/Shape	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Reshape	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Shape/_3458	_SINK	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/mod/_3460	_SINK	
model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/concat/axis/_3462	_SINK	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/Sum_1	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Shape	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Shape/_3470	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/v/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/k/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/GatherV2_1/_3465	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Prod_1	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Prod_1/_3474	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/GatherV2/_3467	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Prod	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Prod	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Prod/_3472	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/GatherV2/_3469	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/concat_2	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/k/Tensordot	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/v/Tensordot	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Shape/_3470	_SINK	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Prod/_3472	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Prod/_3473	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Prod/_3473	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/stack	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Prod_1/_3474	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Prod_1/_3475	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Prod_1/_3475	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/stack	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/stack	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/GatherV2_1/_3477	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Prod_1	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Prod_1/_3484	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/GatherV2/_3479	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Prod	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Prod/_3482	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/GatherV2/_3481	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/concat_2	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/k/Tensordot	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/v/Tensordot	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul_1	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/MatMul	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/k/Tensordot/MatMul	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/v/Tensordot/MatMul	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Prod/_3482	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Prod/_3483	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Prod/_3483	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Prod_1/_3484	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Prod_1/_3485	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Prod_1/_3485	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/stack	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Reshape	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot_grad/Shape	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads/Reshape	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/k/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/k/Tensordot_grad/Shape	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/k/Tensordot	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_1/Reshape	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/v/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/v/Tensordot_grad/Shape	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/v/Tensordot	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_2/Reshape	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul_1	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/MatMul	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/k/Tensordot/MatMul	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/v/Tensordot/MatMul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads/Shape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/k/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/k/Tensordot_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/k/Tensordot	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_1/Shape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/v/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/v/Tensordot_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/v/Tensordot	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_2/Shape	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads/Reshape	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/k/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/k/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/k/Tensordot	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_1/Reshape	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/v/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/v/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/v/Tensordot	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_2/Reshape	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads/Shape	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads/strided_slice_1	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_1/Shape	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_1/strided_slice_1	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_2/Shape	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_2/strided_slice_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads/Shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/k/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/k/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/k/Tensordot	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_1/Shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/v/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/v/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/v/Tensordot	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_2/Shape	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads/strided_slice_1	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_1/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_1/strided_slice_1	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_1/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_2/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_2/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads/Shape	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads/strided_slice_1	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_1/Shape	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_1/strided_slice_1	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_2/Shape	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_2/strided_slice_1	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads/Reshape/shape	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads/Reshape	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_1/Reshape/shape	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_1/Reshape	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_2/Reshape/shape	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_2/Reshape	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_1/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_1/strided_slice_1	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_1/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_2/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_2/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads/Reshape	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads/transpose	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_1/Reshape	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_1/transpose	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_2/Reshape	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_2/transpose	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads/Reshape	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_1/Reshape/shape	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_1/Reshape	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_2/Reshape/shape	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_2/Reshape	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/mul_grad/Shape	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/mul	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_1/transpose	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/MatMul_grad/MatMul	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_2/transpose	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/MatMul_1_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads/Reshape	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads/transpose	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_1/Reshape	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_1/transpose	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_2/Reshape	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_2/transpose	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/mul_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/mul	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/MatMul_grad/MatMul_1	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/mul_grad/Shape	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/mul	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_1/transpose	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_2/transpose	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/MatMul_1_grad/MatMul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/mul_grad/Sum	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/add_grad/Shape	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/add	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/mul_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/mul	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/add_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/add_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/add	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/attention_weights	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/mul_grad/Sum	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/add_grad/Shape	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/add	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/add_grad/Sum	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/attention_weights	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/attention_weights_grad/mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/div_grad/Shape	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/div	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/Shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/add_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/add	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/attention_weights	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/div_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/div	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/mul_grad/Shape	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/mul	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/Shape	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/add_grad/Sum	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/attention_weights	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/attention_weights_grad/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/dropout/div_grad/Shape	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/dropout/div	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/dropout/Shape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/mul_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/random_uniform/RandomUniform	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/random_uniform/mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/dropout/div_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/dropout/div	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/dropout/mul_grad/Shape	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/dropout/mul	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/dropout/Shape	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/dropout/random_uniform/RandomUniform	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/random_uniform/mul	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/add	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/dropout/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/dropout/mul_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/dropout/random_uniform/RandomUniform	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/dropout/add	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/add	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/Floor	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/dropout/add	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/dropout/Floor	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/Floor	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/mul_grad/Shape_1	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/mul_grad/Mul	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/dropout/Floor	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/dropout/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/mul_grad/BroadcastGradientArgs	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/mul	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/MatMul_1_grad/MatMul_1	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/dropout/mul	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/MatMul_1_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/mul_grad/Sum	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/MatMul_1	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/combine_heads/transpose	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/combine_heads/Shape	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/MatMul_1	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/combine_heads/transpose	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/combine_heads/Shape	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/combine_heads/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/combine_heads/Reshape_grad/Shape	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/combine_heads/Reshape	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/combine_heads/Shape	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/combine_heads/strided_slice_1	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/combine_heads/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/combine_heads/Reshape_grad/Shape	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/combine_heads/Reshape	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/combine_heads/Shape	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/combine_heads/strided_slice_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/combine_heads/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/combine_heads/Reshape_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/combine_heads/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/combine_heads/strided_slice_1	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/combine_heads/Reshape/shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/combine_heads/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/combine_heads/Reshape_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/combine_heads/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/combine_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/combine_heads/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/combine_heads/Reshape/shape	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/combine_heads/Reshape	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/combine_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/combine_heads/Reshape	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/combine_heads/Reshape	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Shape	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/combine_heads/Reshape	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Shape	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Reshape	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Shape	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Shape/_3486	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Shape	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Shape/_3488	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Shape/_3486	_SINK	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Shape/_3488	_SINK	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/GatherV2_1/_3491	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Prod_1	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Prod_1/_3504	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/GatherV2/_3493	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Prod	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Prod	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Prod/_3502	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/GatherV2/_3495	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/concat_2	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/GatherV2_1/_3497	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Prod_1	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Prod_1/_3508	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/GatherV2/_3499	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Prod	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Prod/_3506	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/GatherV2/_3501	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/concat_2	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Prod/_3502	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Prod/_3503	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Prod/_3503	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/stack	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Prod_1/_3504	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Prod_1/_3505	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Prod_1/_3505	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/stack	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/stack	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Prod/_3506	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Prod/_3507	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Prod/_3507	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Prod_1/_3508	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Prod_1/_3509	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Prod_1/_3509	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/stack	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Reshape	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Reshape	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Reshape	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot_grad/Shape	model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/dropout/div_grad/Shape	model/Transformer/encode/encoder_stack/layer_0/self_attention/dropout/div	model/Transformer/encode/encoder_stack/layer_0/self_attention/dropout/Shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/dropout/div_grad/Shape	model/Transformer/decode/decoder_stack/layer_0/self_attention/dropout/div	model/Transformer/decode/decoder_stack/layer_0/self_attention/dropout/Shape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/dropout/div_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_0/self_attention/dropout/div	model/Transformer/encode/encoder_stack/layer_0/self_attention/dropout/mul	
model/Transformer/encode/encoder_stack/layer_0/self_attention/dropout/Shape	model/Transformer/encode/encoder_stack/layer_0/self_attention/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/dropout/div_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_0/self_attention/dropout/div	model/Transformer/decode/decoder_stack/layer_0/self_attention/dropout/mul	
model/Transformer/decode/decoder_stack/layer_0/self_attention/dropout/Shape	model/Transformer/decode/decoder_stack/layer_0/self_attention/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/dropout/div_grad/Sum	
model/Transformer/encode/encoder_stack/layer_0/self_attention/dropout/random_uniform/RandomUniform	model/Transformer/encode/encoder_stack/layer_0/self_attention/dropout/add	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/dropout/div_grad/Sum	
model/Transformer/decode/decoder_stack/layer_0/self_attention/dropout/random_uniform/RandomUniform	model/Transformer/decode/decoder_stack/layer_0/self_attention/dropout/add	
model/Transformer/encode/encoder_stack/layer_0/self_attention/dropout/add	model/Transformer/encode/encoder_stack/layer_0/self_attention/dropout/Floor	
model/Transformer/decode/decoder_stack/layer_0/self_attention/dropout/add	model/Transformer/decode/decoder_stack/layer_0/self_attention/dropout/Floor	
model/Transformer/encode/encoder_stack/layer_0/self_attention/dropout/Floor	model/Transformer/encode/encoder_stack/layer_0/self_attention/dropout/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/dropout/mul_grad/Mul	
model/Transformer/decode/decoder_stack/layer_0/self_attention/dropout/Floor	model/Transformer/decode/decoder_stack/layer_0/self_attention/dropout/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/dropout/mul_grad/Mul	
model/Transformer/encode/encoder_stack/layer_0/self_attention/dropout/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/add_grad/Shape_1	model/Transformer/encode/encoder_stack/layer_0/self_attention/add	
model/Transformer/decode/decoder_stack/layer_0/self_attention/dropout/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/add_grad/Shape_1	model/Transformer/decode/decoder_stack/layer_0/self_attention/add	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/add_grad/Reshape_1	
model/Transformer/encode/encoder_stack/layer_0/self_attention/add	model/Transformer/encode/encoder_stack/layer_0/ffn/add	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/add_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Shape	model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Prod	model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/add_grad/Reshape_1	
model/Transformer/decode/decoder_stack/layer_0/self_attention/add	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/add	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/sub_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/add_grad/Shape	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/Prod	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/sub_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/add_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Shape/_3510	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/floordiv	
model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_grad/Shape_1	model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/sub_grad/Shape	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/Shape/_3512	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/floordiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/add_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/sub_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/sub_grad/Shape_1	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Shape/_3510	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Shape/_3511	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Shape/_3511	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/DynamicStitch/_3514	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_grad/Reshape_1	
model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Square_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_grad/Shape	model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Square	model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Prod_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/Shape/_3512	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/Shape/_3513	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/Shape/_3513	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/DynamicStitch/_3516	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/sub_1_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/sub_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/sub_grad/Reshape_1	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/sub_1	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Square	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/Prod_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/DynamicStitch/_3514	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/DynamicStitch/_3515	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/DynamicStitch/_3515	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/floordiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Square	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Shape	model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Prod	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/DynamicStitch/_3516	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/DynamicStitch/_3517	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/DynamicStitch/_3517	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/floordiv	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/sub_1_grad/Sum_1	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/sub_grad/Sum_1	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Square	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/Shape	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/Prod	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/floordiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Shape/_3518	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/floordiv	
model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_grad/Shape	model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/floordiv_1/_3520	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/floordiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/Shape/_3522	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/floordiv	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_grad/Shape	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/floordiv_1/_3524	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Shape/_3518	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Shape/_3519	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Shape/_3519	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/DynamicStitch/_3526	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add	model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Rsqrt	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Prod_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/floordiv_1/_3520	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/floordiv_1/_3521	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/floordiv_1/_3521	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Cast	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Cast	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/Shape/_3522	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/Shape/_3523	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/Shape/_3523	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch/_3528	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Rsqrt	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/Prod_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/floordiv_1/_3524	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/floordiv_1/_3525	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/floordiv_1/_3525	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/Cast	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/Cast	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/DynamicStitch/_3526	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/DynamicStitch/_3527	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/DynamicStitch/_3527	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/floordiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_grad/Sum	
model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Rsqrt	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_grad/Shape_1	model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch/_3528	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch/_3529	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch/_3529	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/floordiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_grad/Sum	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Rsqrt	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_grad/Shape_1	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/floordiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_grad/Reshape_1	
model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Shape	model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/floordiv_1/_3530	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/floordiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_grad/Reshape_1	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_1_grad/Shape	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/floordiv_1/_3532	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_1_grad/Shape	model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/floordiv_1/_3530	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/floordiv_1/_3531	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/floordiv_1/_3531	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Cast	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Cast	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/truediv	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_1_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_1_grad/Shape	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/floordiv_1/_3532	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/floordiv_1/_3533	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/floordiv_1/_3533	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/Cast	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/Cast	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_1_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Shape	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/Reshape_1	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/Shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_1_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_1	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/Reshape_grad/Shape	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/GatherNd_grad/Shape	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/GatherNd	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/Shape	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/strided_slice	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/strided_slice_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_1_grad/Sum_1	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/Shape	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/Shape/_3534	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/GatherNd_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/GatherNd	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/ExpandDims_grad/Shape	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/ExpandDims	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/strided_slice	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/re_add_padding/mul	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/re_add_padding/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/strided_slice_1	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/re_add_padding/mul	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/re_add_padding/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/Shape/_3534	_SINK	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/tensor	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/ExpandDims_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/ExpandDims_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/ExpandDims	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Shape	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Reshape	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/re_add_padding/mul	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/re_add_padding/ScatterNd/shape	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/re_add_padding/Reshape/shape	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/re_add_padding/Reshape	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/GatherV2_1/_3537	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/Prod_1	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/Prod_1/_3544	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/GatherV2/_3539	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/Prod	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/Prod/_3542	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/GatherV2/_3541	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/concat_2	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Shape	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Shape/_3546	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/re_add_padding/ScatterNd/shape	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/re_add_padding/ScatterNd	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/Prod/_3542	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/Prod/_3543	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/Prod/_3543	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/Prod_1/_3544	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/Prod_1/_3545	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/Prod_1/_3545	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/stack	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/Reshape	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Shape/_3546	_SINK	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/Reshape	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2_1/_3549	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1/_3556	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2/_3551	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Prod	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Prod	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Prod/_3554	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2/_3553	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/concat_2	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads/Reshape	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Prod/_3554	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Prod/_3555	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Prod/_3555	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/stack	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1/_3556	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1/_3557	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1/_3557	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/stack	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/stack	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads/Shape	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Reshape	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads/Shape	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads/strided_slice_1	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot_grad/Shape	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads/Reshape/shape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/BiasAdd	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads/Reshape	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/BiasAdd	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Relu	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads/Reshape	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads/transpose	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Relu	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/dropout/div_grad/Shape	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/dropout/div	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/dropout/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Relu_grad/ReluGrad	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/mul_grad/Shape	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/dropout/div_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/dropout/div	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/dropout/mul	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/dropout/Shape	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/mul_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/mul	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/dropout/div_grad/Sum	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/dropout/random_uniform/RandomUniform	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/dropout/add	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/mul_grad/Sum	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/dropout/add	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/dropout/Floor	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/dropout/Floor	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/dropout/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/dropout/mul_grad/Mul	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/dropout/mul	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Shape	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Reshape	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Shape	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Shape/_3558	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Shape/_3558	_SINK	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/GatherV2_1/_3561	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Prod_1	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Prod_1/_3568	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/GatherV2/_3563	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Prod	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Prod	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Prod/_3566	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/GatherV2/_3565	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/concat_2	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Prod/_3566	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Prod/_3567	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Prod/_3567	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/stack	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Prod_1/_3568	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Prod_1/_3569	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Prod_1/_3569	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/stack	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/stack	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Reshape	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Reshape	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot_grad/Shape	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/BiasAdd	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/BiasAdd	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/re_add_padding/Squeeze_grad/Shape	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/re_add_padding/Squeeze	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/re_add_padding/Squeeze_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/re_add_padding/Squeeze_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/re_add_padding/Squeeze	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/re_add_padding/ScatterNd	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/re_add_padding/ScatterNd	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/re_add_padding/Reshape_grad/Shape	model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/re_add_padding/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/re_add_padding/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/re_add_padding/Reshape_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/re_add_padding/Reshape	model/Transformer/encode/encoder_stack/layer_0/ffn/dropout/div	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/dropout/div_grad/Shape	model/Transformer/encode/encoder_stack/layer_0/ffn/dropout/Shape	
model/Transformer/encode/encoder_stack/layer_0/ffn/dropout/div	model/Transformer/encode/encoder_stack/layer_0/ffn/dropout/mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/dropout/div_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_0/ffn/dropout/Shape	model/Transformer/encode/encoder_stack/layer_0/ffn/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/dropout/div_grad/Sum	
model/Transformer/encode/encoder_stack/layer_0/ffn/dropout/random_uniform/RandomUniform	model/Transformer/encode/encoder_stack/layer_0/ffn/dropout/add	
model/Transformer/encode/encoder_stack/layer_0/ffn/dropout/add	model/Transformer/encode/encoder_stack/layer_0/ffn/dropout/Floor	
model/Transformer/encode/encoder_stack/layer_0/ffn/dropout/Floor	model/Transformer/encode/encoder_stack/layer_0/ffn/dropout/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/dropout/mul_grad/Mul	
model/Transformer/encode/encoder_stack/layer_0/ffn/dropout/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/add_grad/Shape_1	model/Transformer/encode/encoder_stack/layer_0/ffn/add	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/add_grad/Reshape_1	
model/Transformer/encode/encoder_stack/layer_0/ffn/add	model/Transformer/encode/encoder_stack/layer_1/self_attention/add	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/add_grad/Shape	model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Prod	model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Shape/_3570	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/floordiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/add_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/add_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean	model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Shape/_3570	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Shape/_3571	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Shape/_3571	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/DynamicStitch/_3572	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/floordiv_1	
model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Square_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_grad/Shape	model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Square	model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Prod_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/DynamicStitch/_3572	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/DynamicStitch/_3573	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/DynamicStitch/_3573	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/floordiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Square	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Shape	model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Prod	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/floordiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Shape/_3574	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/floordiv	
model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_grad/Shape	model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/floordiv_1/_3576	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Shape/_3574	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Shape/_3575	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Shape/_3575	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/DynamicStitch/_3578	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add	model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Rsqrt	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Prod_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/floordiv_1/_3576	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/floordiv_1/_3577	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/floordiv_1/_3577	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Cast	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Cast	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/DynamicStitch/_3578	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/DynamicStitch/_3579	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/DynamicStitch/_3579	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/floordiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_grad/Sum	
model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Rsqrt	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_grad/Shape_1	model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/floordiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_grad/Reshape_1	
model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Shape	model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/floordiv_1/_3580	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/Shape	model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/floordiv_1/_3580	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/floordiv_1/_3581	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/floordiv_1/_3581	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Cast	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Cast	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/k/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Reshape_grad/Shape	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Reshape	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/v/Tensordot/Reshape_grad/Shape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/Sum_1	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Shape	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Shape/_3582	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/v/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/k/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Shape/_3582	_SINK	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/GatherV2_1/_3585	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Prod_1	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Prod_1/_3592	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/GatherV2/_3587	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/concat_2	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/k/Tensordot	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/v/Tensordot	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/GatherV2/_3589	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Prod	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Prod	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Prod/_3590	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Prod/_3590	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Prod/_3591	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Prod/_3591	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/stack	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Prod_1/_3592	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Prod_1/_3593	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Prod_1/_3593	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/stack	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/stack	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Reshape	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Reshape	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/k/Tensordot/MatMul	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/v/Tensordot/MatMul	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/k/Tensordot/MatMul	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/k/Tensordot	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/k/Tensordot_grad/Shape	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_1/Reshape	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/v/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/v/Tensordot_grad/Shape	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/v/Tensordot	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_2/Reshape	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/MatMul	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot_grad/Shape	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads/Reshape	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/k/Tensordot	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_1/Shape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/k/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/k/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/v/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/v/Tensordot_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/v/Tensordot	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_2/Shape	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads/Shape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_1/Shape	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_1/strided_slice_1	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_2/Shape	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_2/strided_slice_1	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads/Shape	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads/strided_slice_1	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads/strided_slice	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_1/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_1/strided_slice_1	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_1/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_2/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_2/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads/strided_slice_1	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_1/Reshape/shape	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_1/Reshape	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_2/Reshape/shape	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_2/Reshape	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads/Reshape/shape	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads/Reshape	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_1/Reshape	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_1/transpose	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_2/Reshape	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_2/transpose	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads/Reshape	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads/transpose	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_1/transpose	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/MatMul_grad/MatMul	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_2/transpose	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/MatMul_1_grad/MatMul	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads/transpose	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/mul_grad/Shape	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/mul	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/mul_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/MatMul	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/add	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/add_grad/Shape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/mul_grad/Sum	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/add	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/attention_weights	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/add_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/add_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/attention_weights	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/div_grad/Shape	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/div	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/attention_weights_grad/mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/add_grad/Sum	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/Shape	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/div_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/div	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/mul_grad/Shape	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/mul	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/random_uniform/RandomUniform	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/random_uniform/mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/mul_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/random_uniform/mul	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/add	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/add	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/Floor	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/Floor	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/mul_grad/Mul	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/mul	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/MatMul_1_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/mul_grad/BroadcastGradientArgs	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/MatMul_1	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/combine_heads/transpose	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/combine_heads/Shape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/mul_grad/Sum	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/combine_heads/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/combine_heads/Reshape_grad/Shape	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/combine_heads/Reshape	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/combine_heads/Shape	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/combine_heads/strided_slice_1	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/combine_heads/strided_slice	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/combine_heads/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/combine_heads/Reshape_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/combine_heads/strided_slice_1	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/combine_heads/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/combine_heads/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/combine_heads/Reshape/shape	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/combine_heads/Reshape	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/combine_heads/Reshape	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Shape	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Reshape	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Shape	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Shape/_3594	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Shape/_3594	_SINK	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/GatherV2/_3597	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/concat_2	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/GatherV2/_3599	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Prod	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Prod	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Prod/_3602	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/GatherV2_1/_3601	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Prod_1	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Prod_1/_3604	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Prod/_3602	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Prod/_3603	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Prod/_3603	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/stack	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Prod_1/_3604	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Prod_1/_3605	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Prod_1/_3605	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/stack	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/stack	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Reshape	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Reshape	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot_grad/Shape	model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/dropout/div_grad/Shape	model/Transformer/encode/encoder_stack/layer_1/self_attention/dropout/Shape	model/Transformer/encode/encoder_stack/layer_1/self_attention/dropout/div	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/dropout/div_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_1/self_attention/dropout/Shape	model/Transformer/encode/encoder_stack/layer_1/self_attention/dropout/random_uniform/RandomUniform	
model/Transformer/encode/encoder_stack/layer_1/self_attention/dropout/div	model/Transformer/encode/encoder_stack/layer_1/self_attention/dropout/mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/dropout/div_grad/Sum	
model/Transformer/encode/encoder_stack/layer_1/self_attention/dropout/random_uniform/RandomUniform	model/Transformer/encode/encoder_stack/layer_1/self_attention/dropout/add	
model/Transformer/encode/encoder_stack/layer_1/self_attention/dropout/add	model/Transformer/encode/encoder_stack/layer_1/self_attention/dropout/Floor	
model/Transformer/encode/encoder_stack/layer_1/self_attention/dropout/Floor	model/Transformer/encode/encoder_stack/layer_1/self_attention/dropout/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/dropout/mul_grad/Mul	
model/Transformer/encode/encoder_stack/layer_1/self_attention/dropout/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/add_grad/Shape_1	model/Transformer/encode/encoder_stack/layer_1/self_attention/add	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/add_grad/Reshape_1	
model/Transformer/encode/encoder_stack/layer_1/self_attention/add	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/add_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Shape	model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Prod	model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_1	model/Transformer/encode/encoder_stack/layer_1/ffn/add	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/add_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Shape/_3606	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/floordiv	
model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_grad/Shape_1	model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Shape/_3606	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Shape/_3607	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Shape/_3607	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/DynamicStitch/_3608	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_grad/Reshape_1	
model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_grad/Shape	model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Square	model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Prod_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/DynamicStitch/_3608	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/DynamicStitch/_3609	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/DynamicStitch/_3609	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/floordiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Square	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Shape	model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Prod	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/floordiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Shape/_3610	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/floordiv	
model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_grad/Shape	model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/floordiv_1/_3612	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Shape/_3610	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Shape/_3611	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Shape/_3611	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/DynamicStitch/_3614	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add	model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Rsqrt	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Prod_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/floordiv_1/_3612	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/floordiv_1/_3613	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/floordiv_1/_3613	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Cast	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Cast	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/DynamicStitch/_3614	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/DynamicStitch/_3615	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/DynamicStitch/_3615	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/floordiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_grad/Sum	
model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Rsqrt	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_grad/Shape_1	model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/floordiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_grad/Reshape_1	
model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Shape	model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/floordiv_1/_3616	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_1_grad/Shape	model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/floordiv_1/_3616	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/floordiv_1/_3617	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/floordiv_1/_3617	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Cast	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Cast	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_1_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Shape	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/Reshape_1	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/Shape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/GatherNd_grad/Shape	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/GatherNd	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/Shape	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/strided_slice_1	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/strided_slice	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/GatherNd_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/GatherNd	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/ExpandDims_grad/Shape	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/ExpandDims	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/strided_slice_1	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/re_add_padding/Reshape/shape	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/re_add_padding/mul	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/strided_slice	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/re_add_padding/Reshape/shape	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/re_add_padding/mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/tensor	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/ExpandDims_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/ExpandDims_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/ExpandDims	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Shape	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Reshape	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/re_add_padding/Reshape/shape	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/re_add_padding/Reshape	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/re_add_padding/mul	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/re_add_padding/ScatterNd/shape	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Shape	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Shape/_3618	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/re_add_padding/ScatterNd/shape	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/re_add_padding/ScatterNd	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Shape/_3618	_SINK	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2_1/_3621	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1/_3628	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2/_3623	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Prod	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Prod	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Prod/_3626	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2/_3625	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/concat_2	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Prod/_3626	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Prod/_3627	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Prod/_3627	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/stack	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1/_3628	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1/_3629	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1/_3629	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/stack	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/stack	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Reshape	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Reshape	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot_grad/Shape	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/BiasAdd	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/BiasAdd	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Relu	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Relu	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/dropout/div_grad/Shape	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/dropout/div	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/dropout/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Relu_grad/ReluGrad	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/dropout/div_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/dropout/div	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/dropout/mul	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/dropout/Shape	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/dropout/div_grad/Sum	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/dropout/random_uniform/RandomUniform	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/dropout/add	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/dropout/add	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/dropout/Floor	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/dropout/Floor	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/dropout/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/dropout/mul_grad/Mul	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/dropout/mul	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Shape	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Reshape	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Shape	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Shape/_3630	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Shape/_3630	_SINK	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/GatherV2_1/_3633	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Prod_1	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Prod_1/_3640	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/GatherV2/_3635	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Prod	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Prod	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Prod/_3638	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/GatherV2/_3637	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/concat_2	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Prod/_3638	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Prod/_3639	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Prod/_3639	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/stack	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Prod_1/_3640	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Prod_1/_3641	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Prod_1/_3641	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/stack	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/stack	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Reshape	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Reshape	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot_grad/Shape	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/BiasAdd	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/BiasAdd	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/re_add_padding/Squeeze_grad/Shape	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/re_add_padding/Squeeze	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/re_add_padding/Squeeze_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/re_add_padding/Squeeze_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/re_add_padding/Squeeze	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/re_add_padding/ScatterNd	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/re_add_padding/ScatterNd	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/re_add_padding/Reshape_grad/Shape	model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/re_add_padding/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/re_add_padding/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/re_add_padding/Reshape_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/re_add_padding/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/dropout/div_grad/Shape	model/Transformer/encode/encoder_stack/layer_1/ffn/dropout/Shape	model/Transformer/encode/encoder_stack/layer_1/ffn/dropout/div	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/dropout/div_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_1/ffn/dropout/Shape	model/Transformer/encode/encoder_stack/layer_1/ffn/dropout/random_uniform/RandomUniform	
model/Transformer/encode/encoder_stack/layer_1/ffn/dropout/div	model/Transformer/encode/encoder_stack/layer_1/ffn/dropout/mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/dropout/div_grad/Sum	
model/Transformer/encode/encoder_stack/layer_1/ffn/dropout/random_uniform/RandomUniform	model/Transformer/encode/encoder_stack/layer_1/ffn/dropout/add	
model/Transformer/encode/encoder_stack/layer_1/ffn/dropout/add	model/Transformer/encode/encoder_stack/layer_1/ffn/dropout/Floor	
model/Transformer/encode/encoder_stack/layer_1/ffn/dropout/Floor	model/Transformer/encode/encoder_stack/layer_1/ffn/dropout/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/dropout/mul_grad/Mul	
model/Transformer/encode/encoder_stack/layer_1/ffn/dropout/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/add_grad/Shape_1	model/Transformer/encode/encoder_stack/layer_1/ffn/add	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/add_grad/Reshape_1	
model/Transformer/encode/encoder_stack/layer_1/ffn/add	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/add_grad/Shape	model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Prod	model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_1	model/Transformer/encode/encoder_stack/layer_2/self_attention/add	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Shape/_3642	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/floordiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/add_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/add_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_grad/Shape_1	model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Shape/_3642	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Shape/_3643	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Shape/_3643	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/DynamicStitch/_3644	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_grad/Reshape_1	
model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_grad/Shape	model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Square	model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Prod_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/DynamicStitch/_3644	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/DynamicStitch/_3645	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/DynamicStitch/_3645	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/floordiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Square	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Shape	model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Prod	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/floordiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Shape/_3646	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/floordiv	
model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_grad/Shape	model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/floordiv_1/_3648	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Shape/_3646	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Shape/_3647	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Shape/_3647	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/DynamicStitch/_3650	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add	model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Rsqrt	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Prod_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/floordiv_1/_3648	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/floordiv_1/_3649	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/floordiv_1/_3649	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Cast	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Cast	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/DynamicStitch/_3650	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/DynamicStitch/_3651	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/DynamicStitch/_3651	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/floordiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_grad/Sum	
model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Rsqrt	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_grad/Shape_1	model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/floordiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_grad/Reshape_1	
model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Shape	model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/floordiv_1/_3652	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/Shape	model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/floordiv_1/_3652	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/floordiv_1/_3653	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/floordiv_1/_3653	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Cast	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Cast	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_1	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/v/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/k/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Reshape_grad/Shape	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/Sum_1	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Shape	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Shape/_3654	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/v/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/k/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Shape/_3654	_SINK	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/GatherV2_1/_3657	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Prod_1	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Prod_1/_3664	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/GatherV2/_3659	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Prod	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Prod	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Prod/_3662	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/GatherV2/_3661	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/concat_2	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/k/Tensordot	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/v/Tensordot	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Prod/_3662	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Prod/_3663	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Prod/_3663	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/stack	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Prod_1/_3664	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Prod_1/_3665	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Prod_1/_3665	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/stack	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/stack	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Reshape	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Reshape	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/MatMul	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/k/Tensordot/MatMul	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/v/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot_grad/Shape	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads/Reshape	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/k/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/k/Tensordot_grad/Shape	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/k/Tensordot	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_1/Reshape	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/v/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/v/Tensordot_grad/Shape	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/v/Tensordot	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_2/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads/Shape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/k/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/k/Tensordot_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/k/Tensordot	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_1/Shape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/v/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/v/Tensordot_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/v/Tensordot	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_2/Shape	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads/Shape	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads/strided_slice_1	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_1/Shape	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_1/strided_slice_1	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_2/Shape	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_2/strided_slice	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads/strided_slice_1	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_1/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_1/strided_slice_1	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_1/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_2/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_2/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads/Reshape/shape	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads/Reshape	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_1/Reshape/shape	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_1/Reshape	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_2/Reshape/shape	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_2/Reshape	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads/Reshape	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads/transpose	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_1/Reshape	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_1/transpose	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_2/Reshape	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_2/transpose	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/mul_grad/Shape	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/mul	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_1/transpose	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/MatMul_grad/MatMul	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_2/transpose	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/MatMul_1_grad/MatMul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/mul_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/mul	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/mul_grad/Sum	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/add_grad/Shape	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/add	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/add_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/add_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/add	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/attention_weights	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/add_grad/Sum	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/attention_weights	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/attention_weights_grad/mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/div_grad/Shape	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/div	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/Shape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/div_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/div	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/mul_grad/Shape	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/mul	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/Shape	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/mul_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/random_uniform/RandomUniform	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/random_uniform/mul	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/random_uniform/mul	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/add	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/add	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/Floor	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/Floor	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/mul_grad/Shape_1	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/mul_grad/BroadcastGradientArgs	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/mul	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/MatMul_1_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/mul_grad/Sum	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/MatMul_1	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/combine_heads/transpose	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/combine_heads/Shape	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/combine_heads/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/combine_heads/Reshape_grad/Shape	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/combine_heads/Reshape	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/combine_heads/Shape	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/combine_heads/strided_slice_1	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/combine_heads/strided_slice	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/combine_heads/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/combine_heads/Reshape_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/combine_heads/strided_slice_1	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/combine_heads/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/combine_heads/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/combine_heads/Reshape/shape	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/combine_heads/Reshape	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/combine_heads/Reshape	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Shape	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Reshape	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Shape	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Shape/_3666	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Shape/_3666	_SINK	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/GatherV2/_3669	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/concat_2	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/GatherV2/_3671	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Prod	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Prod	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Prod/_3674	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/GatherV2_1/_3673	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Prod_1	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Prod_1/_3676	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Prod/_3674	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Prod/_3675	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Prod/_3675	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/stack	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Prod_1/_3676	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Prod_1/_3677	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Prod_1/_3677	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/stack	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/stack	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Reshape	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Reshape	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot_grad/Shape	model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/dropout/div_grad/Shape	model/Transformer/encode/encoder_stack/layer_2/self_attention/dropout/Shape	model/Transformer/encode/encoder_stack/layer_2/self_attention/dropout/div	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/dropout/div_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_2/self_attention/dropout/Shape	model/Transformer/encode/encoder_stack/layer_2/self_attention/dropout/random_uniform/RandomUniform	
model/Transformer/encode/encoder_stack/layer_2/self_attention/dropout/div	model/Transformer/encode/encoder_stack/layer_2/self_attention/dropout/mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/dropout/div_grad/Sum	
model/Transformer/encode/encoder_stack/layer_2/self_attention/dropout/random_uniform/RandomUniform	model/Transformer/encode/encoder_stack/layer_2/self_attention/dropout/add	
model/Transformer/encode/encoder_stack/layer_2/self_attention/dropout/add	model/Transformer/encode/encoder_stack/layer_2/self_attention/dropout/Floor	
model/Transformer/encode/encoder_stack/layer_2/self_attention/dropout/Floor	model/Transformer/encode/encoder_stack/layer_2/self_attention/dropout/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/dropout/mul_grad/Mul	
model/Transformer/encode/encoder_stack/layer_2/self_attention/dropout/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/add_grad/Shape_1	model/Transformer/encode/encoder_stack/layer_2/self_attention/add	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/add_grad/Reshape_1	
model/Transformer/encode/encoder_stack/layer_2/self_attention/add	model/Transformer/encode/encoder_stack/layer_2/ffn/add	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/add_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Shape	model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Prod	model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/add_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Shape/_3678	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/floordiv	
model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_grad/Shape_1	model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Shape/_3678	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Shape/_3679	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Shape/_3679	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/DynamicStitch/_3680	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_grad/Reshape_1	
model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Square_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_grad/Shape	model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Square	model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Prod_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/DynamicStitch/_3680	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/DynamicStitch/_3681	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/DynamicStitch/_3681	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/floordiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Square	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Shape	model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Prod	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/floordiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Shape/_3682	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/floordiv	
model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_grad/Shape	model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/floordiv_1/_3684	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Shape/_3682	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Shape/_3683	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Shape/_3683	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/DynamicStitch/_3686	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add	model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Rsqrt	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Prod_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/floordiv_1/_3684	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/floordiv_1/_3685	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/floordiv_1/_3685	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Cast	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Cast	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/DynamicStitch/_3686	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/DynamicStitch/_3687	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/DynamicStitch/_3687	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/floordiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_grad/Sum	
model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Rsqrt	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_grad/Shape_1	model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/floordiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_grad/Reshape_1	
model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Shape	model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/floordiv_1/_3688	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_1_grad/Shape	model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/floordiv_1/_3688	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/floordiv_1/_3689	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/floordiv_1/_3689	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Cast	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Cast	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_1_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Shape	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/Reshape_1	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/Shape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/GatherNd_grad/Shape	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/GatherNd	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/Shape	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/strided_slice_1	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/strided_slice	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/GatherNd_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/GatherNd	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/ExpandDims_grad/Shape	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/ExpandDims	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/strided_slice_1	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/re_add_padding/Reshape/shape	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/re_add_padding/mul	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/strided_slice	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/re_add_padding/Reshape/shape	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/re_add_padding/mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/tensor	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/ExpandDims_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/ExpandDims_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/ExpandDims	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Shape	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Reshape	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/re_add_padding/Reshape/shape	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/re_add_padding/Reshape	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/re_add_padding/mul	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/re_add_padding/ScatterNd/shape	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Shape	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Shape/_3690	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/re_add_padding/ScatterNd/shape	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/re_add_padding/ScatterNd	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Shape/_3690	_SINK	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2_1/_3693	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1/_3700	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2/_3695	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Prod	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Prod	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Prod/_3698	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2/_3697	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/concat_2	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Prod/_3698	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Prod/_3699	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Prod/_3699	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/stack	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1/_3700	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1/_3701	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1/_3701	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/stack	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/stack	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Reshape	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Reshape	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot_grad/Shape	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/BiasAdd	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/BiasAdd	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Relu	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Relu	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/dropout/div_grad/Shape	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/dropout/div	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/dropout/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Relu_grad/ReluGrad	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/dropout/div_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/dropout/div	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/dropout/mul	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/dropout/Shape	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/dropout/div_grad/Sum	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/dropout/random_uniform/RandomUniform	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/dropout/add	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/dropout/add	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/dropout/Floor	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/dropout/Floor	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/dropout/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/dropout/mul_grad/Mul	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/dropout/mul	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Shape	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Reshape	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Shape	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Shape/_3702	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Shape/_3702	_SINK	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/GatherV2_1/_3705	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Prod_1	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Prod_1/_3712	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/GatherV2/_3707	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Prod	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Prod	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Prod/_3710	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/GatherV2/_3709	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/concat_2	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Prod/_3710	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Prod/_3711	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Prod/_3711	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/stack	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Prod_1/_3712	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Prod_1/_3713	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Prod_1/_3713	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/stack	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/stack	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Reshape	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Reshape	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot_grad/Shape	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/BiasAdd	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/BiasAdd	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/re_add_padding/Squeeze_grad/Shape	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/re_add_padding/Squeeze	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/re_add_padding/Squeeze_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/re_add_padding/Squeeze_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/re_add_padding/Squeeze	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/re_add_padding/ScatterNd	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/re_add_padding/ScatterNd	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/re_add_padding/Reshape_grad/Shape	model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/re_add_padding/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/re_add_padding/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/re_add_padding/Reshape_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/re_add_padding/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/dropout/div_grad/Shape	model/Transformer/encode/encoder_stack/layer_2/ffn/dropout/Shape	model/Transformer/encode/encoder_stack/layer_2/ffn/dropout/div	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/dropout/div_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_2/ffn/dropout/Shape	model/Transformer/encode/encoder_stack/layer_2/ffn/dropout/random_uniform/RandomUniform	
model/Transformer/encode/encoder_stack/layer_2/ffn/dropout/div	model/Transformer/encode/encoder_stack/layer_2/ffn/dropout/mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/dropout/div_grad/Sum	
model/Transformer/encode/encoder_stack/layer_2/ffn/dropout/random_uniform/RandomUniform	model/Transformer/encode/encoder_stack/layer_2/ffn/dropout/add	
model/Transformer/encode/encoder_stack/layer_2/ffn/dropout/add	model/Transformer/encode/encoder_stack/layer_2/ffn/dropout/Floor	
model/Transformer/encode/encoder_stack/layer_2/ffn/dropout/Floor	model/Transformer/encode/encoder_stack/layer_2/ffn/dropout/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/dropout/mul_grad/Mul	
model/Transformer/encode/encoder_stack/layer_2/ffn/dropout/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/add_grad/Shape_1	model/Transformer/encode/encoder_stack/layer_2/ffn/add	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/add_grad/Reshape_1	
model/Transformer/encode/encoder_stack/layer_2/ffn/add	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/add_grad/Shape	model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Prod	model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_1	model/Transformer/encode/encoder_stack/layer_3/self_attention/add	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Shape/_3714	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/floordiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/add_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/add_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_grad/Shape_1	model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Shape/_3714	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Shape/_3715	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Shape/_3715	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/DynamicStitch/_3716	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_grad/Reshape_1	
model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_grad/Shape	model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Square	model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Prod_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/DynamicStitch/_3716	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/DynamicStitch/_3717	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/DynamicStitch/_3717	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/floordiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Square	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Shape	model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Prod	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/floordiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Shape/_3718	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/floordiv	
model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_grad/Shape	model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/floordiv_1/_3720	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Shape/_3718	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Shape/_3719	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Shape/_3719	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/DynamicStitch/_3722	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add	model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Rsqrt	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Prod_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/floordiv_1/_3720	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/floordiv_1/_3721	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/floordiv_1/_3721	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Cast	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Cast	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/DynamicStitch/_3722	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/DynamicStitch/_3723	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/DynamicStitch/_3723	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/floordiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_grad/Sum	
model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Rsqrt	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_grad/Shape_1	model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/floordiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_grad/Reshape_1	
model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Shape	model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/floordiv_1/_3724	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/Shape	model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/floordiv_1/_3724	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/floordiv_1/_3725	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/floordiv_1/_3725	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Cast	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Cast	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_1	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/v/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/k/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Reshape_grad/Shape	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/Sum_1	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Shape	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Shape/_3726	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/v/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/k/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Shape/_3726	_SINK	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/GatherV2_1/_3729	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Prod_1	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Prod_1/_3736	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/GatherV2/_3731	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Prod	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Prod	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Prod/_3734	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/GatherV2/_3733	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/concat_2	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/k/Tensordot	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/v/Tensordot	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Prod/_3734	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Prod/_3735	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Prod/_3735	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/stack	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Prod_1/_3736	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Prod_1/_3737	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Prod_1/_3737	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/stack	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/stack	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Reshape	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Reshape	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/MatMul	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/k/Tensordot/MatMul	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/v/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot_grad/Shape	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads/Reshape	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/k/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/k/Tensordot_grad/Shape	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/k/Tensordot	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_1/Reshape	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/v/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/v/Tensordot_grad/Shape	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/v/Tensordot	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_2/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads/Shape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/k/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/k/Tensordot_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/k/Tensordot	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_1/Shape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/v/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/v/Tensordot_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/v/Tensordot	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_2/Shape	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads/Shape	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads/strided_slice_1	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_1/Shape	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_1/strided_slice_1	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_2/Shape	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_2/strided_slice	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads/strided_slice_1	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_1/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_1/strided_slice_1	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_1/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_2/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_2/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads/Reshape/shape	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads/Reshape	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_1/Reshape/shape	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_1/Reshape	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_2/Reshape/shape	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_2/Reshape	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads/Reshape	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads/transpose	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_1/Reshape	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_1/transpose	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_2/Reshape	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_2/transpose	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/mul_grad/Shape	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/mul	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_1/transpose	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/MatMul_grad/MatMul	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_2/transpose	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/MatMul_1_grad/MatMul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/mul_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/mul	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/mul_grad/Sum	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/add_grad/Shape	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/add	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/add_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/add_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/add	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/attention_weights	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/add_grad/Sum	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/attention_weights	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/div_grad/Shape	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/div	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/attention_weights_grad/mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/div_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/div	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/mul_grad/Shape	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/mul	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/Shape	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/mul_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/random_uniform/RandomUniform	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/random_uniform/mul	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/random_uniform/mul	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/add	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/add	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/Floor	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/Floor	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/mul_grad/Shape_1	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/mul_grad/BroadcastGradientArgs	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/mul	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/MatMul_1_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/mul_grad/Sum	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/MatMul_1	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/combine_heads/transpose	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/combine_heads/Shape	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/combine_heads/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/combine_heads/Reshape_grad/Shape	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/combine_heads/Reshape	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/combine_heads/Shape	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/combine_heads/strided_slice_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/combine_heads/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/combine_heads/Reshape_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/combine_heads/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/combine_heads/strided_slice_1	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/combine_heads/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/combine_heads/Reshape/shape	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/combine_heads/Reshape	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/combine_heads/Reshape	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Shape	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Reshape	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Shape	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Shape/_3738	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Shape/_3738	_SINK	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/GatherV2_1/_3741	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Prod_1	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Prod_1/_3748	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/GatherV2/_3743	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Prod	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Prod	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Prod/_3746	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/GatherV2/_3745	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/concat_2	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Prod/_3746	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Prod/_3747	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Prod/_3747	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/stack	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Prod_1/_3748	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Prod_1/_3749	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Prod_1/_3749	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/stack	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/stack	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Reshape	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Reshape	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot_grad/Shape	model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/dropout/div_grad/Shape	model/Transformer/encode/encoder_stack/layer_3/self_attention/dropout/div	model/Transformer/encode/encoder_stack/layer_3/self_attention/dropout/Shape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/dropout/div_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_3/self_attention/dropout/div	model/Transformer/encode/encoder_stack/layer_3/self_attention/dropout/mul	
model/Transformer/encode/encoder_stack/layer_3/self_attention/dropout/Shape	model/Transformer/encode/encoder_stack/layer_3/self_attention/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/dropout/div_grad/Sum	
model/Transformer/encode/encoder_stack/layer_3/self_attention/dropout/random_uniform/RandomUniform	model/Transformer/encode/encoder_stack/layer_3/self_attention/dropout/add	
model/Transformer/encode/encoder_stack/layer_3/self_attention/dropout/add	model/Transformer/encode/encoder_stack/layer_3/self_attention/dropout/Floor	
model/Transformer/encode/encoder_stack/layer_3/self_attention/dropout/Floor	model/Transformer/encode/encoder_stack/layer_3/self_attention/dropout/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/dropout/mul_grad/Mul	
model/Transformer/encode/encoder_stack/layer_3/self_attention/dropout/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/add_grad/Shape_1	model/Transformer/encode/encoder_stack/layer_3/self_attention/add	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/add_grad/Reshape_1	
model/Transformer/encode/encoder_stack/layer_3/self_attention/add	model/Transformer/encode/encoder_stack/layer_3/ffn/add	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/add_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Shape	model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Prod	model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/add_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Shape/_3750	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/floordiv	
model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_grad/Shape_1	model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Shape/_3750	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Shape/_3751	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Shape/_3751	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/DynamicStitch/_3752	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_grad/Reshape_1	
model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_grad/Shape	model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Square	model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Prod_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/DynamicStitch/_3752	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/DynamicStitch/_3753	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/DynamicStitch/_3753	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/floordiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Square	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Shape	model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Prod	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/floordiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Shape/_3754	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/floordiv	
model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_grad/Shape	model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/floordiv_1/_3756	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Shape/_3754	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Shape/_3755	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Shape/_3755	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/DynamicStitch/_3758	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add	model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Rsqrt	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Prod_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/floordiv_1/_3756	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/floordiv_1/_3757	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/floordiv_1/_3757	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Cast	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Cast	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/DynamicStitch/_3758	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/DynamicStitch/_3759	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/DynamicStitch/_3759	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/floordiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_grad/Sum	
model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Rsqrt	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_grad/Shape_1	model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/floordiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_grad/Reshape_1	
model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Shape	model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/floordiv_1/_3760	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_1_grad/Shape	model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/floordiv_1/_3760	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/floordiv_1/_3761	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/floordiv_1/_3761	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Cast	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Cast	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_1_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Shape	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/Reshape_1	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/Shape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/GatherNd_grad/Shape	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/GatherNd	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/Shape	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/strided_slice	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/strided_slice_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/GatherNd_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/GatherNd	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/ExpandDims_grad/Shape	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/ExpandDims	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/strided_slice	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/re_add_padding/mul	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/re_add_padding/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/strided_slice_1	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/re_add_padding/mul	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/re_add_padding/Reshape/shape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/tensor	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/ExpandDims_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/ExpandDims_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/ExpandDims	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Shape	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Reshape	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/re_add_padding/mul	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/re_add_padding/ScatterNd/shape	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/re_add_padding/Reshape/shape	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/re_add_padding/Reshape	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Shape	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Shape/_3762	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/re_add_padding/ScatterNd/shape	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/re_add_padding/ScatterNd	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Shape/_3762	_SINK	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2_1/_3765	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1/_3772	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2/_3767	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Prod	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Prod	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Prod/_3770	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2/_3769	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/concat_2	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Prod/_3770	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Prod/_3771	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Prod/_3771	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/stack	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1/_3772	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1/_3773	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1/_3773	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/stack	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/stack	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Reshape	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Reshape	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot_grad/Shape	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/BiasAdd	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/BiasAdd	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Relu	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Relu	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/dropout/div_grad/Shape	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/dropout/div	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/dropout/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Relu_grad/ReluGrad	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/dropout/div_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/dropout/div	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/dropout/mul	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/dropout/Shape	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/dropout/div_grad/Sum	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/dropout/random_uniform/RandomUniform	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/dropout/add	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/dropout/add	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/dropout/Floor	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/dropout/Floor	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/dropout/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/dropout/mul_grad/Mul	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/dropout/mul	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Shape	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Reshape	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Shape	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Shape/_3774	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Shape/_3774	_SINK	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/GatherV2_1/_3777	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Prod_1	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Prod_1/_3784	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/GatherV2/_3779	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Prod	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Prod	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Prod/_3782	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/GatherV2/_3781	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/concat_2	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Prod/_3782	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Prod/_3783	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Prod/_3783	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/stack	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Prod_1/_3784	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Prod_1/_3785	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Prod_1/_3785	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/stack	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/stack	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Reshape	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Reshape	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot_grad/Shape	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/BiasAdd	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/BiasAdd	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/re_add_padding/Squeeze_grad/Shape	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/re_add_padding/Squeeze	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/re_add_padding/Squeeze_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/re_add_padding/Squeeze_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/re_add_padding/Squeeze	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/re_add_padding/ScatterNd	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/re_add_padding/ScatterNd	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/re_add_padding/Reshape_grad/Shape	model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/re_add_padding/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/re_add_padding/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/re_add_padding/Reshape_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/re_add_padding/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/dropout/div_grad/Shape	model/Transformer/encode/encoder_stack/layer_3/ffn/dropout/div	model/Transformer/encode/encoder_stack/layer_3/ffn/dropout/Shape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/dropout/div_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_3/ffn/dropout/div	model/Transformer/encode/encoder_stack/layer_3/ffn/dropout/mul	
model/Transformer/encode/encoder_stack/layer_3/ffn/dropout/Shape	model/Transformer/encode/encoder_stack/layer_3/ffn/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/dropout/div_grad/Sum	
model/Transformer/encode/encoder_stack/layer_3/ffn/dropout/random_uniform/RandomUniform	model/Transformer/encode/encoder_stack/layer_3/ffn/dropout/add	
model/Transformer/encode/encoder_stack/layer_3/ffn/dropout/add	model/Transformer/encode/encoder_stack/layer_3/ffn/dropout/Floor	
model/Transformer/encode/encoder_stack/layer_3/ffn/dropout/Floor	model/Transformer/encode/encoder_stack/layer_3/ffn/dropout/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/dropout/mul_grad/Mul	
model/Transformer/encode/encoder_stack/layer_3/ffn/dropout/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/add_grad/Shape_1	model/Transformer/encode/encoder_stack/layer_3/ffn/add	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/add_grad/Reshape_1	
model/Transformer/encode/encoder_stack/layer_3/ffn/add	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/add_grad/Shape	model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Prod	model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_1	model/Transformer/encode/encoder_stack/layer_4/self_attention/add	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Shape/_3786	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/floordiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/add_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/add_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_grad/Shape_1	model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Shape/_3786	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Shape/_3787	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Shape/_3787	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/DynamicStitch/_3788	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_grad/Reshape_1	
model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_grad/Shape	model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Square	model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Prod_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/DynamicStitch/_3788	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/DynamicStitch/_3789	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/DynamicStitch/_3789	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/floordiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Square	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Shape	model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Prod	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/floordiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Shape/_3790	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/floordiv	
model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_grad/Shape	model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/floordiv_1/_3792	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Shape/_3790	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Shape/_3791	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Shape/_3791	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/DynamicStitch/_3794	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add	model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Rsqrt	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Prod_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/floordiv_1/_3792	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/floordiv_1/_3793	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/floordiv_1/_3793	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Cast	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Cast	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/DynamicStitch/_3794	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/DynamicStitch/_3795	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/DynamicStitch/_3795	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/floordiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_grad/Sum	
model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Rsqrt	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_grad/Shape_1	model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/floordiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_grad/Reshape_1	
model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Shape	model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/floordiv_1/_3796	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/Shape	model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/floordiv_1/_3796	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/floordiv_1/_3797	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/floordiv_1/_3797	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Cast	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Cast	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_1	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/v/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/k/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Reshape_grad/Shape	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/Sum_1	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Shape	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Shape/_3798	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/v/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/k/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Shape/_3798	_SINK	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/GatherV2_1/_3801	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Prod_1	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Prod_1/_3808	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/GatherV2/_3803	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Prod	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Prod	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Prod/_3806	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/GatherV2/_3805	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/concat_2	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/k/Tensordot	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/v/Tensordot	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Prod/_3806	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Prod/_3807	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Prod/_3807	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/stack	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Prod_1/_3808	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Prod_1/_3809	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Prod_1/_3809	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/stack	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/stack	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Reshape	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Reshape	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/MatMul	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/k/Tensordot/MatMul	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/v/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot_grad/Shape	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads/Reshape	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/k/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/k/Tensordot_grad/Shape	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/k/Tensordot	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_1/Reshape	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/v/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/v/Tensordot_grad/Shape	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/v/Tensordot	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_2/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads/Shape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/k/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/k/Tensordot_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/k/Tensordot	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_1/Shape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/v/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/v/Tensordot_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/v/Tensordot	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_2/Shape	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads/Shape	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads/strided_slice_1	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_1/Shape	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_1/strided_slice_1	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_2/Shape	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_2/strided_slice_1	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads/strided_slice_1	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_1/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_1/strided_slice_1	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_1/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_2/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_2/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads/Reshape/shape	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads/Reshape	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_1/Reshape/shape	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_1/Reshape	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_2/Reshape/shape	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_2/Reshape	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads/Reshape	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads/transpose	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_1/Reshape	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_1/transpose	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_2/Reshape	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_2/transpose	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/mul_grad/Shape	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/mul	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_1/transpose	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/MatMul_grad/MatMul	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_2/transpose	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/MatMul_1_grad/MatMul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/mul_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/mul	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/mul_grad/Sum	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/add_grad/Shape	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/add	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/add_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/add_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/add	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/attention_weights	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/add_grad/Sum	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/attention_weights	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/div_grad/Shape	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/div	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/attention_weights_grad/mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/div_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/div	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/mul_grad/Shape	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/mul	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/Shape	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/mul_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/random_uniform/RandomUniform	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/random_uniform/mul	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/random_uniform/mul	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/add	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/add	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/Floor	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/Floor	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/mul_grad/Shape_1	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/mul_grad/BroadcastGradientArgs	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/mul	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/MatMul_1_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/mul_grad/Sum	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/MatMul_1	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/combine_heads/transpose	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/combine_heads/Shape	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/combine_heads/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/combine_heads/Reshape_grad/Shape	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/combine_heads/Reshape	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/combine_heads/Shape	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/combine_heads/strided_slice_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/combine_heads/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/combine_heads/Reshape_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/combine_heads/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/combine_heads/strided_slice_1	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/combine_heads/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/combine_heads/Reshape/shape	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/combine_heads/Reshape	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/combine_heads/Reshape	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Shape	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Reshape	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Shape	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Shape/_3810	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Shape/_3810	_SINK	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/GatherV2_1/_3813	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Prod_1	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Prod_1/_3820	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/GatherV2/_3815	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Prod	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Prod	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Prod/_3818	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/GatherV2/_3817	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/concat_2	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Prod/_3818	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Prod/_3819	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Prod/_3819	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/stack	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Prod_1/_3820	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Prod_1/_3821	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Prod_1/_3821	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/stack	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/stack	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Reshape	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Reshape	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot_grad/Shape	model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/dropout/div_grad/Shape	model/Transformer/encode/encoder_stack/layer_4/self_attention/dropout/div	model/Transformer/encode/encoder_stack/layer_4/self_attention/dropout/Shape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/dropout/div_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_4/self_attention/dropout/div	model/Transformer/encode/encoder_stack/layer_4/self_attention/dropout/mul	
model/Transformer/encode/encoder_stack/layer_4/self_attention/dropout/Shape	model/Transformer/encode/encoder_stack/layer_4/self_attention/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/dropout/div_grad/Sum	
model/Transformer/encode/encoder_stack/layer_4/self_attention/dropout/random_uniform/RandomUniform	model/Transformer/encode/encoder_stack/layer_4/self_attention/dropout/add	
model/Transformer/encode/encoder_stack/layer_4/self_attention/dropout/add	model/Transformer/encode/encoder_stack/layer_4/self_attention/dropout/Floor	
model/Transformer/encode/encoder_stack/layer_4/self_attention/dropout/Floor	model/Transformer/encode/encoder_stack/layer_4/self_attention/dropout/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/dropout/mul_grad/Mul	
model/Transformer/encode/encoder_stack/layer_4/self_attention/dropout/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/add_grad/Shape_1	model/Transformer/encode/encoder_stack/layer_4/self_attention/add	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/add_grad/Reshape_1	
model/Transformer/encode/encoder_stack/layer_4/self_attention/add	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/add_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Shape	model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Prod	model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_1	model/Transformer/encode/encoder_stack/layer_4/ffn/add	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/add_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Shape/_3822	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/floordiv	
model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_grad/Shape_1	model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Shape/_3822	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Shape/_3823	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Shape/_3823	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/DynamicStitch/_3824	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_grad/Reshape_1	
model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_grad/Shape	model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Square	model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Prod_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/DynamicStitch/_3824	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/DynamicStitch/_3825	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/DynamicStitch/_3825	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/floordiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Square	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Shape	model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Prod	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/floordiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Shape/_3826	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/floordiv	
model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_grad/Shape	model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/floordiv_1/_3828	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Shape/_3826	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Shape/_3827	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Shape/_3827	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/DynamicStitch/_3830	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add	model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Rsqrt	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Prod_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/floordiv_1/_3828	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/floordiv_1/_3829	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/floordiv_1/_3829	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Cast	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Cast	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/DynamicStitch/_3830	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/DynamicStitch/_3831	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/DynamicStitch/_3831	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/floordiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_grad/Sum	
model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Rsqrt	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_grad/Shape_1	model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/floordiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_grad/Reshape_1	
model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Shape	model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/floordiv_1/_3832	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_1_grad/Shape	model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/floordiv_1/_3832	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/floordiv_1/_3833	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/floordiv_1/_3833	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Cast	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Cast	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_1_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Shape	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/Reshape_1	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/Shape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/GatherNd_grad/Shape	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/GatherNd	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/Shape	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/strided_slice	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/strided_slice_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/GatherNd_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/GatherNd	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/ExpandDims_grad/Shape	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/ExpandDims	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/strided_slice	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/re_add_padding/mul	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/re_add_padding/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/strided_slice_1	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/re_add_padding/mul	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/re_add_padding/Reshape/shape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/tensor	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/ExpandDims_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/ExpandDims_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/ExpandDims	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Shape	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Reshape	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/re_add_padding/mul	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/re_add_padding/ScatterNd/shape	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/re_add_padding/Reshape/shape	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/re_add_padding/Reshape	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Shape	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Shape/_3834	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/re_add_padding/ScatterNd/shape	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/re_add_padding/ScatterNd	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Shape/_3834	_SINK	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2_1/_3837	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1/_3844	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2/_3839	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Prod	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Prod	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Prod/_3842	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2/_3841	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/concat_2	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Prod/_3842	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Prod/_3843	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Prod/_3843	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/stack	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1/_3844	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1/_3845	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1/_3845	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/stack	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/stack	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Reshape	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Reshape	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot_grad/Shape	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/BiasAdd	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/BiasAdd	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Relu	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Relu	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/dropout/div_grad/Shape	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/dropout/div	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/dropout/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Relu_grad/ReluGrad	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/dropout/div_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/dropout/div	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/dropout/mul	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/dropout/Shape	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/dropout/div_grad/Sum	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/dropout/random_uniform/RandomUniform	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/dropout/add	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/dropout/add	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/dropout/Floor	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/dropout/Floor	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/dropout/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/dropout/mul_grad/Mul	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/dropout/mul	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Shape	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Reshape	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Shape	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Shape/_3846	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Shape/_3846	_SINK	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/GatherV2_1/_3849	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Prod_1	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Prod_1/_3856	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/GatherV2/_3851	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Prod	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Prod	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Prod/_3854	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/GatherV2/_3853	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/concat_2	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Prod/_3854	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Prod/_3855	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Prod/_3855	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/stack	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Prod_1/_3856	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Prod_1/_3857	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Prod_1/_3857	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/stack	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/stack	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Reshape	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Reshape	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot_grad/Shape	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/BiasAdd	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/BiasAdd	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/re_add_padding/Squeeze_grad/Shape	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/re_add_padding/Squeeze	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/re_add_padding/Squeeze_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/re_add_padding/Squeeze_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/re_add_padding/Squeeze	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/re_add_padding/ScatterNd	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/re_add_padding/ScatterNd	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/re_add_padding/Reshape_grad/Shape	model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/re_add_padding/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/re_add_padding/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/re_add_padding/Reshape_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/re_add_padding/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/dropout/div_grad/Shape	model/Transformer/encode/encoder_stack/layer_4/ffn/dropout/div	model/Transformer/encode/encoder_stack/layer_4/ffn/dropout/Shape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/dropout/div_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_4/ffn/dropout/div	model/Transformer/encode/encoder_stack/layer_4/ffn/dropout/mul	
model/Transformer/encode/encoder_stack/layer_4/ffn/dropout/Shape	model/Transformer/encode/encoder_stack/layer_4/ffn/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/dropout/div_grad/Sum	
model/Transformer/encode/encoder_stack/layer_4/ffn/dropout/random_uniform/RandomUniform	model/Transformer/encode/encoder_stack/layer_4/ffn/dropout/add	
model/Transformer/encode/encoder_stack/layer_4/ffn/dropout/add	model/Transformer/encode/encoder_stack/layer_4/ffn/dropout/Floor	
model/Transformer/encode/encoder_stack/layer_4/ffn/dropout/Floor	model/Transformer/encode/encoder_stack/layer_4/ffn/dropout/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/dropout/mul_grad/Mul	
model/Transformer/encode/encoder_stack/layer_4/ffn/dropout/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/add_grad/Shape_1	model/Transformer/encode/encoder_stack/layer_4/ffn/add	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/add_grad/Reshape_1	
model/Transformer/encode/encoder_stack/layer_4/ffn/add	model/Transformer/encode/encoder_stack/layer_5/self_attention/add	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/add_grad/Shape	model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Prod	model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Shape/_3858	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/floordiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/add_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/add_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_grad/Shape_1	model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Shape/_3858	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Shape/_3859	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Shape/_3859	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/DynamicStitch/_3860	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_grad/Reshape_1	
model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_1	model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Square_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_grad/Shape	model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Square	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Prod_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/DynamicStitch/_3860	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/DynamicStitch/_3861	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/DynamicStitch/_3861	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/floordiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Square	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Shape	model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Prod	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/floordiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Shape/_3862	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/floordiv	
model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_grad/Shape	model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/floordiv_1/_3864	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Shape/_3862	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Shape/_3863	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Shape/_3863	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/DynamicStitch/_3866	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add	model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Rsqrt	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Prod_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/floordiv_1/_3864	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/floordiv_1/_3865	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/floordiv_1/_3865	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Cast	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Cast	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/DynamicStitch/_3866	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/DynamicStitch/_3867	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/DynamicStitch/_3867	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/floordiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_grad/Sum	
model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Rsqrt	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_grad/Shape_1	model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/floordiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_grad/Reshape_1	
model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Shape	model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/floordiv_1/_3868	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/Shape	model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/floordiv_1/_3868	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/floordiv_1/_3869	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/floordiv_1/_3869	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Cast	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Cast	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_1	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/v/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/k/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Reshape_grad/Shape	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/Sum_1	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Shape	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Shape/_3870	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/v/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/k/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Shape/_3870	_SINK	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/GatherV2_1/_3873	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Prod_1	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Prod_1/_3880	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/GatherV2/_3875	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Prod	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Prod	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Prod/_3878	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/GatherV2/_3877	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/concat_2	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/k/Tensordot	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/v/Tensordot	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Prod/_3878	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Prod/_3879	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Prod/_3879	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/stack	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Prod_1/_3880	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Prod_1/_3881	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Prod_1/_3881	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/stack	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/stack	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Reshape	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Reshape	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/MatMul	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/k/Tensordot/MatMul	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/v/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot_grad/Shape	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads/Reshape	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/k/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/k/Tensordot_grad/Shape	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/k/Tensordot	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_1/Reshape	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/v/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/v/Tensordot_grad/Shape	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/v/Tensordot	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_2/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads/Shape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/k/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/k/Tensordot_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/k/Tensordot	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_1/Shape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/v/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/v/Tensordot_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/v/Tensordot	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_2/Shape	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads/Shape	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads/strided_slice_1	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_1/Shape	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_1/strided_slice_1	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_2/Shape	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_2/strided_slice	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads/strided_slice_1	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_1/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_1/strided_slice_1	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_1/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_2/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_2/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads/Reshape/shape	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads/Reshape	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_1/Reshape/shape	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_1/Reshape	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_2/Reshape/shape	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_2/Reshape	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads/Reshape	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads/transpose	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_1/Reshape	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_1/transpose	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_2/Reshape	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_2/transpose	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/mul_grad/Shape	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/mul	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_1/transpose	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/MatMul_grad/MatMul	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_2/transpose	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/MatMul_1_grad/MatMul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/mul_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/mul	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/mul_grad/Sum	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/add_grad/Shape	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/add	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/add_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/add_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/add	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/attention_weights	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/add_grad/Sum	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/attention_weights	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/div_grad/Shape	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/div	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/attention_weights_grad/mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/div_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/div	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/mul_grad/Shape	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/mul	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/Shape	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/mul_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/random_uniform/RandomUniform	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/random_uniform/mul	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/random_uniform/mul	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/add	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/add	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/Floor	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/Floor	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/mul_grad/Shape_1	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/mul_grad/BroadcastGradientArgs	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/mul	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/MatMul_1_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/mul_grad/Sum	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/MatMul_1	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/combine_heads/transpose	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/combine_heads/Shape	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/combine_heads/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/combine_heads/Reshape_grad/Shape	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/combine_heads/Reshape	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/combine_heads/Shape	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/combine_heads/strided_slice_1	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/combine_heads/strided_slice	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/combine_heads/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/combine_heads/Reshape_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/combine_heads/strided_slice_1	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/combine_heads/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/combine_heads/Reshape/shape	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/combine_heads/Reshape/shape	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/combine_heads/Reshape	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/combine_heads/Reshape	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Shape	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Reshape	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Shape	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Shape/_3882	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Shape/_3882	_SINK	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/GatherV2/_3885	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/concat_2	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/GatherV2/_3887	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Prod	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Prod	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Prod/_3890	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/GatherV2_1/_3889	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Prod_1	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Prod_1/_3892	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Prod/_3890	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Prod/_3891	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Prod/_3891	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/stack	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Prod_1/_3892	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Prod_1/_3893	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Prod_1/_3893	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/stack	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/stack	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Reshape	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Reshape	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/MatMul	model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot_grad/Shape	
model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot	model/Transformer/encode/encoder_stack/layer_5/self_attention/dropout/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/dropout/div_grad/Shape	model/Transformer/encode/encoder_stack/layer_5/self_attention/dropout/div	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_5/self_attention/dropout/Shape	model/Transformer/encode/encoder_stack/layer_5/self_attention/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/dropout/div_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_5/self_attention/dropout/div	model/Transformer/encode/encoder_stack/layer_5/self_attention/dropout/mul	
model/Transformer/encode/encoder_stack/layer_5/self_attention/dropout/random_uniform/RandomUniform	model/Transformer/encode/encoder_stack/layer_5/self_attention/dropout/add	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/dropout/div_grad/Sum	
model/Transformer/encode/encoder_stack/layer_5/self_attention/dropout/add	model/Transformer/encode/encoder_stack/layer_5/self_attention/dropout/Floor	
model/Transformer/encode/encoder_stack/layer_5/self_attention/dropout/Floor	model/Transformer/encode/encoder_stack/layer_5/self_attention/dropout/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/dropout/mul_grad/Mul	
model/Transformer/encode/encoder_stack/layer_5/self_attention/dropout/mul	model/Transformer/encode/encoder_stack/layer_5/self_attention/add	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/add_grad/Shape_1	
model/Transformer/encode/encoder_stack/layer_5/self_attention/add	model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/add_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Shape	model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Prod	model/Transformer/encode/encoder_stack/layer_5/ffn/add	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/add_grad/Reshape_1	
model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_grad/Shape_1	model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/add_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Shape/_3894	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/floordiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_grad/Reshape_1	
model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_1	model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Square	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_grad/Shape	model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Square_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Prod_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Shape/_3894	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Shape/_3895	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Shape/_3895	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/DynamicStitch/_3896	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_grad/Sum_1	
model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Square	model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Prod	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/DynamicStitch/_3896	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/DynamicStitch/_3897	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/DynamicStitch/_3897	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/floordiv	
model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1	model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Shape/_3898	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/floordiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/floordiv_1/_3900	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/floordiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Tile	
model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add	model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Rsqrt	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Prod_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Shape/_3898	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Shape/_3899	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Shape/_3899	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/DynamicStitch/_3902	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/floordiv_1/_3900	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/floordiv_1/_3901	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/floordiv_1/_3901	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Cast	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Cast	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/truediv	
model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Rsqrt	model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/DynamicStitch/_3902	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/DynamicStitch/_3903	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/DynamicStitch/_3903	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/floordiv	
model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul	model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/floordiv_1/_3904	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/floordiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Tile	
model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_1	model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_1_grad/Shape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/floordiv_1/_3904	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/floordiv_1/_3905	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/floordiv_1/_3905	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Cast	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Cast	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/truediv	
model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Shape	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/Reshape_1	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/Shape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/GatherNd_grad/Shape	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/GatherNd	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/Shape	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/strided_slice_1	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/strided_slice	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/GatherNd_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/GatherNd	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/ExpandDims_grad/Shape	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/ExpandDims	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/strided_slice_1	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/re_add_padding/Reshape/shape	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/re_add_padding/mul	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/strided_slice	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/re_add_padding/Reshape/shape	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/re_add_padding/mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/strided_slice	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/tensor	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/ExpandDims_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/ExpandDims_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/ExpandDims	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Shape	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Reshape	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/re_add_padding/Reshape/shape	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/re_add_padding/Reshape	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/re_add_padding/mul	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/re_add_padding/ScatterNd/shape	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Shape	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Shape/_3906	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/re_add_padding/ScatterNd/shape	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/re_add_padding/ScatterNd	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Shape/_3906	_SINK	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2_1/_3909	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1/_3916	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2/_3911	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Prod	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Prod	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Prod/_3914	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2/_3913	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/concat_2	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Prod/_3914	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Prod/_3915	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Prod/_3915	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/stack	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1/_3916	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1/_3917	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1/_3917	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/stack	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/stack	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Reshape	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Reshape	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot_grad/Shape	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/BiasAdd	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/BiasAdd	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Relu	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Relu	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/dropout/div_grad/Shape	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/dropout/div	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/dropout/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Relu_grad/ReluGrad	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/dropout/div_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/dropout/div	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/dropout/mul	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/dropout/Shape	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/dropout/div_grad/Sum	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/dropout/random_uniform/RandomUniform	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/dropout/add	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/dropout/add	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/dropout/Floor	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/dropout/Floor	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/dropout/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/dropout/mul_grad/Mul	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/dropout/mul	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Shape	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Reshape	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Shape	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Shape/_3918	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Shape/_3918	_SINK	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/GatherV2_1/_3921	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Prod_1	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Prod_1	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Prod_1/_3928	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/GatherV2/_3923	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Prod	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Prod	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Prod/_3926	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/GatherV2/_3925	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/concat_2	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/concat_2	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Prod/_3926	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Prod/_3927	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Prod/_3927	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/stack	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Prod_1/_3928	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Prod_1/_3929	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Prod_1/_3929	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/stack	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/stack	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Reshape	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Reshape	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot_grad/Shape	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/BiasAdd	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/BiasAdd	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/re_add_padding/Squeeze_grad/Shape	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/re_add_padding/Squeeze	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/re_add_padding/Squeeze_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/re_add_padding/Squeeze_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/re_add_padding/Squeeze	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/re_add_padding/ScatterNd	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/re_add_padding/ScatterNd	model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/re_add_padding/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/re_add_padding/Reshape_grad/Shape	
model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/re_add_padding/Reshape	model/Transformer/encode/encoder_stack/layer_5/ffn/dropout/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/dropout/div_grad/Shape	model/Transformer/encode/encoder_stack/layer_5/ffn/dropout/div	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/re_add_padding/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/re_add_padding/Reshape_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_5/ffn/dropout/Shape	model/Transformer/encode/encoder_stack/layer_5/ffn/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/dropout/div_grad/Reshape	
model/Transformer/encode/encoder_stack/layer_5/ffn/dropout/div	model/Transformer/encode/encoder_stack/layer_5/ffn/dropout/mul	
model/Transformer/encode/encoder_stack/layer_5/ffn/dropout/random_uniform/RandomUniform	model/Transformer/encode/encoder_stack/layer_5/ffn/dropout/add	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/dropout/div_grad/Sum	
model/Transformer/encode/encoder_stack/layer_5/ffn/dropout/add	model/Transformer/encode/encoder_stack/layer_5/ffn/dropout/Floor	
model/Transformer/encode/encoder_stack/layer_5/ffn/dropout/Floor	model/Transformer/encode/encoder_stack/layer_5/ffn/dropout/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/dropout/mul_grad/Mul	
model/Transformer/encode/encoder_stack/layer_5/ffn/dropout/mul	model/Transformer/encode/encoder_stack/layer_5/ffn/add	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/add_grad/Shape_1	
model/Transformer/encode/encoder_stack/layer_5/ffn/add	model/Transformer/encode/encoder_stack/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/Shape	model/Transformer/encode/encoder_stack/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/Prod	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/add_grad/Reshape_1	
model/Transformer/encode/encoder_stack/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_grad/Shape_1	model/Transformer/encode/encoder_stack/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/Shape/_3930	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/floordiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_grad/Reshape_1	
model/Transformer/encode/encoder_stack/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Square_grad/Mul	model/Transformer/encode/encoder_stack/layer_normalization/Square	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_grad/Shape	model/Transformer/encode/encoder_stack/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/Prod_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/Shape/_3930	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/Shape/_3931	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/Shape/_3931	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/DynamicStitch/_3932	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_grad/Sum_1	
model/Transformer/encode/encoder_stack/layer_normalization/Square	model/Transformer/encode/encoder_stack/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/Prod	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/DynamicStitch/_3932	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/DynamicStitch/_3933	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/DynamicStitch/_3933	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/floordiv	
model/Transformer/encode/encoder_stack/layer_normalization/Mean_1	model/Transformer/encode/encoder_stack/layer_normalization/add	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/add_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/Shape/_3934	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/floordiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/floordiv_1/_3936	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/floordiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/Tile	
model/Transformer/encode/encoder_stack/layer_normalization/add	model/Transformer/encode/encoder_stack/layer_normalization/Rsqrt	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/add_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/Prod_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/Shape/_3934	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/Shape/_3935	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/Shape/_3935	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/DynamicStitch/_3938	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/floordiv_1/_3936	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/floordiv_1/_3937	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/floordiv_1/_3937	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/Cast	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/Cast	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/truediv	
model/Transformer/encode/encoder_stack/layer_normalization/Rsqrt	model/Transformer/encode/encoder_stack/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/DynamicStitch/_3938	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/DynamicStitch/_3939	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/DynamicStitch/_3939	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/floordiv	
model/Transformer/encode/encoder_stack/layer_normalization/mul	model/Transformer/encode/encoder_stack/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/floordiv_1/_3940	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/floordiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/Tile	
model/Transformer/encode/encoder_stack/layer_normalization/mul_1	model/Transformer/encode/encoder_stack/layer_normalization/add_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/add_1_grad/Shape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/floordiv_1/_3940	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/floordiv_1/_3941	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/floordiv_1/_3941	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/Cast	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/Cast	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/truediv	
model/Transformer/encode/encoder_stack/layer_normalization/add_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/k/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/v/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/k/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/v/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/k/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/v/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/k/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/v/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/Reshape_grad/Shape	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/Reshape	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/v/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/k/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/v/Tensordot/Reshape_grad/Shape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/add_1_grad/Shape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/add_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_1_grad/Sum_1	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/Shape	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/Shape/_3942	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/v/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/v/Tensordot/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/k/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/k/Tensordot/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/v/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/v/Tensordot/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/k/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/k/Tensordot/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/v/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/v/Tensordot/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/k/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/k/Tensordot/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/v/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/v/Tensordot/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/k/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/k/Tensordot/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/v/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/v/Tensordot/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/k/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/k/Tensordot/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/v/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/v/Tensordot/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/add_1_grad/Sum_1	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/Shape/_3942	_SINK	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/GatherV2_1/_3945	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/Prod_1	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/Prod_1/_3952	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/GatherV2/_3947	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/Prod	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/Prod/_3950	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/GatherV2/_3949	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/concat_2	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/k/Tensordot	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/v/Tensordot	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/k/Tensordot	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/v/Tensordot	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/k/Tensordot	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/v/Tensordot	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/v/Tensordot	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/k/Tensordot	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/v/Tensordot	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/k/Tensordot	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/v/Tensordot	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/Prod/_3950	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/Prod/_3951	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/Prod/_3951	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/Prod_1/_3952	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/Prod_1/_3953	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/Prod_1/_3953	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/stack	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/Reshape	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/k/Tensordot/MatMul	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/v/Tensordot/MatMul	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/k/Tensordot/MatMul	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/v/Tensordot/MatMul	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/k/Tensordot/MatMul	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/v/Tensordot/MatMul	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/MatMul	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/v/Tensordot/MatMul	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/k/Tensordot/MatMul	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/v/Tensordot/MatMul	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/k/Tensordot/MatMul	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/v/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/v/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/k/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/v/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/k/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/v/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/v/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/k/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/k/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/v/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/k/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/v/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/k/Tensordot/MatMul	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/k/Tensordot	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/k/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_1/Reshape	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/v/Tensordot/MatMul	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/v/Tensordot	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/v/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_2/Reshape	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/k/Tensordot/MatMul	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/k/Tensordot	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/k/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_1/Reshape	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/v/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/v/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/v/Tensordot	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_2/Reshape	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/k/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/k/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/k/Tensordot	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_1/Reshape	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/v/Tensordot/MatMul	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/v/Tensordot	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/v/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_2/Reshape	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_1/Reshape	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/v/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/v/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/v/Tensordot	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_2/Reshape	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/k/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/k/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/k/Tensordot	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_1/Reshape	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/v/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/v/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/v/Tensordot	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_2/Reshape	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/k/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/k/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/k/Tensordot	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_1/Reshape	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/v/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/v/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/v/Tensordot	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_2/Reshape	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/k/Tensordot	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_1/Shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/k/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/k/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/v/Tensordot	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_2/Shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/v/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/v/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/k/Tensordot	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_1/Shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/k/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/k/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/v/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/v/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/v/Tensordot	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_2/Shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/k/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/k/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/k/Tensordot	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_1/Shape	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/v/Tensordot	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_2/Shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/v/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/v/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_1/Shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/v/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/v/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/v/Tensordot	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_2/Shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/k/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/k/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/k/Tensordot	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_1/Shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/v/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/v/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/v/Tensordot	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_2/Shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/k/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/k/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/k/Tensordot	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_1/Shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/v/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/v/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/v/Tensordot	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_2/Shape	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_1/Shape	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_1/strided_slice_1	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_2/Shape	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_2/strided_slice_1	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_1/Shape	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_1/strided_slice_1	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_2/Shape	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_2/strided_slice_1	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_1/Shape	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_1/strided_slice_1	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_2/Shape	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_2/strided_slice	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_1/Shape	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_1/strided_slice_1	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_2/Shape	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_2/strided_slice_1	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_1/Shape	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_1/strided_slice_1	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_2/Shape	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_2/strided_slice_1	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_1/Shape	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_1/strided_slice_1	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_2/Shape	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_2/strided_slice_1	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_1/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_1/strided_slice_1	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_1/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_2/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_2/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_1/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_1/strided_slice_1	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_1/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_2/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_2/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_1/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_1/strided_slice_1	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_1/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_2/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_2/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_1/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_1/strided_slice_1	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_1/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_2/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_2/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_1/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_1/strided_slice_1	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_1/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_2/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_2/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_1/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_1/strided_slice_1	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_1/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_2/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_2/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_1/Reshape/shape	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_1/Reshape	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_2/Reshape/shape	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_2/Reshape	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_1/Reshape/shape	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_1/Reshape	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_2/Reshape/shape	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_2/Reshape	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_1/Reshape/shape	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_1/Reshape	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_2/Reshape/shape	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_2/Reshape	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_1/Reshape/shape	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_1/Reshape	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_2/Reshape/shape	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_2/Reshape	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_1/Reshape/shape	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_1/Reshape	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_2/Reshape/shape	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_2/Reshape	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_1/Reshape/shape	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_1/Reshape	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_2/Reshape/shape	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_2/Reshape	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_1/Reshape	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_1/transpose	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_2/Reshape	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_2/transpose	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_1/Reshape	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_1/transpose	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_2/Reshape	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_2/transpose	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_1/Reshape	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_1/transpose	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_2/Reshape	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_2/transpose	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_1/Reshape	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_1/transpose	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_2/Reshape	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_2/transpose	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_1/Reshape	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_1/transpose	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_2/Reshape	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_2/transpose	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_1/Reshape	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_1/transpose	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_2/Reshape	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_2/transpose	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_1/transpose	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_2/transpose	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/MatMul_1_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_1/transpose	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_2/transpose	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/MatMul_1_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_1/transpose	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_2/transpose	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/MatMul_1_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_1/transpose	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_2/transpose	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/MatMul_1_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_1/transpose	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_2/transpose	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/MatMul_1_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_1/transpose	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_2/transpose	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/MatMul_1_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/add_grad/Shape	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/add	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/add_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/add	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/attention_weights	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/add_grad/Sum	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/attention_weights	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/div_grad/Shape	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/div	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/attention_weights_grad/mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/div_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/div	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/mul_grad/Shape	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/mul	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/Shape	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/mul_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/random_uniform/RandomUniform	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/random_uniform/mul	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/random_uniform/mul	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/add	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/add	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/Floor	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/Floor	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/mul_grad/Shape_1	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/mul_grad/BroadcastGradientArgs	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/mul	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/MatMul_1_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/mul_grad/Sum	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/MatMul_1	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/combine_heads/transpose	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/combine_heads/Shape	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/combine_heads/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/combine_heads/Reshape_grad/Shape	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/combine_heads/Reshape	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/combine_heads/Shape	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/combine_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/combine_heads/strided_slice_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/combine_heads/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/combine_heads/Reshape_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/combine_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/combine_heads/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/combine_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/combine_heads/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/combine_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/combine_heads/Reshape	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/combine_heads/Reshape	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/Reshape_grad/Shape	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/Shape	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/Shape/_3954	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/Reshape_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/Shape/_3954	_SINK	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/GatherV2_1/_3957	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/Prod_1	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/Prod_1/_3964	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/GatherV2/_3959	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/Prod	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/Prod/_3962	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/GatherV2/_3961	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/concat_2	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/Prod/_3962	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/Prod/_3963	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/Prod/_3963	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/Prod_1/_3964	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/Prod_1/_3965	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/Prod_1/_3965	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/stack	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/Reshape	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/dropout/div_grad/Shape	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/dropout/div	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/dropout/Shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/dropout/div_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/dropout/div	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/dropout/mul	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/dropout/Shape	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/dropout/div_grad/Sum	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/dropout/random_uniform/RandomUniform	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/dropout/add	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/dropout/add	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/dropout/Floor	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/dropout/Floor	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/dropout/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/dropout/mul_grad/Mul	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/dropout/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/add_grad/Shape_1	model/Transformer/decode/decoder_stack/layer_0/encdec_attention/add	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/add_grad/Reshape_1	
model/Transformer/decode/decoder_stack/layer_0/encdec_attention/add	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/sub_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Shape	model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Prod	model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/sub_1	model/Transformer/decode/decoder_stack/layer_0/ffn/add	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/sub_grad/Shape	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Shape/_3966	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/floordiv	
model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/sub_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/sub_grad/Shape_1	model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Shape/_3966	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Shape/_3967	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Shape/_3967	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/DynamicStitch/_3968	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/sub_1_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/sub_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/sub_grad/Reshape_1	
model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/sub_1	model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Square	model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Prod_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/DynamicStitch/_3968	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/DynamicStitch/_3969	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/DynamicStitch/_3969	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/floordiv	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/sub_1_grad/Sum_1	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/sub_grad/Sum_1	
model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Square	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Shape	model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Prod	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/floordiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Shape/_3970	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/floordiv	
model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_grad/Shape	model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/floordiv_1/_3972	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Shape/_3970	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Shape/_3971	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Shape/_3971	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/DynamicStitch/_3974	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add	model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Rsqrt	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Prod_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/floordiv_1/_3972	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/floordiv_1/_3973	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/floordiv_1/_3973	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Cast	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Cast	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/DynamicStitch/_3974	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/DynamicStitch/_3975	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/DynamicStitch/_3975	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/floordiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_grad/Sum	
model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Rsqrt	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_grad/Shape_1	model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/floordiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_grad/Reshape_1	
model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Shape	model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/floordiv_1/_3976	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_1_grad/Shape	model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/floordiv_1/_3976	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/floordiv_1/_3977	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/floordiv_1/_3977	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Cast	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Cast	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_1_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_1	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Shape	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_1_grad/Sum_1	
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Shape	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Shape/_3978	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Shape/_3978	_SINK	
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2_1/_3981	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1	
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1/_3988	
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2/_3983	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Prod	
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Prod/_3986	
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2/_3985	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/concat_2	
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot	
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Prod/_3986	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Prod/_3987	
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Prod/_3987	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1/_3988	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1/_3989	
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1/_3989	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/stack	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Reshape	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/BiasAdd	
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/BiasAdd	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Relu	
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Relu	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/dropout/div_grad/Shape	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/dropout/div	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/dropout/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Relu_grad/ReluGrad	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/dropout/div_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/dropout/div	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/dropout/mul	
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/dropout/Shape	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/dropout/div_grad/Sum	
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/dropout/random_uniform/RandomUniform	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/dropout/add	
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/dropout/add	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/dropout/Floor	
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/dropout/Floor	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/dropout/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/dropout/mul_grad/Mul	
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/dropout/mul	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Shape	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Shape	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Shape/_3990	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Shape/_3990	_SINK	
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/GatherV2_1/_3993	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Prod_1	
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Prod_1/_4000	
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/GatherV2/_3995	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Prod	
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Prod/_3998	
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/GatherV2/_3997	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/concat_2	
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot	
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Prod/_3998	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Prod/_3999	
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Prod/_3999	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Prod_1/_4000	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Prod_1/_4001	
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Prod_1/_4001	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/stack	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Reshape	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot	model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/BiasAdd	
model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/BiasAdd	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/dropout/div_grad/Shape	model/Transformer/decode/decoder_stack/layer_0/ffn/dropout/div	model/Transformer/decode/decoder_stack/layer_0/ffn/dropout/Shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/dropout/div_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_0/ffn/dropout/div	model/Transformer/decode/decoder_stack/layer_0/ffn/dropout/mul	
model/Transformer/decode/decoder_stack/layer_0/ffn/dropout/Shape	model/Transformer/decode/decoder_stack/layer_0/ffn/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/dropout/div_grad/Sum	
model/Transformer/decode/decoder_stack/layer_0/ffn/dropout/random_uniform/RandomUniform	model/Transformer/decode/decoder_stack/layer_0/ffn/dropout/add	
model/Transformer/decode/decoder_stack/layer_0/ffn/dropout/add	model/Transformer/decode/decoder_stack/layer_0/ffn/dropout/Floor	
model/Transformer/decode/decoder_stack/layer_0/ffn/dropout/Floor	model/Transformer/decode/decoder_stack/layer_0/ffn/dropout/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/dropout/mul_grad/Mul	
model/Transformer/decode/decoder_stack/layer_0/ffn/dropout/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/add_grad/Shape_1	model/Transformer/decode/decoder_stack/layer_0/ffn/add	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/add_grad/Reshape_1	
model/Transformer/decode/decoder_stack/layer_0/ffn/add	model/Transformer/decode/decoder_stack/layer_1/self_attention/add	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/sub_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Shape	model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Prod	model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/sub_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/sub_grad/Shape	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Shape/_4002	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/floordiv	
model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/sub_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/sub_grad/Shape_1	model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Shape/_4002	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Shape/_4003	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Shape/_4003	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/DynamicStitch/_4004	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/sub_1_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/sub_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/sub_grad/Reshape_1	
model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/sub_1	model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Square	model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Prod_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/DynamicStitch/_4004	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/DynamicStitch/_4005	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/DynamicStitch/_4005	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/floordiv	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/sub_1_grad/Sum_1	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/sub_grad/Sum_1	
model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Square	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Shape	model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Prod	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/floordiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Shape/_4006	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/floordiv	
model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_grad/Shape	model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/floordiv_1/_4008	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Shape/_4006	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Shape/_4007	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Shape/_4007	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/DynamicStitch/_4010	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add	model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Rsqrt	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Prod_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/floordiv_1/_4008	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/floordiv_1/_4009	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/floordiv_1/_4009	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Cast	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Cast	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/DynamicStitch/_4010	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/DynamicStitch/_4011	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/DynamicStitch/_4011	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/floordiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_grad/Sum	
model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Rsqrt	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_grad/Shape_1	model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/floordiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_grad/Reshape_1	
model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Shape	model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/floordiv_1/_4012	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/Shape	model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/floordiv_1/_4012	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/floordiv_1/_4013	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/floordiv_1/_4013	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Cast	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Cast	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_1	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/v/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/k/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Reshape_grad/Shape	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/Sum_1	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Shape	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Shape/_4014	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/v/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/k/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Shape/_4014	_SINK	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/GatherV2_1/_4017	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Prod_1	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Prod_1/_4024	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/GatherV2/_4019	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Prod	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Prod/_4022	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/GatherV2/_4021	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/concat_2	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/k/Tensordot	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/v/Tensordot	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Prod/_4022	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Prod/_4023	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Prod/_4023	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Prod_1/_4024	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Prod_1/_4025	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Prod_1/_4025	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/stack	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Reshape	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/MatMul	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/k/Tensordot/MatMul	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/v/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads/Reshape	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/k/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/k/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/k/Tensordot	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_1/Reshape	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/v/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/v/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/v/Tensordot	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_2/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads/Shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/k/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/k/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/k/Tensordot	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_1/Shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/v/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/v/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/v/Tensordot	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_2/Shape	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads/Shape	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads/strided_slice_1	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_1/Shape	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_1/strided_slice_1	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_2/Shape	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_2/strided_slice_1	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_1/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_1/strided_slice_1	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_1/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_2/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_2/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads/Reshape	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_1/Reshape/shape	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_1/Reshape	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_2/Reshape/shape	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_2/Reshape	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads/Reshape	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads/transpose	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_1/Reshape	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_1/transpose	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_2/Reshape	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_2/transpose	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/mul_grad/Shape	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/mul	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_1/transpose	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_2/transpose	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/MatMul_1_grad/MatMul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/mul_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/mul	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/mul_grad/Sum	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/add_grad/Shape	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/add	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/add_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/add	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/attention_weights	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/add_grad/Sum	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/attention_weights	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/dropout/div_grad/Shape	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/dropout/div	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/dropout/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/attention_weights_grad/mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/dropout/div_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/dropout/div	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/dropout/mul_grad/Shape	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/dropout/mul	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/dropout/Shape	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/dropout/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/dropout/mul_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/dropout/random_uniform/RandomUniform	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/dropout/add	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/dropout/add	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/dropout/Floor	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/dropout/Floor	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/dropout/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/dropout/mul_grad/Mul	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/dropout/mul	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/MatMul_1_grad/MatMul_1	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/MatMul_1	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/combine_heads/transpose	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/combine_heads/Shape	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/combine_heads/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/combine_heads/Reshape_grad/Shape	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/combine_heads/Reshape	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/combine_heads/Shape	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/combine_heads/strided_slice_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/combine_heads/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/combine_heads/Reshape_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/combine_heads/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/combine_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/combine_heads/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/combine_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/combine_heads/Reshape	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/combine_heads/Reshape	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Shape	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Shape	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Shape/_4026	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Shape/_4026	_SINK	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/GatherV2_1/_4029	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Prod_1	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Prod_1/_4036	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/GatherV2/_4031	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Prod	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Prod/_4034	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/GatherV2/_4033	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/concat_2	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Prod/_4034	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Prod/_4035	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Prod/_4035	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Prod_1/_4036	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Prod_1/_4037	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Prod_1/_4037	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/stack	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Reshape	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/dropout/div_grad/Shape	model/Transformer/decode/decoder_stack/layer_1/self_attention/dropout/div	model/Transformer/decode/decoder_stack/layer_1/self_attention/dropout/Shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/dropout/div_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_1/self_attention/dropout/div	model/Transformer/decode/decoder_stack/layer_1/self_attention/dropout/mul	
model/Transformer/decode/decoder_stack/layer_1/self_attention/dropout/Shape	model/Transformer/decode/decoder_stack/layer_1/self_attention/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/dropout/div_grad/Sum	
model/Transformer/decode/decoder_stack/layer_1/self_attention/dropout/random_uniform/RandomUniform	model/Transformer/decode/decoder_stack/layer_1/self_attention/dropout/add	
model/Transformer/decode/decoder_stack/layer_1/self_attention/dropout/add	model/Transformer/decode/decoder_stack/layer_1/self_attention/dropout/Floor	
model/Transformer/decode/decoder_stack/layer_1/self_attention/dropout/Floor	model/Transformer/decode/decoder_stack/layer_1/self_attention/dropout/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/dropout/mul_grad/Mul	
model/Transformer/decode/decoder_stack/layer_1/self_attention/dropout/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/add_grad/Shape_1	model/Transformer/decode/decoder_stack/layer_1/self_attention/add	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/add_grad/Reshape_1	
model/Transformer/decode/decoder_stack/layer_1/self_attention/add	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/sub_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/Shape	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/Prod	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/sub_1	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/add	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/sub_grad/Shape	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/Shape/_4038	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/floordiv	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/sub_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/sub_grad/Shape_1	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/Shape/_4038	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/Shape/_4039	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/Shape/_4039	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/DynamicStitch/_4040	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/sub_1_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/sub_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/sub_grad/Reshape_1	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/sub_1	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Square	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/Prod_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/DynamicStitch/_4040	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/DynamicStitch/_4041	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/DynamicStitch/_4041	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/floordiv	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/sub_1_grad/Sum_1	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/sub_grad/Sum_1	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Square	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/Shape	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/Prod	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/floordiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/Shape/_4042	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/floordiv	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_grad/Shape	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/floordiv_1/_4044	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/Shape/_4042	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/Shape/_4043	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/Shape/_4043	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch/_4046	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Rsqrt	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/Prod_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/floordiv_1/_4044	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/floordiv_1/_4045	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/floordiv_1/_4045	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/Cast	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/Cast	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch/_4046	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch/_4047	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch/_4047	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/floordiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_grad/Sum	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Rsqrt	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_grad/Shape_1	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/floordiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_grad/Reshape_1	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_1_grad/Shape	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/floordiv_1/_4048	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_1_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_1_grad/Shape	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/floordiv_1/_4048	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/floordiv_1/_4049	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/floordiv_1/_4049	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/Cast	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/Cast	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_1_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_1	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/Reshape_grad/Shape	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_1_grad/Sum_1	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/Shape	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/Shape/_4050	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/Reshape_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/Shape/_4050	_SINK	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/GatherV2_1/_4053	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/Prod_1	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/Prod_1/_4060	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/GatherV2/_4055	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/Prod	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/Prod/_4058	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/GatherV2/_4057	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/concat_2	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/Prod/_4058	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/Prod/_4059	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/Prod/_4059	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/Prod_1/_4060	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/Prod_1/_4061	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/Prod_1/_4061	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/stack	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/Reshape	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads/Shape	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads/Shape	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads/strided_slice_1	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads/Reshape	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads/Reshape	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads/transpose	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/mul_grad/Shape	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/mul_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/mul	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/mul_grad/Sum	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/add_grad/Shape	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/add	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/add_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/add	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/attention_weights	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/add_grad/Sum	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/attention_weights	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/div_grad/Shape	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/div	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/attention_weights_grad/mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/div_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/div	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/mul_grad/Shape	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/mul	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/Shape	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/mul_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/random_uniform/RandomUniform	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/random_uniform/mul	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/random_uniform/mul	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/add	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/add	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/Floor	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/Floor	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/mul_grad/Shape_1	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/mul_grad/BroadcastGradientArgs	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/mul	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/MatMul_1_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/mul_grad/Sum	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/MatMul_1	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/combine_heads/transpose	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/combine_heads/Shape	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/combine_heads/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/combine_heads/Reshape_grad/Shape	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/combine_heads/Reshape	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/combine_heads/Shape	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/combine_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/combine_heads/strided_slice_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/combine_heads/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/combine_heads/Reshape_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/combine_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/combine_heads/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/combine_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/combine_heads/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/combine_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/combine_heads/Reshape	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/combine_heads/Reshape	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/Reshape_grad/Shape	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/Shape	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/Shape/_4062	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/Reshape_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/Shape/_4062	_SINK	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/GatherV2_1/_4065	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/Prod_1	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/Prod_1/_4072	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/GatherV2/_4067	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/Prod	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/Prod/_4070	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/GatherV2/_4069	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/concat_2	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/Prod/_4070	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/Prod/_4071	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/Prod/_4071	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/Prod_1/_4072	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/Prod_1/_4073	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/Prod_1/_4073	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/stack	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/Reshape	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/dropout/div_grad/Shape	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/dropout/div	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/dropout/Shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/dropout/div_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/dropout/div	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/dropout/mul	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/dropout/Shape	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/dropout/div_grad/Sum	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/dropout/random_uniform/RandomUniform	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/dropout/add	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/dropout/add	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/dropout/Floor	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/dropout/Floor	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/dropout/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/dropout/mul_grad/Mul	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/dropout/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/add_grad/Shape_1	model/Transformer/decode/decoder_stack/layer_1/encdec_attention/add	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/add_grad/Reshape_1	
model/Transformer/decode/decoder_stack/layer_1/encdec_attention/add	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/sub_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Shape	model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Prod	model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/sub_1	model/Transformer/decode/decoder_stack/layer_1/ffn/add	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/sub_grad/Shape	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Shape/_4074	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/floordiv	
model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/sub_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/sub_grad/Shape_1	model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Shape/_4074	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Shape/_4075	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Shape/_4075	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/DynamicStitch/_4076	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/sub_1_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/sub_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/sub_grad/Reshape_1	
model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/sub_1	model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Square	model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Prod_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/DynamicStitch/_4076	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/DynamicStitch/_4077	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/DynamicStitch/_4077	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/floordiv	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/sub_1_grad/Sum_1	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/sub_grad/Sum_1	
model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Square	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Shape	model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Prod	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/floordiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Shape/_4078	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/floordiv	
model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_grad/Shape	model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/floordiv_1/_4080	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Shape/_4078	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Shape/_4079	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Shape/_4079	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/DynamicStitch/_4082	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add	model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Rsqrt	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Prod_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/floordiv_1/_4080	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/floordiv_1/_4081	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/floordiv_1/_4081	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Cast	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Cast	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/DynamicStitch/_4082	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/DynamicStitch/_4083	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/DynamicStitch/_4083	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/floordiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_grad/Sum	
model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Rsqrt	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_grad/Shape_1	model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/floordiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_grad/Reshape_1	
model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Shape	model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/floordiv_1/_4084	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_1_grad/Shape	model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/floordiv_1/_4084	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/floordiv_1/_4085	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/floordiv_1/_4085	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Cast	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Cast	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_1_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_1	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Shape	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_1_grad/Sum_1	
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Shape	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Shape/_4086	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Shape/_4086	_SINK	
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2_1/_4089	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1	
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1/_4096	
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2/_4091	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Prod	
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Prod/_4094	
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2/_4093	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/concat_2	
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot	
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Prod/_4094	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Prod/_4095	
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Prod/_4095	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1/_4096	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1/_4097	
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1/_4097	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/stack	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Reshape	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/BiasAdd	
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/BiasAdd	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Relu	
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Relu	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/dropout/div_grad/Shape	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/dropout/div	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/dropout/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Relu_grad/ReluGrad	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/dropout/div_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/dropout/div	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/dropout/mul	
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/dropout/Shape	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/dropout/div_grad/Sum	
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/dropout/random_uniform/RandomUniform	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/dropout/add	
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/dropout/add	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/dropout/Floor	
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/dropout/Floor	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/dropout/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/dropout/mul_grad/Mul	
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/dropout/mul	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Shape	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Shape	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Shape/_4098	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Shape/_4098	_SINK	
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/GatherV2_1/_4101	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Prod_1	
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Prod_1/_4108	
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/GatherV2/_4103	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Prod	
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Prod/_4106	
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/GatherV2/_4105	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/concat_2	
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot	
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Prod/_4106	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Prod/_4107	
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Prod/_4107	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Prod_1/_4108	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Prod_1/_4109	
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Prod_1/_4109	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/stack	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Reshape	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot	model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/BiasAdd	
model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/BiasAdd	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/dropout/div_grad/Shape	model/Transformer/decode/decoder_stack/layer_1/ffn/dropout/div	model/Transformer/decode/decoder_stack/layer_1/ffn/dropout/Shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/dropout/div_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_1/ffn/dropout/div	model/Transformer/decode/decoder_stack/layer_1/ffn/dropout/mul	
model/Transformer/decode/decoder_stack/layer_1/ffn/dropout/Shape	model/Transformer/decode/decoder_stack/layer_1/ffn/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/dropout/div_grad/Sum	
model/Transformer/decode/decoder_stack/layer_1/ffn/dropout/random_uniform/RandomUniform	model/Transformer/decode/decoder_stack/layer_1/ffn/dropout/add	
model/Transformer/decode/decoder_stack/layer_1/ffn/dropout/add	model/Transformer/decode/decoder_stack/layer_1/ffn/dropout/Floor	
model/Transformer/decode/decoder_stack/layer_1/ffn/dropout/Floor	model/Transformer/decode/decoder_stack/layer_1/ffn/dropout/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/dropout/mul_grad/Mul	
model/Transformer/decode/decoder_stack/layer_1/ffn/dropout/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/add_grad/Shape_1	model/Transformer/decode/decoder_stack/layer_1/ffn/add	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/add_grad/Reshape_1	
model/Transformer/decode/decoder_stack/layer_1/ffn/add	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/sub_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Shape	model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Prod	model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/sub_1	model/Transformer/decode/decoder_stack/layer_2/self_attention/add	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/sub_grad/Shape	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Shape/_4110	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/floordiv	
model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/sub_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/sub_grad/Shape_1	model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Shape/_4110	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Shape/_4111	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Shape/_4111	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/DynamicStitch/_4112	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/sub_1_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/sub_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/sub_grad/Reshape_1	
model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/sub_1	model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Square	model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Prod_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/DynamicStitch/_4112	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/DynamicStitch/_4113	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/DynamicStitch/_4113	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/floordiv	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/sub_1_grad/Sum_1	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/sub_grad/Sum_1	
model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Square	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Shape	model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Prod	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/floordiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Shape/_4114	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/floordiv	
model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_grad/Shape	model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/floordiv_1/_4116	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Shape/_4114	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Shape/_4115	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Shape/_4115	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/DynamicStitch/_4118	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add	model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Rsqrt	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Prod_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/floordiv_1/_4116	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/floordiv_1/_4117	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/floordiv_1/_4117	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Cast	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Cast	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/DynamicStitch/_4118	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/DynamicStitch/_4119	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/DynamicStitch/_4119	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/floordiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_grad/Sum	
model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Rsqrt	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_grad/Shape_1	model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/floordiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_grad/Reshape_1	
model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Shape	model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/floordiv_1/_4120	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/Shape	model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/floordiv_1/_4120	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/floordiv_1/_4121	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/floordiv_1/_4121	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Cast	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Cast	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_1	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/v/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/k/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Reshape_grad/Shape	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/Sum_1	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Shape	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Shape/_4122	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/v/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/k/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Shape/_4122	_SINK	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/GatherV2_1/_4125	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Prod_1	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Prod_1/_4132	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/GatherV2/_4127	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Prod	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Prod/_4130	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/GatherV2/_4129	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/concat_2	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/k/Tensordot	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/v/Tensordot	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Prod/_4130	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Prod/_4131	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Prod/_4131	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Prod_1/_4132	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Prod_1/_4133	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Prod_1/_4133	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/stack	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Reshape	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/MatMul	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/k/Tensordot/MatMul	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/v/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads/Reshape	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/k/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/k/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/k/Tensordot	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_1/Reshape	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/v/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/v/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/v/Tensordot	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_2/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads/Shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/k/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/k/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/k/Tensordot	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_1/Shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/v/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/v/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/v/Tensordot	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_2/Shape	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads/Shape	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads/strided_slice_1	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_1/Shape	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_1/strided_slice_1	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_2/Shape	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_2/strided_slice_1	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_1/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_1/strided_slice_1	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_1/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_2/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_2/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads/Reshape	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_1/Reshape/shape	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_1/Reshape	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_2/Reshape/shape	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_2/Reshape	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads/Reshape	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads/transpose	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_1/Reshape	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_1/transpose	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_2/Reshape	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_2/transpose	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/mul_grad/Shape	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/mul	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_1/transpose	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_2/transpose	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/MatMul_1_grad/MatMul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/mul_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/mul	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/mul_grad/Sum	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/add_grad/Shape	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/add	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/add_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/add	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/attention_weights	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/add_grad/Sum	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/attention_weights	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/dropout/div_grad/Shape	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/dropout/div	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/dropout/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/attention_weights_grad/mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/dropout/div_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/dropout/div	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/dropout/mul_grad/Shape	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/dropout/mul	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/dropout/Shape	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/dropout/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/dropout/mul_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/dropout/random_uniform/RandomUniform	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/dropout/add	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/dropout/add	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/dropout/Floor	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/dropout/Floor	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/dropout/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/dropout/mul_grad/Mul	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/dropout/mul	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/MatMul_1_grad/MatMul_1	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/MatMul_1	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/combine_heads/transpose	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/combine_heads/Shape	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/combine_heads/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/combine_heads/Reshape_grad/Shape	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/combine_heads/Reshape	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/combine_heads/Shape	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/combine_heads/strided_slice_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/combine_heads/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/combine_heads/Reshape_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/combine_heads/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/combine_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/combine_heads/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/combine_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/combine_heads/Reshape	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/combine_heads/Reshape	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Shape	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Shape	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Shape/_4134	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Shape/_4134	_SINK	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/GatherV2_1/_4137	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Prod_1	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Prod_1/_4144	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/GatherV2/_4139	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Prod	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Prod/_4142	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/GatherV2/_4141	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/concat_2	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Prod/_4142	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Prod/_4143	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Prod/_4143	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Prod_1/_4144	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Prod_1/_4145	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Prod_1/_4145	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/stack	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Reshape	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/dropout/div_grad/Shape	model/Transformer/decode/decoder_stack/layer_2/self_attention/dropout/div	model/Transformer/decode/decoder_stack/layer_2/self_attention/dropout/Shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/dropout/div_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_2/self_attention/dropout/div	model/Transformer/decode/decoder_stack/layer_2/self_attention/dropout/mul	
model/Transformer/decode/decoder_stack/layer_2/self_attention/dropout/Shape	model/Transformer/decode/decoder_stack/layer_2/self_attention/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/dropout/div_grad/Sum	
model/Transformer/decode/decoder_stack/layer_2/self_attention/dropout/random_uniform/RandomUniform	model/Transformer/decode/decoder_stack/layer_2/self_attention/dropout/add	
model/Transformer/decode/decoder_stack/layer_2/self_attention/dropout/add	model/Transformer/decode/decoder_stack/layer_2/self_attention/dropout/Floor	
model/Transformer/decode/decoder_stack/layer_2/self_attention/dropout/Floor	model/Transformer/decode/decoder_stack/layer_2/self_attention/dropout/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/dropout/mul_grad/Mul	
model/Transformer/decode/decoder_stack/layer_2/self_attention/dropout/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/add_grad/Shape_1	model/Transformer/decode/decoder_stack/layer_2/self_attention/add	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/add_grad/Reshape_1	
model/Transformer/decode/decoder_stack/layer_2/self_attention/add	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/add	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/sub_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/Shape	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/Prod	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/sub_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/sub_grad/Shape	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/Shape/_4146	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/floordiv	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/sub_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/sub_grad/Shape_1	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/Shape/_4146	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/Shape/_4147	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/Shape/_4147	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/DynamicStitch/_4148	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/sub_1_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/sub_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/sub_grad/Reshape_1	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/sub_1	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Square	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/Prod_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/DynamicStitch/_4148	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/DynamicStitch/_4149	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/DynamicStitch/_4149	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/floordiv	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/sub_1_grad/Sum_1	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/sub_grad/Sum_1	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Square	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/Shape	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/Prod	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/floordiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/Shape/_4150	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/floordiv	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_grad/Shape	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/floordiv_1/_4152	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/Shape/_4150	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/Shape/_4151	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/Shape/_4151	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch/_4154	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Rsqrt	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/Prod_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/floordiv_1/_4152	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/floordiv_1/_4153	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/floordiv_1/_4153	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/Cast	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/Cast	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch/_4154	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch/_4155	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch/_4155	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/floordiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_grad/Sum	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Rsqrt	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_grad/Shape_1	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/floordiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_grad/Reshape_1	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_1_grad/Shape	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/floordiv_1/_4156	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_1_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_1_grad/Shape	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/floordiv_1/_4156	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/floordiv_1/_4157	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/floordiv_1/_4157	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/Cast	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/Cast	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_1_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_1	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/Reshape_grad/Shape	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_1_grad/Sum_1	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/Shape	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/Shape/_4158	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/Reshape_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/Shape/_4158	_SINK	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/GatherV2_1/_4161	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/Prod_1	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/Prod_1/_4168	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/GatherV2/_4163	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/Prod	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/Prod/_4166	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/GatherV2/_4165	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/concat_2	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/Prod/_4166	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/Prod/_4167	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/Prod/_4167	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/Prod_1/_4168	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/Prod_1/_4169	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/Prod_1/_4169	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/stack	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/Reshape	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads/Shape	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads/Shape	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads/strided_slice_1	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads/Reshape	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads/Reshape	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads/transpose	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/mul_grad/Shape	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/mul_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/mul	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/mul_grad/Sum	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/add_grad/Shape	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/add	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/add_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/add	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/attention_weights	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/add_grad/Sum	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/attention_weights	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/attention_weights_grad/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/div_grad/Shape	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/div	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/Shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/div_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/div	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/mul_grad/Shape	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/mul	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/Shape	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/mul_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/random_uniform/RandomUniform	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/random_uniform/mul	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/random_uniform/mul	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/add	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/add	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/Floor	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/Floor	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/mul_grad/Shape_1	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/mul_grad/BroadcastGradientArgs	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/mul	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/MatMul_1_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/mul_grad/Sum	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/MatMul_1	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/combine_heads/transpose	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/combine_heads/Shape	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/combine_heads/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/combine_heads/Reshape_grad/Shape	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/combine_heads/Reshape	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/combine_heads/Shape	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/combine_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/combine_heads/strided_slice_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/combine_heads/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/combine_heads/Reshape_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/combine_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/combine_heads/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/combine_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/combine_heads/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/combine_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/combine_heads/Reshape	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/combine_heads/Reshape	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/Reshape_grad/Shape	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/Shape	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/Shape/_4170	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/Reshape_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/Shape/_4170	_SINK	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/GatherV2_1/_4173	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/Prod_1	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/Prod_1/_4180	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/GatherV2/_4175	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/Prod	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/Prod/_4178	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/GatherV2/_4177	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/concat_2	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/Prod/_4178	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/Prod/_4179	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/Prod/_4179	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/Prod_1/_4180	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/Prod_1/_4181	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/Prod_1/_4181	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/stack	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/Reshape	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/dropout/div_grad/Shape	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/dropout/div	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/dropout/Shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/dropout/div_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/dropout/div	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/dropout/mul	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/dropout/Shape	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/dropout/div_grad/Sum	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/dropout/random_uniform/RandomUniform	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/dropout/add	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/dropout/add	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/dropout/Floor	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/dropout/Floor	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/dropout/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/dropout/mul_grad/Mul	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/dropout/mul	model/Transformer/decode/decoder_stack/layer_2/encdec_attention/add	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/add_grad/Shape_1	
model/Transformer/decode/decoder_stack/layer_2/encdec_attention/add	model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/sub_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Shape	model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Prod	model/Transformer/decode/decoder_stack/layer_2/ffn/add	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/add_grad/Reshape_1	
model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/sub_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/sub_grad/Shape_1	model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/sub_grad/Shape	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Shape/_4182	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/floordiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/sub_1_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/sub_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/sub_grad/Reshape_1	
model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/sub_1	model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Square	model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Prod_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Shape/_4182	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Shape/_4183	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Shape/_4183	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/DynamicStitch/_4184	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/floordiv_1	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/sub_1_grad/Sum_1	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/sub_grad/Sum_1	
model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Square	model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Prod	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/DynamicStitch/_4184	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/DynamicStitch/_4185	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/DynamicStitch/_4185	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/floordiv	
model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1	model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Shape/_4186	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/floordiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/floordiv_1/_4188	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/floordiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Tile	
model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add	model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Rsqrt	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Prod_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Shape/_4186	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Shape/_4187	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Shape/_4187	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/DynamicStitch/_4190	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/floordiv_1/_4188	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/floordiv_1/_4189	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/floordiv_1/_4189	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Cast	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Cast	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/truediv	
model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Rsqrt	model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/DynamicStitch/_4190	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/DynamicStitch/_4191	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/DynamicStitch/_4191	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/floordiv	
model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul	model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/floordiv_1/_4192	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/floordiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Tile	
model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_1	model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_1_grad/Shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Reshape	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/floordiv_1/_4192	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/floordiv_1/_4193	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/floordiv_1/_4193	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Cast	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Cast	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/truediv	
model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_1	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Shape	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Sum_1	
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Shape	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Shape/_4194	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_1_grad/Sum_1	
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Shape/_4194	_SINK	
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2/_4197	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/concat_2	
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot	
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2/_4199	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Prod	
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Prod/_4202	
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2_1/_4201	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1	
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1/_4204	
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Prod/_4202	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Prod/_4203	
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Prod/_4203	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1/_4204	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1/_4205	
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1/_4205	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/stack	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Reshape	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/MatMul	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot_grad/Shape	
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/BiasAdd	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/BiasAdd	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Relu	
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Relu	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/dropout/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/dropout/div_grad/Shape	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/dropout/div	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Relu_grad/ReluGrad	
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/dropout/Shape	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/dropout/div_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/dropout/div	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/dropout/mul	
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/dropout/random_uniform/RandomUniform	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/dropout/add	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/dropout/div_grad/Sum	
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/dropout/add	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/dropout/Floor	
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/dropout/Floor	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/dropout/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/dropout/mul_grad/Mul	
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/dropout/mul	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Shape	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Shape	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Shape/_4206	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Shape/_4206	_SINK	
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/GatherV2/_4209	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/concat_2	
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot	
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/GatherV2/_4211	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Prod	
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Prod/_4214	
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/GatherV2_1/_4213	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Prod_1	
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Prod_1/_4216	
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Prod/_4214	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Prod/_4215	
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Prod/_4215	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Prod_1/_4216	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Prod_1/_4217	
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Prod_1/_4217	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/stack	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Reshape	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/MatMul	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot_grad/Shape	
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot	model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/BiasAdd	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/BiasAdd	model/Transformer/decode/decoder_stack/layer_2/ffn/dropout/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/dropout/div_grad/Shape	model/Transformer/decode/decoder_stack/layer_2/ffn/dropout/div	
model/Transformer/decode/decoder_stack/layer_2/ffn/dropout/Shape	model/Transformer/decode/decoder_stack/layer_2/ffn/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/dropout/div_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_2/ffn/dropout/div	model/Transformer/decode/decoder_stack/layer_2/ffn/dropout/mul	
model/Transformer/decode/decoder_stack/layer_2/ffn/dropout/random_uniform/RandomUniform	model/Transformer/decode/decoder_stack/layer_2/ffn/dropout/add	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/dropout/div_grad/Sum	
model/Transformer/decode/decoder_stack/layer_2/ffn/dropout/add	model/Transformer/decode/decoder_stack/layer_2/ffn/dropout/Floor	
model/Transformer/decode/decoder_stack/layer_2/ffn/dropout/Floor	model/Transformer/decode/decoder_stack/layer_2/ffn/dropout/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/dropout/mul_grad/Mul	
model/Transformer/decode/decoder_stack/layer_2/ffn/dropout/mul	model/Transformer/decode/decoder_stack/layer_2/ffn/add	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/add_grad/Shape_1	
model/Transformer/decode/decoder_stack/layer_2/ffn/add	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Prod	model/Transformer/decode/decoder_stack/layer_3/self_attention/add	model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/sub_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Shape	model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/sub_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/add_grad/Reshape_1	
model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/sub_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/sub_grad/Shape_1	model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/sub_grad/Shape	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Shape/_4218	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/floordiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/sub_1_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/sub_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/sub_grad/Reshape_1	
model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/sub_1	model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Square	model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Prod_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Shape/_4218	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Shape/_4219	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Shape/_4219	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/DynamicStitch/_4220	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/floordiv_1	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/sub_1_grad/Sum_1	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/sub_grad/Sum_1	
model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Square	model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Prod	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/DynamicStitch/_4220	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/DynamicStitch/_4221	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/DynamicStitch/_4221	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/floordiv	
model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1	model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Shape/_4222	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/floordiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/floordiv_1/_4224	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/floordiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Tile	
model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add	model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Rsqrt	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Prod_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Shape/_4222	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Shape/_4223	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Shape/_4223	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/DynamicStitch/_4226	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/floordiv_1/_4224	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/floordiv_1/_4225	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/floordiv_1/_4225	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Cast	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Cast	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/truediv	
model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Rsqrt	model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/DynamicStitch/_4226	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/DynamicStitch/_4227	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/DynamicStitch/_4227	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/floordiv	
model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul	model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/floordiv_1/_4228	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/floordiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Tile	
model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_1	model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/Shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Reshape	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/floordiv_1/_4228	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/floordiv_1/_4229	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/floordiv_1/_4229	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Cast	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Cast	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/truediv	
model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_1	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/v/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/k/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Reshape_grad/Shape	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Sum_1	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Shape	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Shape/_4230	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/v/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/k/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/Sum_1	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Shape/_4230	_SINK	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/GatherV2_1/_4233	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Prod_1	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Prod_1/_4240	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/GatherV2/_4235	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Prod	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Prod/_4238	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/GatherV2/_4237	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/concat_2	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/k/Tensordot	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/v/Tensordot	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Prod/_4238	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Prod/_4239	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Prod/_4239	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Prod_1/_4240	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Prod_1/_4241	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Prod_1/_4241	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/stack	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul_1	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/MatMul	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/k/Tensordot/MatMul	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/v/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads/Reshape	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/k/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/k/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/k/Tensordot	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_1/Reshape	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/v/Tensordot/MatMul	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/v/Tensordot	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/v/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_2/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads/Shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/k/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/k/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/k/Tensordot	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_1/Shape	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/v/Tensordot	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_2/Shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/v/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/v/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads/Shape	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads/strided_slice_1	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_1/Shape	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_1/strided_slice_1	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_2/Shape	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_2/strided_slice	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_1/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_1/strided_slice_1	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_1/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_2/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_2/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads/Reshape	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_1/Reshape/shape	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_1/Reshape	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_2/Reshape/shape	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_2/Reshape	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads/Reshape	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads/transpose	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_1/Reshape	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_1/transpose	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_2/Reshape	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_2/transpose	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/mul_grad/Shape	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/mul	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_1/transpose	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_2/transpose	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/MatMul_1_grad/MatMul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/mul_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/mul	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/mul_grad/Sum	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/add_grad/Shape	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/add	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/add_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/add	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/attention_weights	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/add_grad/Sum	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/attention_weights	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/attention_weights_grad/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/dropout/div_grad/Shape	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/dropout/div	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/dropout/Shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/dropout/div_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/dropout/div	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/dropout/mul_grad/Shape	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/dropout/mul	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/dropout/Shape	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/dropout/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/dropout/mul_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/dropout/random_uniform/RandomUniform	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/dropout/add	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/dropout/add	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/dropout/Floor	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/dropout/Floor	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/dropout/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/dropout/mul_grad/Mul	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/dropout/mul	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/MatMul_1_grad/MatMul_1	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/MatMul_1	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/combine_heads/transpose	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/combine_heads/Shape	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/combine_heads/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/combine_heads/Reshape_grad/Shape	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/combine_heads/Reshape	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/combine_heads/Shape	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/combine_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/combine_heads/strided_slice	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/combine_heads/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/combine_heads/Reshape_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/combine_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/combine_heads/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/combine_heads/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/combine_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/combine_heads/Reshape	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/combine_heads/Reshape	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Shape	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Shape	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Shape/_4242	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Shape/_4242	_SINK	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/GatherV2/_4245	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/concat_2	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/GatherV2/_4247	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Prod	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Prod/_4250	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/GatherV2_1/_4249	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Prod_1	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Prod_1/_4252	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Prod/_4250	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Prod/_4251	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Prod/_4251	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Prod_1/_4252	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Prod_1/_4253	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Prod_1/_4253	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/stack	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Reshape	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/MatMul	model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot_grad/Shape	
model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot	model/Transformer/decode/decoder_stack/layer_3/self_attention/dropout/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/dropout/div_grad/Shape	model/Transformer/decode/decoder_stack/layer_3/self_attention/dropout/div	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_3/self_attention/dropout/Shape	model/Transformer/decode/decoder_stack/layer_3/self_attention/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/dropout/div_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_3/self_attention/dropout/div	model/Transformer/decode/decoder_stack/layer_3/self_attention/dropout/mul	
model/Transformer/decode/decoder_stack/layer_3/self_attention/dropout/random_uniform/RandomUniform	model/Transformer/decode/decoder_stack/layer_3/self_attention/dropout/add	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/dropout/div_grad/Sum	
model/Transformer/decode/decoder_stack/layer_3/self_attention/dropout/add	model/Transformer/decode/decoder_stack/layer_3/self_attention/dropout/Floor	
model/Transformer/decode/decoder_stack/layer_3/self_attention/dropout/Floor	model/Transformer/decode/decoder_stack/layer_3/self_attention/dropout/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/dropout/mul_grad/Mul	
model/Transformer/decode/decoder_stack/layer_3/self_attention/dropout/mul	model/Transformer/decode/decoder_stack/layer_3/self_attention/add	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/add_grad/Shape_1	
model/Transformer/decode/decoder_stack/layer_3/self_attention/add	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/sub_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/Shape	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/Prod	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/add	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/add_grad/Reshape_1	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/sub_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/sub_grad/Shape_1	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/sub_grad/Shape	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/Shape/_4254	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/floordiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/sub_1_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/sub_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/sub_grad/Reshape_1	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/sub_1	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Square	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/Prod_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/Shape/_4254	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/Shape/_4255	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/Shape/_4255	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/DynamicStitch/_4256	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/floordiv_1	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/sub_1_grad/Sum_1	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/sub_grad/Sum_1	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Square	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/Prod	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/DynamicStitch/_4256	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/DynamicStitch/_4257	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/DynamicStitch/_4257	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/floordiv	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/Shape/_4258	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/floordiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/floordiv_1/_4260	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/floordiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/Tile	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Rsqrt	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/Prod_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/Shape/_4258	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/Shape/_4259	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/Shape/_4259	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch/_4262	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/floordiv_1/_4260	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/floordiv_1/_4261	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/floordiv_1/_4261	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/Cast	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/Cast	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/truediv	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Rsqrt	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch/_4262	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch/_4263	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch/_4263	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/floordiv	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/floordiv_1/_4264	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/floordiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/Tile	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_1	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_1_grad/Shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_1_grad/Reshape	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/floordiv_1/_4264	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/floordiv_1/_4265	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/floordiv_1/_4265	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/Cast	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/Cast	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/truediv	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_1	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/Reshape_grad/Shape	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_1_grad/Sum_1	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/Shape	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/Shape/_4266	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_1_grad/Sum_1	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/Shape/_4266	_SINK	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/GatherV2/_4269	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/concat_2	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/GatherV2/_4271	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/Prod	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/Prod/_4274	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/GatherV2_1/_4273	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/Prod_1	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/Prod_1/_4276	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/Prod/_4274	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/Prod/_4275	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/Prod/_4275	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/Prod_1/_4276	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/Prod_1/_4277	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/Prod_1/_4277	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/stack	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/Reshape	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/MatMul	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads/Reshape	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads/Shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads/Shape	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads/strided_slice	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads/Reshape	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads/Reshape	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads/transpose	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads/transpose	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/mul_grad/Shape	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/mul	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/mul_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/MatMul	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/add	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/add_grad/Shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/mul_grad/Sum	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/add	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/attention_weights	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/add_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/attention_weights	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/div_grad/Shape	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/div	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/attention_weights_grad/mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/add_grad/Sum	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/Shape	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/div_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/div	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/mul_grad/Shape	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/mul	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/random_uniform/RandomUniform	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/random_uniform/mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/mul_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/random_uniform/mul	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/add	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/add	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/Floor	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/Floor	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/mul_grad/Mul	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/mul	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/MatMul_1_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/mul_grad/BroadcastGradientArgs	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/MatMul_1	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/combine_heads/transpose	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/combine_heads/Shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/mul_grad/Sum	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/combine_heads/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/combine_heads/Reshape_grad/Shape	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/combine_heads/Reshape	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/combine_heads/Shape	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/combine_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/combine_heads/strided_slice	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/combine_heads/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/combine_heads/Reshape_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/combine_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/combine_heads/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/combine_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/combine_heads/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/combine_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/combine_heads/Reshape	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/combine_heads/Reshape	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/Reshape_grad/Shape	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/Shape	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/Shape/_4278	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/Reshape_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/Shape/_4278	_SINK	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/GatherV2/_4281	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/concat_2	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/GatherV2/_4283	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/Prod	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/Prod/_4286	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/GatherV2_1/_4285	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/Prod_1	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/Prod_1/_4288	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/Prod/_4286	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/Prod/_4287	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/Prod/_4287	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/Prod_1/_4288	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/Prod_1/_4289	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/Prod_1/_4289	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/stack	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/Reshape	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/MatMul	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot_grad/Shape	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/dropout/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/dropout/div_grad/Shape	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/dropout/div	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/dropout/Shape	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/dropout/div_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/dropout/div	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/dropout/mul	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/dropout/random_uniform/RandomUniform	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/dropout/add	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/dropout/div_grad/Sum	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/dropout/add	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/dropout/Floor	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/dropout/Floor	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/dropout/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/dropout/mul_grad/Mul	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/dropout/mul	model/Transformer/decode/decoder_stack/layer_3/encdec_attention/add	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/add_grad/Shape_1	
model/Transformer/decode/decoder_stack/layer_3/encdec_attention/add	model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/sub_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Shape	model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Prod	model/Transformer/decode/decoder_stack/layer_3/ffn/add	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/add_grad/Reshape_1	
model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/sub_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/sub_grad/Shape_1	model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/sub_grad/Shape	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Shape/_4290	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/floordiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/sub_1_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/sub_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/sub_grad/Reshape_1	
model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/sub_1	model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Square	model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Prod_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Shape/_4290	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Shape/_4291	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Shape/_4291	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/DynamicStitch/_4292	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/floordiv_1	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/sub_1_grad/Sum_1	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/sub_grad/Sum_1	
model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Square	model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Prod	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/DynamicStitch/_4292	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/DynamicStitch/_4293	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/DynamicStitch/_4293	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/floordiv	
model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1	model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Shape/_4294	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/floordiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/floordiv_1/_4296	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/floordiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Tile	
model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add	model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Rsqrt	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Prod_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Shape/_4294	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Shape/_4295	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Shape/_4295	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/DynamicStitch/_4298	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/floordiv_1/_4296	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/floordiv_1/_4297	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/floordiv_1/_4297	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Cast	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Cast	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/truediv	
model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Rsqrt	model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/DynamicStitch/_4298	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/DynamicStitch/_4299	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/DynamicStitch/_4299	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/floordiv	
model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul	model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/floordiv_1/_4300	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/floordiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Tile	
model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_1	model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_1_grad/Shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Reshape	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/floordiv_1/_4300	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/floordiv_1/_4301	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/floordiv_1/_4301	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Cast	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Cast	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/truediv	
model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_1	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Shape	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Sum_1	
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Shape	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Shape/_4302	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_1_grad/Sum_1	
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Shape/_4302	_SINK	
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2/_4305	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/concat_2	
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot	
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2/_4307	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Prod	
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Prod/_4310	
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2_1/_4309	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1	
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1/_4312	
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Prod/_4310	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Prod/_4311	
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Prod/_4311	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1/_4312	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1/_4313	
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1/_4313	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/stack	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Reshape	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/MatMul	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot_grad/Shape	
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/BiasAdd	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/BiasAdd	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Relu	
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Relu	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/dropout/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/dropout/div_grad/Shape	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/dropout/div	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Relu_grad/ReluGrad	
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/dropout/Shape	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/dropout/div_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/dropout/div	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/dropout/mul	
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/dropout/random_uniform/RandomUniform	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/dropout/add	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/dropout/div_grad/Sum	
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/dropout/add	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/dropout/Floor	
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/dropout/Floor	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/dropout/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/dropout/mul_grad/Mul	
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/dropout/mul	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Shape	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Shape	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Shape/_4314	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Shape/_4314	_SINK	
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/GatherV2/_4317	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/concat_2	
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot	
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/GatherV2/_4319	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Prod	
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Prod/_4322	
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/GatherV2_1/_4321	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Prod_1	
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Prod_1/_4324	
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Prod/_4322	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Prod/_4323	
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Prod/_4323	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Prod_1/_4324	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Prod_1/_4325	
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Prod_1/_4325	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/stack	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Reshape	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/MatMul	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot_grad/Shape	
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot	model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/BiasAdd	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/BiasAdd	model/Transformer/decode/decoder_stack/layer_3/ffn/dropout/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/dropout/div_grad/Shape	model/Transformer/decode/decoder_stack/layer_3/ffn/dropout/div	
model/Transformer/decode/decoder_stack/layer_3/ffn/dropout/Shape	model/Transformer/decode/decoder_stack/layer_3/ffn/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/dropout/div_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_3/ffn/dropout/div	model/Transformer/decode/decoder_stack/layer_3/ffn/dropout/mul	
model/Transformer/decode/decoder_stack/layer_3/ffn/dropout/random_uniform/RandomUniform	model/Transformer/decode/decoder_stack/layer_3/ffn/dropout/add	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/dropout/div_grad/Sum	
model/Transformer/decode/decoder_stack/layer_3/ffn/dropout/add	model/Transformer/decode/decoder_stack/layer_3/ffn/dropout/Floor	
model/Transformer/decode/decoder_stack/layer_3/ffn/dropout/Floor	model/Transformer/decode/decoder_stack/layer_3/ffn/dropout/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/dropout/mul_grad/Mul	
model/Transformer/decode/decoder_stack/layer_3/ffn/dropout/mul	model/Transformer/decode/decoder_stack/layer_3/ffn/add	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/add_grad/Shape_1	
model/Transformer/decode/decoder_stack/layer_3/ffn/add	model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/sub_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Shape	model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Prod	model/Transformer/decode/decoder_stack/layer_4/self_attention/add	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/add_grad/Reshape_1	
model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/sub_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/sub_grad/Shape_1	model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/sub_grad/Shape	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Shape/_4326	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/floordiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/sub_1_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/sub_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/sub_grad/Reshape_1	
model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/sub_1	model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Square	model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Prod_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Shape/_4326	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Shape/_4327	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Shape/_4327	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/DynamicStitch/_4328	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/floordiv_1	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/sub_1_grad/Sum_1	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/sub_grad/Sum_1	
model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Square	model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Prod	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/DynamicStitch/_4328	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/DynamicStitch/_4329	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/DynamicStitch/_4329	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/floordiv	
model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1	model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Shape/_4330	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/floordiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/floordiv_1/_4332	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/floordiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Tile	
model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add	model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Rsqrt	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Prod_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Shape/_4330	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Shape/_4331	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Shape/_4331	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/DynamicStitch/_4334	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/floordiv_1/_4332	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/floordiv_1/_4333	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/floordiv_1/_4333	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Cast	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Cast	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/truediv	
model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Rsqrt	model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/DynamicStitch/_4334	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/DynamicStitch/_4335	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/DynamicStitch/_4335	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/floordiv	
model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul	model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/floordiv_1/_4336	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/floordiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Tile	
model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_1	model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/Shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Reshape	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/floordiv_1/_4336	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/floordiv_1/_4337	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/floordiv_1/_4337	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Cast	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Cast	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/truediv	
model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_1	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/v/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/k/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Reshape_grad/Shape	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Sum_1	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Shape	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Shape/_4338	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/v/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/k/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/Sum_1	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Shape/_4338	_SINK	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/GatherV2_1/_4341	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Prod_1	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Prod_1/_4348	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/GatherV2/_4343	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Prod	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Prod/_4346	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/GatherV2/_4345	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/concat_2	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/k/Tensordot	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/v/Tensordot	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Prod/_4346	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Prod/_4347	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Prod/_4347	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Prod_1/_4348	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Prod_1/_4349	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Prod_1/_4349	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/stack	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Reshape	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/MatMul	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/k/Tensordot/MatMul	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/v/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads/Reshape	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/k/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/k/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/k/Tensordot	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_1/Reshape	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/v/Tensordot/MatMul	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/v/Tensordot	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/v/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_2/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads/Shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/k/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/k/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/k/Tensordot	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_1/Shape	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/v/Tensordot	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_2/Shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/v/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/v/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads/Shape	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads/strided_slice_1	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_1/Shape	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_1/strided_slice_1	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_2/Shape	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_2/strided_slice	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_1/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_1/strided_slice_1	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_1/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_2/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_2/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads/Reshape	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_1/Reshape/shape	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_1/Reshape	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_2/Reshape/shape	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_2/Reshape	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads/Reshape	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads/transpose	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_1/Reshape	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_1/transpose	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_2/Reshape	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_2/transpose	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/mul_grad/Shape	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/mul	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_1/transpose	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_2/transpose	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/MatMul_1_grad/MatMul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/mul_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/mul	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/mul_grad/Sum	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/add_grad/Shape	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/add	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/add_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/add	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/attention_weights	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/add_grad/Sum	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/attention_weights	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/attention_weights_grad/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/dropout/div_grad/Shape	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/dropout/div	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/dropout/Shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/dropout/div_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/dropout/div	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/dropout/mul_grad/Shape	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/dropout/mul	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/dropout/Shape	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/dropout/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/dropout/mul_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/dropout/random_uniform/RandomUniform	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/dropout/add	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/dropout/add	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/dropout/Floor	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/dropout/Floor	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/dropout/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/dropout/mul_grad/Mul	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/dropout/mul	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/MatMul_1_grad/MatMul_1	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/MatMul_1	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/combine_heads/transpose	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/combine_heads/Shape	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/combine_heads/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/combine_heads/Reshape_grad/Shape	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/combine_heads/Reshape	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/combine_heads/Shape	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/combine_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/combine_heads/strided_slice	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/combine_heads/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/combine_heads/Reshape_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/combine_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/combine_heads/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/combine_heads/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/combine_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/combine_heads/Reshape	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/combine_heads/Reshape	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Shape	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Shape	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Shape/_4350	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Shape/_4350	_SINK	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/GatherV2/_4353	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/concat_2	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/GatherV2/_4355	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Prod	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Prod/_4358	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/GatherV2_1/_4357	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Prod_1	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Prod_1/_4360	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Prod/_4358	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Prod/_4359	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Prod/_4359	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Prod_1/_4360	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Prod_1/_4361	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Prod_1/_4361	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/stack	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Reshape	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/MatMul	model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot_grad/Shape	
model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot	model/Transformer/decode/decoder_stack/layer_4/self_attention/dropout/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/dropout/div_grad/Shape	model/Transformer/decode/decoder_stack/layer_4/self_attention/dropout/div	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_4/self_attention/dropout/Shape	model/Transformer/decode/decoder_stack/layer_4/self_attention/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/dropout/div_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_4/self_attention/dropout/div	model/Transformer/decode/decoder_stack/layer_4/self_attention/dropout/mul	
model/Transformer/decode/decoder_stack/layer_4/self_attention/dropout/random_uniform/RandomUniform	model/Transformer/decode/decoder_stack/layer_4/self_attention/dropout/add	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/dropout/div_grad/Sum	
model/Transformer/decode/decoder_stack/layer_4/self_attention/dropout/add	model/Transformer/decode/decoder_stack/layer_4/self_attention/dropout/Floor	
model/Transformer/decode/decoder_stack/layer_4/self_attention/dropout/Floor	model/Transformer/decode/decoder_stack/layer_4/self_attention/dropout/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/dropout/mul_grad/Mul	
model/Transformer/decode/decoder_stack/layer_4/self_attention/dropout/mul	model/Transformer/decode/decoder_stack/layer_4/self_attention/add	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/add_grad/Shape_1	
model/Transformer/decode/decoder_stack/layer_4/self_attention/add	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/add	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/sub_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/Shape	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/Prod	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/add_grad/Reshape_1	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/sub_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/sub_grad/Shape_1	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/sub_grad/Shape	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/Shape/_4362	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/floordiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/sub_1_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/sub_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/sub_grad/Reshape_1	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/sub_1	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Square	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/Prod_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/Shape/_4362	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/Shape/_4363	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/Shape/_4363	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/DynamicStitch/_4364	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/floordiv_1	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/sub_1_grad/Sum_1	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/sub_grad/Sum_1	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Square	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/Prod	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/DynamicStitch/_4364	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/DynamicStitch/_4365	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/DynamicStitch/_4365	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/floordiv	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/Shape/_4366	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/floordiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/floordiv_1/_4368	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/floordiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/Tile	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Rsqrt	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/Prod_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/Shape/_4366	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/Shape/_4367	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/Shape/_4367	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch/_4370	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/floordiv_1/_4368	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/floordiv_1/_4369	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/floordiv_1/_4369	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/Cast	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/Cast	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/truediv	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Rsqrt	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch/_4370	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch/_4371	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch/_4371	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/floordiv	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/floordiv_1/_4372	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/floordiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/Tile	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_1	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_1_grad/Shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_1_grad/Reshape	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/floordiv_1/_4372	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/floordiv_1/_4373	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/floordiv_1/_4373	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/Cast	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/Cast	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/truediv	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_1	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/Reshape_grad/Shape	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_1_grad/Sum_1	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/Shape	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/Shape/_4374	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_1_grad/Sum_1	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/Shape/_4374	_SINK	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/GatherV2/_4377	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/concat_2	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/GatherV2/_4379	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/Prod	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/Prod/_4382	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/GatherV2_1/_4381	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/Prod_1	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/Prod_1/_4384	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/Prod/_4382	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/Prod/_4383	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/Prod/_4383	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/Prod_1/_4384	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/Prod_1/_4385	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/Prod_1/_4385	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/stack	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/Reshape	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/MatMul	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads/Reshape	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads/Shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads/Shape	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads/strided_slice	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads/Reshape	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads/Reshape	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads/transpose	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads/transpose	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/mul_grad/Shape	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/mul	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/mul_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/MatMul	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/add	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/add_grad/Shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/mul_grad/Sum	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/add	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/attention_weights	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/add_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/attention_weights	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/attention_weights_grad/mul_1	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/div_grad/Shape	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/div	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/add_grad/Sum	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/Shape	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/div_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/div	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/mul_grad/Shape	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/mul	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/random_uniform/RandomUniform	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/random_uniform/mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/mul_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/random_uniform/mul	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/add	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/add	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/Floor	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/Floor	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/mul_grad/Mul	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/mul	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/MatMul_1_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/mul_grad/BroadcastGradientArgs	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/MatMul_1	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/combine_heads/transpose	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/combine_heads/Shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/mul_grad/Sum	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/combine_heads/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/combine_heads/Reshape_grad/Shape	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/combine_heads/Reshape	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/combine_heads/Shape	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/combine_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/combine_heads/strided_slice	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/combine_heads/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/combine_heads/Reshape_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/combine_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/combine_heads/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/combine_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/combine_heads/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/combine_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/combine_heads/Reshape	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/combine_heads/Reshape	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/Reshape_grad/Shape	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/Shape	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/Shape/_4386	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/Reshape_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/Shape/_4386	_SINK	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/GatherV2/_4389	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/concat_2	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/GatherV2/_4391	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/Prod	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/Prod/_4394	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/GatherV2_1/_4393	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/Prod_1	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/Prod_1/_4396	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/Prod/_4394	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/Prod/_4395	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/Prod/_4395	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/Prod_1/_4396	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/Prod_1/_4397	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/Prod_1/_4397	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/stack	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/Reshape	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/MatMul	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot_grad/Shape	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/dropout/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/dropout/div_grad/Shape	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/dropout/div	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/dropout/Shape	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/dropout/div_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/dropout/div	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/dropout/mul	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/dropout/random_uniform/RandomUniform	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/dropout/add	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/dropout/div_grad/Sum	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/dropout/add	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/dropout/Floor	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/dropout/Floor	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/dropout/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/dropout/mul_grad/Mul	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/dropout/mul	model/Transformer/decode/decoder_stack/layer_4/encdec_attention/add	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/add_grad/Shape_1	
model/Transformer/decode/decoder_stack/layer_4/encdec_attention/add	model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/sub_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Shape	model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Prod	model/Transformer/decode/decoder_stack/layer_4/ffn/add	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/add_grad/Reshape_1	
model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/sub_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/sub_grad/Shape_1	model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/sub_grad/Shape	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Shape/_4398	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/floordiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/sub_1_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/sub_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/sub_grad/Reshape_1	
model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/sub_1	model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Square	model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Prod_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Shape/_4398	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Shape/_4399	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Shape/_4399	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/DynamicStitch/_4400	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/floordiv_1	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/sub_1_grad/Sum_1	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/sub_grad/Sum_1	
model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Square	model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Prod	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/DynamicStitch/_4400	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/DynamicStitch/_4401	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/DynamicStitch/_4401	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/floordiv	
model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1	model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Shape/_4402	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/floordiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/floordiv_1/_4404	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/floordiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Tile	
model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add	model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Rsqrt	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Prod_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Shape/_4402	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Shape/_4403	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Shape/_4403	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/DynamicStitch/_4406	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/floordiv_1/_4404	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/floordiv_1/_4405	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/floordiv_1/_4405	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Cast	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Cast	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/truediv	
model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Rsqrt	model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/DynamicStitch/_4406	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/DynamicStitch/_4407	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/DynamicStitch/_4407	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/floordiv	
model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul	model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/floordiv_1/_4408	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/floordiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Tile	
model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_1	model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_1_grad/Shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Reshape	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/floordiv_1/_4408	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/floordiv_1/_4409	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/floordiv_1/_4409	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Cast	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Cast	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/truediv	
model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_1	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Shape	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Sum_1	
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Shape	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Shape/_4410	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_1_grad/Sum_1	
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Shape/_4410	_SINK	
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2/_4413	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/concat_2	
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot	
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2/_4415	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Prod	
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Prod/_4418	
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2_1/_4417	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1	
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1/_4420	
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Prod/_4418	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Prod/_4419	
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Prod/_4419	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1/_4420	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1/_4421	
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1/_4421	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/stack	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Reshape	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/MatMul	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot_grad/Shape	
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/BiasAdd	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/BiasAdd	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Relu	
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Relu	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/dropout/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/dropout/div_grad/Shape	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/dropout/div	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Relu_grad/ReluGrad	
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/dropout/Shape	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/dropout/div_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/dropout/div	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/dropout/mul	
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/dropout/random_uniform/RandomUniform	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/dropout/add	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/dropout/div_grad/Sum	
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/dropout/add	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/dropout/Floor	
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/dropout/Floor	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/dropout/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/dropout/mul_grad/Mul	
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/dropout/mul	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Shape	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Shape	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Shape/_4422	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Shape/_4422	_SINK	
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/GatherV2/_4425	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/concat_2	
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot	
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/GatherV2/_4427	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Prod	
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Prod/_4430	
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/GatherV2_1/_4429	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Prod_1	
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Prod_1/_4432	
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Prod/_4430	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Prod/_4431	
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Prod/_4431	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Prod_1/_4432	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Prod_1/_4433	
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Prod_1/_4433	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/stack	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Reshape	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot	model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/BiasAdd	
model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/BiasAdd	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/dropout/div_grad/Shape	model/Transformer/decode/decoder_stack/layer_4/ffn/dropout/Shape	model/Transformer/decode/decoder_stack/layer_4/ffn/dropout/div	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/dropout/div_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_4/ffn/dropout/Shape	model/Transformer/decode/decoder_stack/layer_4/ffn/dropout/random_uniform/RandomUniform	
model/Transformer/decode/decoder_stack/layer_4/ffn/dropout/div	model/Transformer/decode/decoder_stack/layer_4/ffn/dropout/mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/dropout/div_grad/Sum	
model/Transformer/decode/decoder_stack/layer_4/ffn/dropout/random_uniform/RandomUniform	model/Transformer/decode/decoder_stack/layer_4/ffn/dropout/add	
model/Transformer/decode/decoder_stack/layer_4/ffn/dropout/add	model/Transformer/decode/decoder_stack/layer_4/ffn/dropout/Floor	
model/Transformer/decode/decoder_stack/layer_4/ffn/dropout/Floor	model/Transformer/decode/decoder_stack/layer_4/ffn/dropout/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/dropout/mul_grad/Mul	
model/Transformer/decode/decoder_stack/layer_4/ffn/dropout/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/add_grad/Shape_1	model/Transformer/decode/decoder_stack/layer_4/ffn/add	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/add_grad/Reshape_1	
model/Transformer/decode/decoder_stack/layer_4/ffn/add	model/Transformer/decode/decoder_stack/layer_5/self_attention/add	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/sub_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Shape	model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Prod	model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/sub_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/sub_grad/Shape	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Shape/_4434	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/floordiv	
model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/sub_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/sub_grad/Shape_1	model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Shape/_4434	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Shape/_4435	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Shape/_4435	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/DynamicStitch/_4436	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/sub_1_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/sub_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/sub_grad/Reshape_1	
model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/sub_1	model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Square	model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Prod_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/DynamicStitch/_4436	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/DynamicStitch/_4437	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/DynamicStitch/_4437	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/floordiv	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/sub_1_grad/Sum_1	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/sub_grad/Sum_1	
model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Square	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Shape	model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Prod	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/floordiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Shape/_4438	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/floordiv	
model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_grad/Shape	model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/floordiv_1/_4440	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Shape/_4438	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Shape/_4439	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Shape/_4439	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/DynamicStitch/_4442	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add	model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Rsqrt	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Prod_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/floordiv_1/_4440	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/floordiv_1/_4441	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/floordiv_1/_4441	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Cast	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Cast	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/DynamicStitch/_4442	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/DynamicStitch/_4443	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/DynamicStitch/_4443	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/floordiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_grad/Sum	
model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Rsqrt	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_grad/Shape_1	model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/floordiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_grad/Reshape_1	
model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Shape	model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/floordiv_1/_4444	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/Shape	model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/floordiv_1/_4444	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/floordiv_1/_4445	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/floordiv_1/_4445	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Cast	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Cast	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_1	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/v/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/k/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Reshape_grad/Shape	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/Sum_1	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Shape	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Shape/_4446	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/v/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/k/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Shape/_4446	_SINK	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/GatherV2_1/_4449	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Prod_1	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Prod_1/_4456	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/GatherV2/_4451	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Prod	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Prod/_4454	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/GatherV2/_4453	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/concat_2	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/k/Tensordot	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/v/Tensordot	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Prod/_4454	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Prod/_4455	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Prod/_4455	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Prod_1/_4456	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Prod_1/_4457	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Prod_1/_4457	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/stack	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Reshape	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/MatMul	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/k/Tensordot/MatMul	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/v/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads/Reshape	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/k/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/k/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/k/Tensordot	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_1/Reshape	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/v/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/v/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/v/Tensordot	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_2/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads/Shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/k/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/k/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/k/Tensordot	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_1/Shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/v/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/v/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/v/Tensordot	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_2/Shape	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads/Shape	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads/strided_slice_1	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_1/Shape	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_1/strided_slice_1	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_2/Shape	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_2/strided_slice	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_1/strided_slice	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_1/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_1/strided_slice_1	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_1/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_2/strided_slice_1	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_2/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_2/strided_slice	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_2/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads/Reshape	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_1/Reshape/shape	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_1/Reshape	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_2/Reshape/shape	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_2/Reshape	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads/Reshape	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads/transpose	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_1/Reshape	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_1/transpose	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_2/Reshape	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_2/transpose	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/mul_grad/Shape	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/mul	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_1/transpose	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/MatMul_grad/MatMul	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_2/transpose	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/MatMul_1_grad/MatMul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/mul_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/mul	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/mul_grad/Sum	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/add_grad/Shape	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/add	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/add_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/add	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/attention_weights	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/add_grad/Sum	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/attention_weights	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/dropout/div_grad/Shape	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/dropout/div	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/dropout/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/attention_weights_grad/mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/dropout/div_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/dropout/div	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/dropout/mul_grad/Shape	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/dropout/mul	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/dropout/Shape	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/dropout/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/dropout/mul_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/dropout/random_uniform/RandomUniform	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/dropout/add	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/dropout/add	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/dropout/Floor	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/dropout/Floor	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/dropout/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/dropout/mul_grad/Mul	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/dropout/mul	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/MatMul_1_grad/MatMul_1	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/MatMul_1	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/combine_heads/transpose	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/combine_heads/Shape	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/combine_heads/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/combine_heads/Reshape_grad/Shape	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/combine_heads/Reshape	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/combine_heads/Shape	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/combine_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/combine_heads/strided_slice	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/combine_heads/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/combine_heads/Reshape_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/combine_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/combine_heads/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/combine_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/combine_heads/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/combine_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/combine_heads/Reshape	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/combine_heads/Reshape	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Shape	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Shape	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Shape/_4458	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Shape/_4458	_SINK	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/GatherV2/_4461	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/concat_2	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/GatherV2/_4463	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Prod	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Prod/_4466	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/GatherV2_1/_4465	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Prod_1	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Prod_1/_4468	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Prod/_4466	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Prod/_4467	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Prod/_4467	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Prod_1/_4468	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Prod_1/_4469	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Prod_1/_4469	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/stack	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Reshape	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/dropout/div_grad/Shape	model/Transformer/decode/decoder_stack/layer_5/self_attention/dropout/Shape	model/Transformer/decode/decoder_stack/layer_5/self_attention/dropout/div	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/dropout/div_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_5/self_attention/dropout/Shape	model/Transformer/decode/decoder_stack/layer_5/self_attention/dropout/random_uniform/RandomUniform	
model/Transformer/decode/decoder_stack/layer_5/self_attention/dropout/div	model/Transformer/decode/decoder_stack/layer_5/self_attention/dropout/mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/dropout/div_grad/Sum	
model/Transformer/decode/decoder_stack/layer_5/self_attention/dropout/random_uniform/RandomUniform	model/Transformer/decode/decoder_stack/layer_5/self_attention/dropout/add	
model/Transformer/decode/decoder_stack/layer_5/self_attention/dropout/add	model/Transformer/decode/decoder_stack/layer_5/self_attention/dropout/Floor	
model/Transformer/decode/decoder_stack/layer_5/self_attention/dropout/Floor	model/Transformer/decode/decoder_stack/layer_5/self_attention/dropout/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/dropout/mul_grad/Mul	
model/Transformer/decode/decoder_stack/layer_5/self_attention/dropout/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/add_grad/Shape_1	model/Transformer/decode/decoder_stack/layer_5/self_attention/add	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/add_grad/Reshape_1	
model/Transformer/decode/decoder_stack/layer_5/self_attention/add	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/sub_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/Shape	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/Prod	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/sub_1	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/add	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/sub_grad/Shape	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/Shape/_4470	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/floordiv	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/sub_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/sub_grad/Shape_1	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/Shape/_4470	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/Shape/_4471	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/Shape/_4471	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/DynamicStitch/_4472	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/sub_1_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/sub_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/sub_grad/Reshape_1	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/sub_1	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Square	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/Prod_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/DynamicStitch/_4472	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/DynamicStitch/_4473	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/DynamicStitch/_4473	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/floordiv	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/sub_1_grad/Sum_1	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/sub_grad/Sum_1	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Square	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/Shape	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/Prod	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/floordiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/Shape/_4474	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/floordiv	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_grad/Shape	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/floordiv_1/_4476	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/Shape/_4474	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/Shape/_4475	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/Shape/_4475	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch/_4478	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Rsqrt	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/Prod_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/floordiv_1/_4476	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/floordiv_1/_4477	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/floordiv_1/_4477	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/Cast	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/Cast	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch/_4478	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch/_4479	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/DynamicStitch/_4479	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/floordiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_grad/Sum	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Rsqrt	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_grad/Shape_1	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/floordiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_grad/Reshape_1	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_1_grad/Shape	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/floordiv_1/_4480	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_1_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_1_grad/Shape	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/floordiv_1/_4480	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/floordiv_1/_4481	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/floordiv_1/_4481	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/Cast	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/Cast	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_1_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_1	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/Reshape_grad/Shape	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_1_grad/Sum_1	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/Shape	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/Shape/_4482	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/Reshape_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/Shape/_4482	_SINK	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/GatherV2/_4485	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/concat_2	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/GatherV2/_4487	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/Prod	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/Prod/_4490	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/GatherV2_1/_4489	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/Prod_1	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/Prod_1/_4492	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/Prod/_4490	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/Prod/_4491	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/Prod/_4491	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/Prod_1/_4492	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/Prod_1/_4493	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/Prod_1/_4493	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/stack	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/Reshape	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads/Shape	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads/Shape	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads/strided_slice	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads/Reshape	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads/Reshape	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads/transpose	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/mul_grad/Shape	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/mul_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/mul	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/mul_grad/Sum	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/add_grad/Shape	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/add	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/add_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/add	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/attention_weights	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/add_grad/Sum	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/attention_weights	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/attention_weights_grad/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/div_grad/Shape	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/Shape	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/div	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/div_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/Shape	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/random_uniform/RandomUniform	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/div	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/mul_grad/Shape	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/div_grad/Sum	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/random_uniform/RandomUniform	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/random_uniform/mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/mul_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/mul_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/random_uniform/mul	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/add	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/add	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/Floor	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/Floor	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/mul_grad/Shape_1	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/mul_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/mul_grad/BroadcastGradientArgs	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/mul	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/MatMul_1_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/mul_grad/Sum	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/MatMul_1	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/combine_heads/transpose	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/combine_heads/Shape	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/combine_heads/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/combine_heads/Reshape_grad/Shape	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/combine_heads/Reshape	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/combine_heads/Shape	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/combine_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/combine_heads/strided_slice	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/combine_heads/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/combine_heads/Reshape_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/combine_heads/strided_slice_1	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/combine_heads/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/combine_heads/strided_slice	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/combine_heads/Reshape/shape	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/combine_heads/Reshape/shape	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/combine_heads/Reshape	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/combine_heads/Reshape	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/Reshape_grad/Shape	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/Shape	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/Shape/_4494	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/Reshape_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/Shape/_4494	_SINK	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/GatherV2/_4497	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/concat_2	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/GatherV2/_4499	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/Prod	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/Prod/_4502	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/GatherV2_1/_4501	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/Prod_1	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/Prod_1/_4504	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/Prod/_4502	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/Prod/_4503	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/Prod/_4503	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/Prod_1/_4504	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/Prod_1/_4505	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/Prod_1/_4505	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/stack	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/Reshape	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/MatMul	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot_grad/Shape	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/dropout/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/dropout/div_grad/Shape	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/dropout/div	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/dropout/Shape	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/dropout/random_uniform/RandomUniform	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/dropout/div_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/dropout/div	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/dropout/mul	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/dropout/random_uniform/RandomUniform	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/dropout/add	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/dropout/div_grad/Sum	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/dropout/add	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/dropout/Floor	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/dropout/Floor	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/dropout/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/dropout/mul_grad/Mul	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/dropout/mul	model/Transformer/decode/decoder_stack/layer_5/encdec_attention/add	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/add_grad/Shape_1	
model/Transformer/decode/decoder_stack/layer_5/encdec_attention/add	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/sub_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Shape	model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Prod	model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/sub_1	model/Transformer/decode/decoder_stack/layer_5/ffn/add	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/add_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/sub_grad/Shape	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Shape/_4506	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/floordiv	
model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/sub_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/sub_grad/Shape_1	model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Shape/_4506	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Shape/_4507	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Shape/_4507	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/DynamicStitch/_4508	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/sub_1_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/sub_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/sub_grad/Reshape_1	
model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/sub_1	model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Square	model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Prod_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/DynamicStitch/_4508	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/DynamicStitch/_4509	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/DynamicStitch/_4509	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/floordiv	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/sub_1_grad/Sum_1	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/sub_grad/Sum_1	
model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Square	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Shape	model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Prod	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/floordiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Shape/_4510	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/floordiv	
model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_grad/Shape	model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/floordiv_1/_4512	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Shape/_4510	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Shape/_4511	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Shape/_4511	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/DynamicStitch/_4514	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add	model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Rsqrt	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Prod_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/floordiv_1/_4512	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/floordiv_1/_4513	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/floordiv_1/_4513	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Cast	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Cast	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/DynamicStitch/_4514	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/DynamicStitch/_4515	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/DynamicStitch/_4515	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/floordiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_grad/Sum	
model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Rsqrt	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_grad/Shape_1	model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/floordiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_grad/Reshape_1	
model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Shape	model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/floordiv_1/_4516	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_1_grad/Shape	model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/floordiv_1/_4516	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/floordiv_1/_4517	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/floordiv_1/_4517	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Cast	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Cast	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_1_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_1	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Shape	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_1_grad/Sum_1	
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Shape	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Shape/_4518	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Shape/_4518	_SINK	
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2/_4521	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/concat_2	
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot	
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2/_4523	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Prod	
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Prod/_4526	
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/GatherV2_1/_4525	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1	
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1/_4528	
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Prod/_4526	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Prod/_4527	
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Prod/_4527	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1/_4528	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1/_4529	
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Prod_1/_4529	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/stack	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Reshape	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/BiasAdd	
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/BiasAdd	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Relu	
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Relu	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/dropout/div_grad/Shape	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/dropout/Shape	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/dropout/div	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Relu_grad/ReluGrad	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/dropout/div_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/dropout/Shape	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/dropout/random_uniform/RandomUniform	
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/dropout/div	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/dropout/mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/dropout/div_grad/Sum	
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/dropout/random_uniform/RandomUniform	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/dropout/add	
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/dropout/add	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/dropout/Floor	
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/dropout/Floor	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/dropout/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/dropout/mul_grad/Mul	
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/dropout/mul	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Shape	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Shape	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Shape/_4530	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Shape/_4530	_SINK	
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/GatherV2/_4533	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/concat_2	
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/concat_2	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot	
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/GatherV2/_4535	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Prod	
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Prod	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Prod/_4538	
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/GatherV2_1/_4537	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Prod_1	
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Prod_1	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Prod_1/_4540	
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Prod/_4538	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Prod/_4539	
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Prod/_4539	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Prod_1/_4540	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Prod_1/_4541	
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Prod_1/_4541	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/stack	
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/stack	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Reshape	
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Reshape	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul_1	
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot_grad/Shape	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot	model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/BiasAdd	
model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/BiasAdd	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/dropout/div_grad/Shape	model/Transformer/decode/decoder_stack/layer_5/ffn/dropout/Shape	model/Transformer/decode/decoder_stack/layer_5/ffn/dropout/div	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/dropout/div_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/dropout/div_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_5/ffn/dropout/Shape	model/Transformer/decode/decoder_stack/layer_5/ffn/dropout/random_uniform/RandomUniform	
model/Transformer/decode/decoder_stack/layer_5/ffn/dropout/div	model/Transformer/decode/decoder_stack/layer_5/ffn/dropout/mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/dropout/div_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/dropout/div_grad/Sum	
model/Transformer/decode/decoder_stack/layer_5/ffn/dropout/random_uniform/RandomUniform	model/Transformer/decode/decoder_stack/layer_5/ffn/dropout/add	
model/Transformer/decode/decoder_stack/layer_5/ffn/dropout/add	model/Transformer/decode/decoder_stack/layer_5/ffn/dropout/Floor	
model/Transformer/decode/decoder_stack/layer_5/ffn/dropout/Floor	model/Transformer/decode/decoder_stack/layer_5/ffn/dropout/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/dropout/mul_grad/Mul	
model/Transformer/decode/decoder_stack/layer_5/ffn/dropout/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/add_grad/Shape_1	model/Transformer/decode/decoder_stack/layer_5/ffn/add	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/add_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/add_grad/Reshape_1	
model/Transformer/decode/decoder_stack/layer_5/ffn/add	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/sub_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/Shape	model/Transformer/decode/decoder_stack/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/Prod	model/Transformer/decode/decoder_stack/layer_normalization/sub_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/sub_grad/Shape	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/Shape/_4542	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/floordiv	
model/Transformer/decode/decoder_stack/layer_normalization/Mean	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/sub_1_grad/Shape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/sub_grad/Shape_1	model/Transformer/decode/decoder_stack/layer_normalization/sub_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/Shape/_4542	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/Shape/_4543	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/Shape/_4543	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/DynamicStitch/_4544	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/sub_1_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/sub_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/sub_grad/Reshape_1	
model/Transformer/decode/decoder_stack/layer_normalization/sub_1	model/Transformer/decode/decoder_stack/layer_normalization/Square	model/Transformer/decode/decoder_stack/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/Prod_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/DynamicStitch/_4544	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/DynamicStitch/_4545	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/DynamicStitch/_4545	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/floordiv	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/sub_1_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/sub_1_grad/Sum_1	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/sub_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/sub_grad/Sum_1	
model/Transformer/decode/decoder_stack/layer_normalization/Square	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/Shape	model/Transformer/decode/decoder_stack/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/Prod	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/floordiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/Shape/_4546	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/floordiv	
model/Transformer/decode/decoder_stack/layer_normalization/Mean_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/add_grad/Shape	model/Transformer/decode/decoder_stack/layer_normalization/add	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/Prod_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/floordiv_1/_4548	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/Shape/_4546	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/Shape/_4547	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/Shape/_4547	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/DynamicStitch	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/DynamicStitch	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/DynamicStitch/_4550	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/Prod	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/add_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/add_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_normalization/add	model/Transformer/decode/decoder_stack/layer_normalization/Rsqrt	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/Prod_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/Maximum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/floordiv_1/_4548	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/floordiv_1/_4549	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/floordiv_1/_4549	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/Cast	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/Cast	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/DynamicStitch/_4550	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/DynamicStitch/_4551	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/DynamicStitch/_4551	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/Maximum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/floordiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/add_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/add_grad/Sum	
model/Transformer/decode/decoder_stack/layer_normalization/Rsqrt	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_grad/Shape_1	model/Transformer/decode/decoder_stack/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/Maximum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/floordiv_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/floordiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_grad/Shape_1	ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_grad/Reshape_1	
model/Transformer/decode/decoder_stack/layer_normalization/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_1_grad/Shape	model/Transformer/decode/decoder_stack/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/floordiv_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/floordiv_1/_4552	
ConstantFolding/model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_grad/BroadcastGradientArgs-bcastargs-1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_1_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_normalization/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/add_1_grad/Shape	model/Transformer/decode/decoder_stack/layer_normalization/add_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/floordiv_1/_4552	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/floordiv_1/_4553	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/floordiv_1/_4553	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/Cast	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/Cast	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/add_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/add_1_grad/Reshape	
model/Transformer/decode/decoder_stack/layer_normalization/add_1	model/get_train_op/gradients/model/Transformer/decode/presoftmax_linear/Reshape_grad/Shape	model/Transformer/decode/presoftmax_linear/Reshape	model/Transformer/decode/presoftmax_linear/Shape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/add_1_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/add_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/presoftmax_linear/Reshape_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/presoftmax_linear/Reshape_grad/Reshape	
model/Transformer/decode/presoftmax_linear/Reshape	model/Transformer/decode/presoftmax_linear/MatMul	model/get_train_op/gradients/model/Transformer/decode/presoftmax_linear/MatMul_grad/MatMul_1	
model/Transformer/decode/presoftmax_linear/Shape	model/Transformer/decode/presoftmax_linear/strided_slice	model/Transformer/decode/presoftmax_linear/strided_slice_1	
model/Transformer/decode/presoftmax_linear/MatMul	model/get_train_op/gradients/model/Transformer/decode/presoftmax_linear/Reshape_1_grad/Shape	model/Transformer/decode/presoftmax_linear/Reshape_1	
model/Transformer/decode/presoftmax_linear/strided_slice	model/Transformer/decode/presoftmax_linear/Reshape_1/shape	
model/Transformer/decode/presoftmax_linear/strided_slice_1	model/Transformer/decode/presoftmax_linear/Reshape_1/shape	
model/get_train_op/gradients/model/Transformer/decode/presoftmax_linear/Reshape_1_grad/Shape	model/get_train_op/gradients/model/Transformer/decode/presoftmax_linear/Reshape_1_grad/Reshape	
model/Transformer/decode/presoftmax_linear/Reshape_1/shape	model/Transformer/decode/presoftmax_linear/Reshape_1	
model/Transformer/decode/presoftmax_linear/Reshape_1	model/get_train_op/gradients/model/loss/pad_to_same_length/Pad_grad/Shape	model/loss/pad_to_same_length/Shape	model/loss/pad_to_same_length/Pad	
model/get_train_op/gradients/model/loss/pad_to_same_length/Pad_grad/Shape	model/get_train_op/gradients/model/loss/pad_to_same_length/Pad_grad/Slice_1	
model/loss/pad_to_same_length/Shape	model/loss/pad_to_same_length/strided_slice	
model/loss/pad_to_same_length/strided_slice	model/loss/pad_to_same_length/Maximum	model/loss/pad_to_same_length/sub	
model/loss/pad_to_same_length/Maximum	model/loss/pad_to_same_length/sub	model/loss/pad_to_same_length/sub_1	
model/loss/pad_to_same_length/sub	model/loss/pad_to_same_length/Pad/paddings/1	
model/loss/pad_to_same_length/sub_1	model/loss/pad_to_same_length/Pad_1/paddings/1	
model/loss/pad_to_same_length/Pad/paddings/1	model/loss/pad_to_same_length/Pad/paddings	
model/loss/pad_to_same_length/Pad_1/paddings/1	model/loss/pad_to_same_length/Pad_1/paddings	
model/loss/pad_to_same_length/Pad/paddings	model/get_train_op/gradients/model/loss/pad_to_same_length/Pad_grad/Slice	model/loss/pad_to_same_length/Pad	
model/loss/pad_to_same_length/Pad_1/paddings	model/loss/pad_to_same_length/Pad_1/paddings/_4556	
model/get_train_op/gradients/model/loss/pad_to_same_length/Pad_grad/Slice	model/get_train_op/gradients/model/loss/pad_to_same_length/Pad_grad/Reshape	
model/loss/pad_to_same_length/Pad	model/get_train_op/gradients/model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/Reshape_grad/Shape	model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/Shape_1	model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/Reshape	
FunctionBufferingResourceGetNext/_4554	_SINK	
model/loss/pad_to_same_length/Pad_1/paddings/_4556	_SINK	
model/get_train_op/gradients/model/loss/pad_to_same_length/Pad_grad/Reshape	model/get_train_op/gradients/model/loss/pad_to_same_length/Pad_grad/Slice_1	
model/get_train_op/gradients/model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/Reshape_grad/Shape	model/get_train_op/gradients/model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/Reshape_grad/Reshape	
model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/Shape_1	model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/Slice	model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/Slice_2	
model/loss/pad_to_same_length/Pad_1/_4559	model/loss/smoothing_cross_entropy/Cast	model/loss/NotEqual	
model/loss/smoothing_cross_entropy/Cast	model/loss/smoothing_cross_entropy/one_hot	
model/loss/NotEqual	model/loss/ToFloat	
model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/Slice	model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/concat	
model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/Slice_2	model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/Reshape_2	
model/loss/smoothing_cross_entropy/one_hot	model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/Shape_2	model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/Reshape_1	
model/loss/ToFloat	model/get_train_op/gradients/model/loss/mul_grad/Shape_1	model/Sum_1	model/loss/mul	model/get_train_op/gradients/model/loss/mul_grad/Mul	
model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/concat	model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/Reshape	
model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/Shape_2	model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/Slice_1	
model/get_train_op/gradients/model/loss/mul_grad/Shape_1	model/get_train_op/gradients/model/loss/mul_grad/BroadcastGradientArgs	
model/Sum_1	model/get_train_op/gradients/model/truediv_grad/RealDiv	model/truediv	
model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/Reshape	model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits	
model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/Slice_1	model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/concat_1	
model/get_train_op/gradients/model/truediv_grad/RealDiv	model/get_train_op/gradients/model/Sum_grad/Reshape	
model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/concat_1	model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/Reshape_1	
model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/Reshape_1	model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits	
model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits	model/get_train_op/gradients/model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/Reshape_2_grad/Shape	model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/Reshape_2	model/get_train_op/gradients/model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits_grad/mul	
model/get_train_op/gradients/model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/Reshape_2_grad/Shape	model/get_train_op/gradients/model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/Reshape_2_grad/Reshape	
model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/Reshape_2	model/get_train_op/gradients/model/loss/smoothing_cross_entropy/sub_grad/Shape	model/loss/smoothing_cross_entropy/sub	
model/get_train_op/gradients/model/loss/smoothing_cross_entropy/sub_grad/Shape	model/get_train_op/gradients/model/loss/smoothing_cross_entropy/sub_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/loss/smoothing_cross_entropy/sub_grad/Reshape	
model/loss/smoothing_cross_entropy/sub	model/get_train_op/gradients/model/loss/mul_grad/Shape	model/loss/mul	
model/get_train_op/gradients/model/loss/smoothing_cross_entropy/sub_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/loss/smoothing_cross_entropy/sub_grad/Sum	
model/get_train_op/gradients/model/loss/mul_grad/Shape	model/get_train_op/gradients/model/loss/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/loss/mul_grad/Reshape	
model/loss/mul	model/get_train_op/gradients/model/Sum_grad/Shape	model/Sum	
model/get_train_op/gradients/model/loss/mul_grad/BroadcastGradientArgs	model/get_train_op/gradients/model/loss/mul_grad/Sum	
model/get_train_op/gradients/model/Sum_grad/Shape	model/get_train_op/gradients/model/Sum_grad/Tile	
model/Sum	model/truediv	model/get_train_op/gradients/model/Sum_grad/Reshape	
model/truediv	model/truediv/_4576	
model/get_train_op/gradients/model/Sum_grad/Reshape	model/get_train_op/gradients/model/Sum_grad/Tile	
model/get_train_op/gradients/model/Sum_grad/Tile	model/get_train_op/gradients/model/loss/mul_grad/Mul	
model/get_train_op/gradients/model/loss/mul_grad/Mul	model/get_train_op/gradients/model/loss/mul_grad/Sum	
model/get_train_op/gradients/model/loss/mul_grad/Sum	model/get_train_op/gradients/model/loss/mul_grad/Reshape	
model/get_train_op/gradients/model/loss/mul_grad/Reshape	model/get_train_op/gradients/model/loss/smoothing_cross_entropy/sub_grad/Sum	
model/get_train_op/gradients/model/loss/smoothing_cross_entropy/sub_grad/Sum	model/get_train_op/gradients/model/loss/smoothing_cross_entropy/sub_grad/Reshape	
model/get_train_op/gradients/model/loss/smoothing_cross_entropy/sub_grad/Reshape	model/get_train_op/gradients/model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/Reshape_2_grad/Reshape	
model/get_train_op/gradients/model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/Reshape_2_grad/Reshape	model/get_train_op/gradients/model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits_grad/ExpandDims	
model/get_train_op/gradients/model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits_grad/ExpandDims	model/get_train_op/gradients/model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits_grad/mul	
model/get_train_op/gradients/model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits_grad/mul	model/get_train_op/gradients/model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/Reshape_grad/Reshape	
model/get_train_op/gradients/model/loss/smoothing_cross_entropy/softmax_cross_entropy_with_logits/Reshape_grad/Reshape	model/get_train_op/gradients/model/loss/pad_to_same_length/Pad_grad/Slice_1	
model/get_train_op/gradients/model/loss/pad_to_same_length/Pad_grad/Slice_1	model/get_train_op/gradients/model/Transformer/decode/presoftmax_linear/Reshape_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/presoftmax_linear/Reshape_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/presoftmax_linear/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/presoftmax_linear/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/presoftmax_linear/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/presoftmax_linear/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/presoftmax_linear/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/presoftmax_linear/Reshape_grad/Reshape	model/get_train_op/gradients/concat	
model/get_train_op/gradients/model/Transformer/decode/presoftmax_linear/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/add_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/add_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/add_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/add_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/add_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_1_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_1_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/AddN_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/mul_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/AddN_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/sub_1_grad/Neg	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/sub_1_grad/Neg	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/sub_1_grad/Reshape_1	model/get_train_op/gradients/AddN	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/Tile	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_1_grad/truediv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Square_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Square_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/sub_grad/Neg	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/AddN	model/get_train_op/gradients/AddN_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/sub_grad/Neg	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/sub_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/sub_grad/Reshape_1	model/get_train_op/gradients/AddN	
model/get_train_op/gradients/AddN	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/Tile	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_normalization/Mean_grad/truediv	model/get_train_op/gradients/AddN_1	
model/get_train_op/gradients/AddN_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/add_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/add_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/dropout/mul_grad/Mul	model/get_train_op/gradients/AddN_3	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/add_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/BiasAdd_grad/BiasAddGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/BiasAdd_grad/BiasAddGrad	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/dropout/mul_grad/Mul	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Relu_grad/ReluGrad	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Relu_grad/ReluGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/BiasAdd_grad/BiasAddGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/BiasAdd_grad/BiasAddGrad	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_1_grad/Sum_1	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/AddN_3	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/mul_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/AddN_3	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/sub_1_grad/Neg	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/sub_1_grad/Neg	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/sub_1_grad/Reshape_1	model/get_train_op/gradients/AddN_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Tile	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/truediv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Square_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Square_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/sub_grad/Neg	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/AddN_2	model/get_train_op/gradients/AddN_3	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/sub_grad/Neg	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/sub_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/sub_grad/Reshape_1	model/get_train_op/gradients/AddN_2	
model/get_train_op/gradients/AddN_2	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Tile	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/ffn/layer_normalization/Mean_grad/truediv	model/get_train_op/gradients/AddN_3	
model/get_train_op/gradients/AddN_3	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/add_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/add_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/AddN_5	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/add_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/combine_heads/Reshape_grad/Reshape	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/combine_heads/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/combine_heads/transpose_grad/transpose	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/combine_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/MatMul_1_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/MatMul_1_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/MatMul_1_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/MatMul_1_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/v/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/v/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/v/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/v/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/v/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/v/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/v/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/v/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/AddN_39	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/attention_weights_grad/sub	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/attention_weights_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/attention_weights_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/attention_weights_grad/sub	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/attention_weights_grad/sub	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/attention_weights_grad/mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/attention_weights_grad/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/k/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/k/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/k/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/k/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/k/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/k/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/k/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/k/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads/transpose_grad/transpose	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/AddN_39	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/split_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/q/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/q/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_1_grad/Sum_1	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_1_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_1_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/AddN_5	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/mul_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/AddN_5	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/sub_1_grad/Neg	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/sub_1_grad/Neg	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/sub_1_grad/Reshape_1	model/get_train_op/gradients/AddN_4	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/Tile	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_1_grad/truediv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Square_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Square_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/sub_grad/Neg	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/AddN_4	model/get_train_op/gradients/AddN_5	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/sub_grad/Neg	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/sub_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/sub_grad/Reshape_1	model/get_train_op/gradients/AddN_4	
model/get_train_op/gradients/AddN_4	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/Tile	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/encdec_attention/layer_normalization/Mean_grad/truediv	model/get_train_op/gradients/AddN_5	
model/get_train_op/gradients/AddN_5	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/add_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/add_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/AddN_8	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/add_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/combine_heads/Reshape_grad/Reshape	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/combine_heads/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/combine_heads/transpose_grad/transpose	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/combine_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/MatMul_1_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/MatMul_1_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/MatMul_1_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/MatMul_1_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/v/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/dropout/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/v/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/dropout/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/AddN_6	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/attention_weights_grad/sub	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/attention_weights_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/attention_weights_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/attention_weights_grad/sub	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/attention_weights_grad/sub	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/attention_weights_grad/mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/attention_weights_grad/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/k/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/k/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads/transpose_grad/transpose	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/AddN_6	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/split_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/AddN_6	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/AddN_6	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/AddN_8	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/mul_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/AddN_8	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/sub_1_grad/Neg	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/sub_1_grad/Neg	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/sub_1_grad/Reshape_1	model/get_train_op/gradients/AddN_7	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Tile	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/truediv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Square_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Square_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/sub_grad/Neg	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/AddN_7	model/get_train_op/gradients/AddN_8	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/sub_grad/Neg	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/sub_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/sub_grad/Reshape_1	model/get_train_op/gradients/AddN_7	
model/get_train_op/gradients/AddN_7	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Tile	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/truediv	model/get_train_op/gradients/AddN_8	
model/get_train_op/gradients/AddN_8	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/add_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/add_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/dropout/mul_grad/Mul	model/get_train_op/gradients/AddN_10	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/add_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/BiasAdd_grad/BiasAddGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/BiasAdd_grad/BiasAddGrad	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/dropout/mul_grad/Mul	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Relu_grad/ReluGrad	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Relu_grad/ReluGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/BiasAdd_grad/BiasAddGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/BiasAdd_grad/BiasAddGrad	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_1_grad/Sum_1	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/AddN_10	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/mul_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/AddN_10	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/sub_1_grad/Neg	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/sub_1_grad/Neg	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/sub_1_grad/Reshape_1	model/get_train_op/gradients/AddN_9	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Tile	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/truediv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Square_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Square_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/sub_grad/Neg	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/AddN_9	model/get_train_op/gradients/AddN_10	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/sub_grad/Neg	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/sub_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/sub_grad/Reshape_1	model/get_train_op/gradients/AddN_9	
model/get_train_op/gradients/AddN_9	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Tile	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/ffn/layer_normalization/Mean_grad/truediv	model/get_train_op/gradients/AddN_10	
model/get_train_op/gradients/AddN_10	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/add_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/add_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/AddN_12	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/add_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/combine_heads/Reshape_grad/Reshape	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/combine_heads/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/combine_heads/transpose_grad/transpose	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/combine_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/MatMul_1_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/MatMul_1_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/MatMul_1_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/MatMul_1_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/v/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/v/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/v/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/v/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/v/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/v/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/v/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/v/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/AddN_39	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/attention_weights_grad/sub	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/attention_weights_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/attention_weights_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/attention_weights_grad/sub	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/attention_weights_grad/sub	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/attention_weights_grad/mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/attention_weights_grad/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/k/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/k/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/k/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/k/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/k/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/k/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/k/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/k/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads/transpose_grad/transpose	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/AddN_39	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/split_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/q/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/q/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_1_grad/Sum_1	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_1_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_1_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/AddN_12	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/mul_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/AddN_12	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/sub_1_grad/Neg	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/sub_1_grad/Neg	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/sub_1_grad/Reshape_1	model/get_train_op/gradients/AddN_11	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/Tile	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_1_grad/truediv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Square_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Square_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/sub_grad/Neg	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/AddN_11	model/get_train_op/gradients/AddN_12	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/sub_grad/Neg	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/sub_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/sub_grad/Reshape_1	model/get_train_op/gradients/AddN_11	
model/get_train_op/gradients/AddN_11	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/Tile	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/encdec_attention/layer_normalization/Mean_grad/truediv	model/get_train_op/gradients/AddN_12	
model/get_train_op/gradients/AddN_12	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/add_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/add_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/AddN_15	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/add_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/combine_heads/Reshape_grad/Reshape	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/combine_heads/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/combine_heads/transpose_grad/transpose	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/combine_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/MatMul_1_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/MatMul_1_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/MatMul_1_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/MatMul_1_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/v/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/dropout/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/v/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/dropout/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/AddN_13	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/attention_weights_grad/sub	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/attention_weights_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/attention_weights_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/attention_weights_grad/sub	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/attention_weights_grad/sub	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/attention_weights_grad/mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/attention_weights_grad/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/k/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/k/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads/transpose_grad/transpose	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/AddN_13	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/split_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/AddN_13	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/AddN_13	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/AddN_15	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/mul_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/AddN_15	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/sub_1_grad/Neg	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/sub_1_grad/Neg	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/sub_1_grad/Reshape_1	model/get_train_op/gradients/AddN_14	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Tile	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/truediv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Square_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Square_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/sub_grad/Neg	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/AddN_14	model/get_train_op/gradients/AddN_15	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/sub_grad/Neg	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/sub_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/sub_grad/Reshape_1	model/get_train_op/gradients/AddN_14	
model/get_train_op/gradients/AddN_14	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Tile	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/truediv	model/get_train_op/gradients/AddN_15	
model/get_train_op/gradients/AddN_15	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/add_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/add_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/dropout/mul_grad/Mul	model/get_train_op/gradients/AddN_17	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/add_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/BiasAdd_grad/BiasAddGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/BiasAdd_grad/BiasAddGrad	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/dropout/mul_grad/Mul	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Relu_grad/ReluGrad	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Relu_grad/ReluGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/BiasAdd_grad/BiasAddGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/BiasAdd_grad/BiasAddGrad	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_1_grad/Sum_1	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/AddN_17	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/mul_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/AddN_17	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/sub_1_grad/Neg	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/sub_1_grad/Neg	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/sub_1_grad/Reshape_1	model/get_train_op/gradients/AddN_16	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Tile	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/truediv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Square_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Square_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/sub_grad/Neg	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/AddN_16	model/get_train_op/gradients/AddN_17	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/sub_grad/Neg	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/sub_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/sub_grad/Reshape_1	model/get_train_op/gradients/AddN_16	
model/get_train_op/gradients/AddN_16	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Tile	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/ffn/layer_normalization/Mean_grad/truediv	model/get_train_op/gradients/AddN_17	
model/get_train_op/gradients/AddN_17	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/add_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/add_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/AddN_19	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/add_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/combine_heads/Reshape_grad/Reshape	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/combine_heads/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/combine_heads/transpose_grad/transpose	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/combine_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/MatMul_1_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/MatMul_1_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/MatMul_1_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/MatMul_1_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/v/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/v/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/v/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/v/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/v/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/v/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/v/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/v/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/AddN_39	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/attention_weights_grad/sub	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/attention_weights_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/attention_weights_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/attention_weights_grad/sub	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/attention_weights_grad/sub	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/attention_weights_grad/mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/attention_weights_grad/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/k/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/k/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/k/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/k/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/k/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/k/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/k/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/k/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads/transpose_grad/transpose	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/AddN_39	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/split_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/q/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/q/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_1_grad/Sum_1	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_1_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_1_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/AddN_19	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/mul_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/AddN_19	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/sub_1_grad/Neg	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/sub_1_grad/Neg	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/sub_1_grad/Reshape_1	model/get_train_op/gradients/AddN_18	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/Tile	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_1_grad/truediv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Square_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Square_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/sub_grad/Neg	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/AddN_18	model/get_train_op/gradients/AddN_19	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/sub_grad/Neg	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/sub_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/sub_grad/Reshape_1	model/get_train_op/gradients/AddN_18	
model/get_train_op/gradients/AddN_18	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/Tile	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/encdec_attention/layer_normalization/Mean_grad/truediv	model/get_train_op/gradients/AddN_19	
model/get_train_op/gradients/AddN_19	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/add_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/add_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/AddN_22	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/add_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/combine_heads/Reshape_grad/Reshape	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/combine_heads/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/combine_heads/transpose_grad/transpose	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/combine_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/MatMul_1_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/MatMul_1_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/MatMul_1_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/MatMul_1_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/v/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/dropout/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/v/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/dropout/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/AddN_20	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/attention_weights_grad/sub	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/attention_weights_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/attention_weights_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/attention_weights_grad/sub	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/attention_weights_grad/sub	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/attention_weights_grad/mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/attention_weights_grad/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/k/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/k/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads/transpose_grad/transpose	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/AddN_20	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/split_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/AddN_20	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/AddN_20	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/AddN_22	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/mul_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/AddN_22	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/sub_1_grad/Neg	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/sub_1_grad/Neg	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/sub_1_grad/Reshape_1	model/get_train_op/gradients/AddN_21	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Tile	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/truediv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Square_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Square_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/sub_grad/Neg	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/AddN_21	model/get_train_op/gradients/AddN_22	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/sub_grad/Neg	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/sub_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/sub_grad/Reshape_1	model/get_train_op/gradients/AddN_21	
model/get_train_op/gradients/AddN_21	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Tile	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/truediv	model/get_train_op/gradients/AddN_22	
model/get_train_op/gradients/AddN_22	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/add_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/add_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/dropout/mul_grad/Mul	model/get_train_op/gradients/AddN_24	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/add_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/BiasAdd_grad/BiasAddGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/BiasAdd_grad/BiasAddGrad	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/dropout/mul_grad/Mul	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Relu_grad/ReluGrad	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Relu_grad/ReluGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/BiasAdd_grad/BiasAddGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/BiasAdd_grad/BiasAddGrad	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_1_grad/Sum_1	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/AddN_24	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/mul_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/AddN_24	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/sub_1_grad/Neg	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/sub_1_grad/Neg	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/sub_1_grad/Reshape_1	model/get_train_op/gradients/AddN_23	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Tile	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/truediv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Square_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Square_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/sub_grad/Neg	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/AddN_23	model/get_train_op/gradients/AddN_24	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/sub_grad/Neg	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/sub_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/sub_grad/Reshape_1	model/get_train_op/gradients/AddN_23	
model/get_train_op/gradients/AddN_23	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Tile	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/ffn/layer_normalization/Mean_grad/truediv	model/get_train_op/gradients/AddN_24	
model/get_train_op/gradients/AddN_24	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/add_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/add_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/AddN_26	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/add_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/combine_heads/Reshape_grad/Reshape	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/combine_heads/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/combine_heads/transpose_grad/transpose	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/combine_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/MatMul_1_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/MatMul_1_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/MatMul_1_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/MatMul_1_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/v/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/v/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/v/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/v/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/v/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/v/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/v/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/v/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/AddN_39	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/attention_weights_grad/sub	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/attention_weights_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/attention_weights_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/attention_weights_grad/sub	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/attention_weights_grad/sub	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/attention_weights_grad/mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/attention_weights_grad/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/k/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/k/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/k/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/k/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/k/Tensordot/MatMul_grad/MatMul	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/k/kernel/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/k/Tensordot/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/k/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/k/kernel/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/k/Tensordot/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads/transpose_grad/transpose	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/AddN_39	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/split_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/q/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/q/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_1_grad/Sum_1	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_1_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_1_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/AddN_26	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/mul_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/AddN_26	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/sub_1_grad/Neg	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/sub_1_grad/Neg	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/sub_1_grad/Reshape_1	model/get_train_op/gradients/AddN_25	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/Tile	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_1_grad/truediv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Square_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Square_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/sub_grad/Neg	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/AddN_25	model/get_train_op/gradients/AddN_26	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/sub_grad/Neg	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/sub_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/sub_grad/Reshape_1	model/get_train_op/gradients/AddN_25	
model/get_train_op/gradients/AddN_25	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/Tile	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/encdec_attention/layer_normalization/Mean_grad/truediv	model/get_train_op/gradients/AddN_26	
model/get_train_op/gradients/AddN_26	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/add_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/add_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/AddN_29	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/add_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/combine_heads/Reshape_grad/Reshape	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/combine_heads/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/combine_heads/transpose_grad/transpose	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/combine_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/MatMul_1_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/MatMul_1_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/MatMul_1_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/MatMul_1_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/v/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/dropout/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/v/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/dropout/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/AddN_27	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/attention_weights_grad/sub	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/attention_weights_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/attention_weights_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/attention_weights_grad/sub	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/attention_weights_grad/sub	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/attention_weights_grad/mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/attention_weights_grad/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/k/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/k/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads/transpose_grad/transpose	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/AddN_27	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/split_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/AddN_27	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/AddN_27	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/AddN_29	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/mul_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/AddN_29	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/sub_1_grad/Neg	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/sub_1_grad/Neg	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/sub_1_grad/Reshape_1	model/get_train_op/gradients/AddN_28	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Tile	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/truediv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Square_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Square_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/sub_grad/Neg	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/AddN_28	model/get_train_op/gradients/AddN_29	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/sub_grad/Neg	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/sub_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/sub_grad/Reshape_1	model/get_train_op/gradients/AddN_28	
model/get_train_op/gradients/AddN_28	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Tile	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/truediv	model/get_train_op/gradients/AddN_29	
model/get_train_op/gradients/AddN_29	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/add_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/add_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/dropout/mul_grad/Mul	model/get_train_op/gradients/AddN_31	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/add_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/BiasAdd_grad/BiasAddGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/BiasAdd_grad/BiasAddGrad	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/dropout/mul_grad/Mul	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Relu_grad/ReluGrad	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Relu_grad/ReluGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/BiasAdd_grad/BiasAddGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/BiasAdd_grad/BiasAddGrad	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_1_grad/Sum_1	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/AddN_31	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/mul_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/AddN_31	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/sub_1_grad/Neg	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/sub_1_grad/Neg	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/sub_1_grad/Reshape_1	model/get_train_op/gradients/AddN_30	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Tile	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/truediv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Square_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Square_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/sub_grad/Neg	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/AddN_30	model/get_train_op/gradients/AddN_31	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/sub_grad/Neg	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/sub_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/sub_grad/Reshape_1	model/get_train_op/gradients/AddN_30	
model/get_train_op/gradients/AddN_30	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Tile	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/ffn/layer_normalization/Mean_grad/truediv	model/get_train_op/gradients/AddN_31	
model/get_train_op/gradients/AddN_31	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/add_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/add_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/AddN_33	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/add_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/combine_heads/Reshape_grad/Reshape	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/combine_heads/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/combine_heads/transpose_grad/transpose	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/combine_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/MatMul_1_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/MatMul_1_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/MatMul_1_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/MatMul_1_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/v/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/v/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/v/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/v/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/v/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/v/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/v/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/v/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/AddN_39	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/attention_weights_grad/sub	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/attention_weights_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/attention_weights_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/attention_weights_grad/sub	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/attention_weights_grad/sub	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/attention_weights_grad/mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/attention_weights_grad/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/k/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/k/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/k/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/k/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/k/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/k/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/k/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/k/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads/transpose_grad/transpose	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/AddN_39	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/split_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/q/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/q/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_1_grad/Sum_1	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_1_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_1_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/AddN_33	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/mul_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/AddN_33	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/sub_1_grad/Neg	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/sub_1_grad/Neg	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/sub_1_grad/Reshape_1	model/get_train_op/gradients/AddN_32	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/Tile	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_1_grad/truediv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Square_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Square_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/sub_grad/Neg	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/AddN_32	model/get_train_op/gradients/AddN_33	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/sub_grad/Neg	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/sub_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/sub_grad/Reshape_1	model/get_train_op/gradients/AddN_32	
model/get_train_op/gradients/AddN_32	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/Tile	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/encdec_attention/layer_normalization/Mean_grad/truediv	model/get_train_op/gradients/AddN_33	
model/get_train_op/gradients/AddN_33	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/add_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/add_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/AddN_36	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/add_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/combine_heads/Reshape_grad/Reshape	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/combine_heads/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/combine_heads/transpose_grad/transpose	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/combine_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/MatMul_1_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/MatMul_1_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/MatMul_1_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/MatMul_1_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/v/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/dropout/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/v/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/dropout/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/AddN_34	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/attention_weights_grad/sub	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/attention_weights_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/attention_weights_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/attention_weights_grad/sub	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/attention_weights_grad/sub	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/attention_weights_grad/mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/attention_weights_grad/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/k/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/k/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads/transpose_grad/transpose	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/AddN_34	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/split_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/AddN_34	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/AddN_34	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/AddN_36	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/mul_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/AddN_36	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/sub_1_grad/Neg	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/sub_1_grad/Neg	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/sub_1_grad/Reshape_1	model/get_train_op/gradients/AddN_35	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Tile	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/truediv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Square_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Square_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/sub_grad/Neg	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/AddN_35	model/get_train_op/gradients/AddN_36	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/sub_grad/Neg	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/sub_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/sub_grad/Reshape_1	model/get_train_op/gradients/AddN_35	
model/get_train_op/gradients/AddN_35	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Tile	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/truediv	model/get_train_op/gradients/AddN_36	
model/get_train_op/gradients/AddN_36	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/add_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/add_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/dropout/mul_grad/Mul	model/get_train_op/gradients/AddN_38	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/add_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/BiasAdd_grad/BiasAddGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/BiasAdd_grad/BiasAddGrad	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/dropout/mul_grad/Mul	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Relu_grad/ReluGrad	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Relu_grad/ReluGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/BiasAdd_grad/BiasAddGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/BiasAdd_grad/BiasAddGrad	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_1_grad/Sum_1	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/AddN_38	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/mul_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/AddN_38	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/sub_1_grad/Neg	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/sub_1_grad/Neg	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/sub_1_grad/Reshape_1	model/get_train_op/gradients/AddN_37	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Tile	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/truediv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Square_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Square_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/sub_grad/Neg	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/AddN_37	model/get_train_op/gradients/AddN_38	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/sub_grad/Neg	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/sub_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/sub_grad/Reshape_1	model/get_train_op/gradients/AddN_37	
model/get_train_op/gradients/AddN_37	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Tile	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/ffn/layer_normalization/Mean_grad/truediv	model/get_train_op/gradients/AddN_38	
model/get_train_op/gradients/AddN_38	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/add_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/add_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/AddN_43	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/add_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/combine_heads/Reshape_grad/Reshape	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/combine_heads/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/combine_heads/transpose_grad/transpose	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/combine_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/MatMul_1_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/MatMul_1_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/MatMul_1_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/MatMul_1_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/v/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/v/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/v/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/v/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/v/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/v/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/v/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/v/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/AddN_39	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/attention_weights_grad/sub	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/attention_weights_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/attention_weights_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/attention_weights_grad/sub	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/attention_weights_grad/sub	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/attention_weights_grad/mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/attention_weights_grad/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_1/transpose_grad/transpose	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_1/transpose_grad/transpose	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads/transpose_grad/transpose	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/k/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/k/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/split_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/AddN_39	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/AddN_39	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/add_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/q/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/q/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/add_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/add_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_1_grad/Sum_1	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/add_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/add_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_1_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_1_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_1_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_1_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_grad/Mul_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_grad/Sum_1	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_grad/Reshape_1	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/encdec_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/AddN_43	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/mul_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/mul_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/AddN_43	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_1_grad/Neg	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/sub_1_grad/Neg	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_1_grad/Reshape	model/get_train_op/gradients/AddN_40	model/get_train_op/gradients/AddN_42	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_1_grad/Neg	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/sub_1_grad/Neg	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_1_grad/Reshape_1	model/get_train_op/gradients/AddN_40	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/sub_1_grad/Reshape_1	model/get_train_op/gradients/AddN_41	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/Tile	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/Tile	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_1_grad/truediv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_1_grad/truediv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Square_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Square_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Square_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Square_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_grad/Neg	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/sub_grad/Neg	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/AddN_41	model/get_train_op/gradients/AddN_43	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/AddN_40	model/get_train_op/gradients/AddN_42	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_grad/Neg	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/sub_grad/Neg	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/sub_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/sub_grad/Reshape_1	model/get_train_op/gradients/AddN_40	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/sub_grad/Reshape_1	model/get_train_op/gradients/AddN_41	
model/get_train_op/gradients/AddN_40	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/AddN_41	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/Tile	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/Tile	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_normalization/Mean_grad/truediv	model/get_train_op/gradients/AddN_42	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/encdec_attention/layer_normalization/Mean_grad/truediv	model/get_train_op/gradients/AddN_43	
model/get_train_op/gradients/AddN_42	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/add_grad/Sum_1	
model/get_train_op/gradients/AddN_43	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/add_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/add_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/add_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/add_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/dropout/mul_grad/Mul	model/get_train_op/gradients/AddN_47	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/add_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/AddN_48	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/add_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/re_add_padding/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/re_add_padding/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/re_add_padding/ScatterNd_grad/GatherNd	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/re_add_padding/ScatterNd_grad/GatherNd	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/re_add_padding/Squeeze_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/re_add_padding/Squeeze_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/BiasAdd_grad/BiasAddGrad	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/combine_heads/Reshape_grad/Reshape	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/BiasAdd_grad/BiasAddGrad	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/combine_heads/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/combine_heads/transpose_grad/transpose	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/combine_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/MatMul_1_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/MatMul_1_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/MatMul_1_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/MatMul_1_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/dropout/mul_grad/Mul	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/v/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/dropout/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/v/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/dropout/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/AddN_44	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Relu_grad/ReluGrad	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/attention_weights_grad/sub	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Relu_grad/ReluGrad	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/BiasAdd_grad/BiasAddGrad	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/attention_weights_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/BiasAdd_grad/BiasAddGrad	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/attention_weights_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/attention_weights_grad/sub	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/attention_weights_grad/sub	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/attention_weights_grad/mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/attention_weights_grad/mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/ExpandDims_grad/Reshape	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/ExpandDims_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/tensor	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/GatherNd_grad/Squeeze/_4560	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/GatherNd_grad/Squeeze/_4561	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/GatherNd_grad/Squeeze/_4561	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/tensor	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/tensor	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/k/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/k/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads/transpose_grad/transpose	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/AddN_44	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/split_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot_grad/Reshape	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/AddN_44	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_grad/Mul_1	
model/get_train_op/gradients/AddN_44	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/Sum_1	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/mul_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_1_grad/Neg	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_1_grad/Reshape	model/get_train_op/gradients/AddN_45	model/get_train_op/gradients/AddN_47	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_1_grad/Neg	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_1_grad/Reshape_1	model/get_train_op/gradients/AddN_45	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/train/update_model/Transformer/decoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/AddN_48	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/Tile	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_1_grad/truediv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/mul_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/AddN_48	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/sub_1_grad/Neg	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Square_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/sub_1_grad/Neg	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Square_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/sub_1_grad/Reshape_1	model/get_train_op/gradients/AddN_46	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_grad/Neg	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/AddN_45	model/get_train_op/gradients/AddN_47	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_grad/Neg	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Tile	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/sub_grad/Reshape_1	model/get_train_op/gradients/AddN_45	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/truediv	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/AddN_45	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Square_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/Tile	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Square_grad/Mul_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/ffn/layer_normalization/Mean_grad/truediv	model/get_train_op/gradients/AddN_47	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/sub_grad/Neg	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/AddN_46	model/get_train_op/gradients/AddN_48	
model/get_train_op/gradients/AddN_47	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/sub_grad/Neg	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/sub_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/add_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/add_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/sub_grad/Reshape_1	model/get_train_op/gradients/AddN_46	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/AddN_51	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/add_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/AddN_46	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Tile	model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/decoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/truediv	model/get_train_op/gradients/AddN_48	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot_grad/Reshape	
model/get_train_op/gradients/AddN_48	model/get_train_op/gradients/model/Transformer/decode/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/decode/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/decode/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/decode/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/combine_heads/Reshape_grad/Reshape	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/decode/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/combine_heads/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/combine_heads/transpose_grad/transpose	
model/get_train_op/gradients/model/Transformer/decode/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/add_pos_encoding/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/combine_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/MatMul_1_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/MatMul_1_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/add_pos_encoding/add_grad/Sum	model/get_train_op/gradients/model/Transformer/decode/add_pos_encoding/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/MatMul_1_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_2/transpose_grad/transpose	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/MatMul_1_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_2/transpose_grad/transpose	
model/get_train_op/gradients/model/Transformer/decode/add_pos_encoding/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/decode/shift_targets/strided_slice_grad/StridedSliceGrad	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/v/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/decode/shift_targets/strided_slice_grad/StridedSliceGrad	model/get_train_op/gradients/model/Transformer/decode/shift_targets/Pad_grad/Slice_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/v/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/decode/shift_targets/Pad_grad/Slice_1	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/mul_1_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/mul_1_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/AddN_49	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/mul_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/mul_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/attention_weights_grad/sub	
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/attention_weights_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/attention_weights_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/attention_weights_grad/sub	
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/Gather_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/attention_weights_grad/sub	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/attention_weights_grad/mul_1	
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding_1/Gather_grad/Reshape	model/get_train_op/gradients/concat	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/attention_weights_grad/mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/k/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/k/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads/transpose_grad/transpose	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/AddN_49	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/split_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/AddN_49	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/AddN_49	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_grad/Mul_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_grad/Sum_1	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_5/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/mul_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_1_grad/Neg	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_1_grad/Reshape	model/get_train_op/gradients/AddN_50	model/get_train_op/gradients/AddN_51	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_1_grad/Neg	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_1_grad/Reshape_1	model/get_train_op/gradients/AddN_50	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/Tile	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_1_grad/truediv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Square_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Square_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_grad/Neg	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/AddN_50	model/get_train_op/gradients/AddN_51	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_grad/Neg	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/sub_grad/Reshape_1	model/get_train_op/gradients/AddN_50	
model/get_train_op/gradients/AddN_50	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/Tile	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_5/self_attention/layer_normalization/Mean_grad/truediv	model/get_train_op/gradients/AddN_51	
model/get_train_op/gradients/AddN_51	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/add_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/add_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/dropout/mul_grad/Mul	model/get_train_op/gradients/AddN_53	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/add_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/re_add_padding/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/re_add_padding/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/re_add_padding/ScatterNd_grad/GatherNd	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/re_add_padding/ScatterNd_grad/GatherNd	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/re_add_padding/Squeeze_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/re_add_padding/Squeeze_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/BiasAdd_grad/BiasAddGrad	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/BiasAdd_grad/BiasAddGrad	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/dropout/mul_grad/Mul	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Relu_grad/ReluGrad	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Relu_grad/ReluGrad	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/BiasAdd_grad/BiasAddGrad	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/BiasAdd_grad/BiasAddGrad	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/ExpandDims_grad/Reshape	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/ExpandDims_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/tensor	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/GatherNd_grad/Squeeze/_4562	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/GatherNd_grad/Squeeze/_4563	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/GatherNd_grad/Squeeze/_4563	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/tensor	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/tensor	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/mul_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_1_grad/Neg	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_1_grad/Reshape	model/get_train_op/gradients/AddN_52	model/get_train_op/gradients/AddN_53	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_1_grad/Neg	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_1_grad/Reshape_1	model/get_train_op/gradients/AddN_52	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/Tile	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_1_grad/truediv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Square_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Square_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_grad/Neg	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/AddN_52	model/get_train_op/gradients/AddN_53	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_grad/Neg	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/sub_grad/Reshape_1	model/get_train_op/gradients/AddN_52	
model/get_train_op/gradients/AddN_52	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/Tile	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/ffn/layer_normalization/Mean_grad/truediv	model/get_train_op/gradients/AddN_53	
model/get_train_op/gradients/AddN_53	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/add_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/add_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/AddN_56	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/add_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/combine_heads/Reshape_grad/Reshape	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/combine_heads/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/combine_heads/transpose_grad/transpose	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/combine_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/MatMul_1_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/MatMul_1_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/MatMul_1_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_2/transpose_grad/transpose	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/MatMul_1_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_2/transpose_grad/transpose	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/v/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/v/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/AddN_54	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/attention_weights_grad/sub	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/attention_weights_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/attention_weights_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/attention_weights_grad/sub	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/attention_weights_grad/sub	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/attention_weights_grad/mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/attention_weights_grad/mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/k/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/k/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads/transpose_grad/transpose	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/AddN_54	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/split_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/AddN_54	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/AddN_54	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_grad/Mul_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_grad/Sum_1	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_4/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/mul_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_1_grad/Neg	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_1_grad/Reshape	model/get_train_op/gradients/AddN_55	model/get_train_op/gradients/AddN_56	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_1_grad/Neg	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_1_grad/Reshape_1	model/get_train_op/gradients/AddN_55	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/Tile	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_1_grad/truediv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Square_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Square_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_grad/Neg	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/AddN_55	model/get_train_op/gradients/AddN_56	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_grad/Neg	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/sub_grad/Reshape_1	model/get_train_op/gradients/AddN_55	
model/get_train_op/gradients/AddN_55	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/Tile	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_4/self_attention/layer_normalization/Mean_grad/truediv	model/get_train_op/gradients/AddN_56	
model/get_train_op/gradients/AddN_56	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/add_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/add_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/dropout/mul_grad/Mul	model/get_train_op/gradients/AddN_58	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/add_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/re_add_padding/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/re_add_padding/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/re_add_padding/ScatterNd_grad/GatherNd	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/re_add_padding/ScatterNd_grad/GatherNd	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/re_add_padding/Squeeze_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/re_add_padding/Squeeze_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/BiasAdd_grad/BiasAddGrad	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/BiasAdd_grad/BiasAddGrad	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/dropout/mul_grad/Mul	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Relu_grad/ReluGrad	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Relu_grad/ReluGrad	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/BiasAdd_grad/BiasAddGrad	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/BiasAdd_grad/BiasAddGrad	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/ExpandDims_grad/Reshape	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/ExpandDims_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/tensor	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/GatherNd_grad/Squeeze/_4564	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/GatherNd_grad/Squeeze/_4565	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/GatherNd_grad/Squeeze/_4565	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/tensor	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/tensor	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/mul_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_1_grad/Neg	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_1_grad/Reshape	model/get_train_op/gradients/AddN_57	model/get_train_op/gradients/AddN_58	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_1_grad/Neg	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_1_grad/Reshape_1	model/get_train_op/gradients/AddN_57	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/Tile	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_1_grad/truediv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Square_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Square_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_grad/Neg	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/AddN_57	model/get_train_op/gradients/AddN_58	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_grad/Neg	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/sub_grad/Reshape_1	model/get_train_op/gradients/AddN_57	
model/get_train_op/gradients/AddN_57	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/Tile	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/ffn/layer_normalization/Mean_grad/truediv	model/get_train_op/gradients/AddN_58	
model/get_train_op/gradients/AddN_58	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/add_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/add_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/AddN_61	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/add_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/combine_heads/Reshape_grad/Reshape	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/combine_heads/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/combine_heads/transpose_grad/transpose	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/combine_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/MatMul_1_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/MatMul_1_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/MatMul_1_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_2/transpose_grad/transpose	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/MatMul_1_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_2/transpose_grad/transpose	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/v/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/v/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/AddN_59	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/attention_weights_grad/sub	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/attention_weights_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/attention_weights_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/attention_weights_grad/sub	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/attention_weights_grad/sub	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/attention_weights_grad/mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/attention_weights_grad/mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/k/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/k/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads/transpose_grad/transpose	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/AddN_59	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/split_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/AddN_59	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/AddN_59	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_grad/Mul_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_grad/Sum_1	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_3/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/mul_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_1_grad/Neg	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_1_grad/Reshape	model/get_train_op/gradients/AddN_60	model/get_train_op/gradients/AddN_61	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_1_grad/Neg	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_1_grad/Reshape_1	model/get_train_op/gradients/AddN_60	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/Tile	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_1_grad/truediv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Square_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Square_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_grad/Neg	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/AddN_60	model/get_train_op/gradients/AddN_61	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_grad/Neg	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/sub_grad/Reshape_1	model/get_train_op/gradients/AddN_60	
model/get_train_op/gradients/AddN_60	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/Tile	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_3/self_attention/layer_normalization/Mean_grad/truediv	model/get_train_op/gradients/AddN_61	
model/get_train_op/gradients/AddN_61	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/add_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/add_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/dropout/mul_grad/Mul	model/get_train_op/gradients/AddN_63	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/add_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/re_add_padding/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/re_add_padding/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/re_add_padding/ScatterNd_grad/GatherNd	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/re_add_padding/ScatterNd_grad/GatherNd	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/re_add_padding/Squeeze_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/re_add_padding/Squeeze_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/BiasAdd_grad/BiasAddGrad	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/BiasAdd_grad/BiasAddGrad	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/dropout/mul_grad/Mul	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Relu_grad/ReluGrad	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Relu_grad/ReluGrad	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/BiasAdd_grad/BiasAddGrad	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/BiasAdd_grad/BiasAddGrad	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/ExpandDims_grad/Reshape	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/ExpandDims_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/tensor	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/GatherNd_grad/Squeeze/_4566	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/GatherNd_grad/Squeeze/_4567	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/GatherNd_grad/Squeeze/_4567	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/tensor	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/tensor	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/mul_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_1_grad/Neg	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_1_grad/Reshape	model/get_train_op/gradients/AddN_62	model/get_train_op/gradients/AddN_63	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_1_grad/Neg	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_1_grad/Reshape_1	model/get_train_op/gradients/AddN_62	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/Tile	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_1_grad/truediv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Square_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Square_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_grad/Neg	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/AddN_62	model/get_train_op/gradients/AddN_63	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_grad/Neg	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/sub_grad/Reshape_1	model/get_train_op/gradients/AddN_62	
model/get_train_op/gradients/AddN_62	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/Tile	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/ffn/layer_normalization/Mean_grad/truediv	model/get_train_op/gradients/AddN_63	
model/get_train_op/gradients/AddN_63	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/add_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/add_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/AddN_66	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/add_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/combine_heads/Reshape_grad/Reshape	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/combine_heads/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/combine_heads/transpose_grad/transpose	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/combine_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/MatMul_1_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/MatMul_1_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/MatMul_1_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_2/transpose_grad/transpose	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/MatMul_1_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_2/transpose_grad/transpose	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/v/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/v/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/AddN_64	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/attention_weights_grad/sub	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/attention_weights_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/attention_weights_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/attention_weights_grad/sub	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/attention_weights_grad/sub	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/attention_weights_grad/mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/attention_weights_grad/mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/k/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/k/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads/transpose_grad/transpose	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/AddN_64	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/split_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/AddN_64	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/AddN_64	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_grad/Mul_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_grad/Sum_1	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_2/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/mul_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_1_grad/Neg	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_1_grad/Reshape	model/get_train_op/gradients/AddN_65	model/get_train_op/gradients/AddN_66	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_1_grad/Neg	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_1_grad/Reshape_1	model/get_train_op/gradients/AddN_65	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/Tile	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_1_grad/truediv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Square_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Square_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_grad/Neg	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/AddN_65	model/get_train_op/gradients/AddN_66	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_grad/Neg	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/sub_grad/Reshape_1	model/get_train_op/gradients/AddN_65	
model/get_train_op/gradients/AddN_65	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/Tile	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_2/self_attention/layer_normalization/Mean_grad/truediv	model/get_train_op/gradients/AddN_66	
model/get_train_op/gradients/AddN_66	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/add_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/add_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/dropout/mul_grad/Mul	model/get_train_op/gradients/AddN_68	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/add_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/re_add_padding/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/re_add_padding/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/re_add_padding/ScatterNd_grad/GatherNd	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/re_add_padding/ScatterNd_grad/GatherNd	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/re_add_padding/Squeeze_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/re_add_padding/Squeeze_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/BiasAdd_grad/BiasAddGrad	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/BiasAdd_grad/BiasAddGrad	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/dropout/mul_grad/Mul	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Relu_grad/ReluGrad	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Relu_grad/ReluGrad	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/BiasAdd_grad/BiasAddGrad	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/BiasAdd_grad/BiasAddGrad	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/ExpandDims_grad/Reshape	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/ExpandDims_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/tensor	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/GatherNd_grad/Squeeze/_4568	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/GatherNd_grad/Squeeze/_4569	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/GatherNd_grad/Squeeze/_4569	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/tensor	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/tensor	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/mul_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_1_grad/Neg	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_1_grad/Reshape	model/get_train_op/gradients/AddN_67	model/get_train_op/gradients/AddN_68	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_1_grad/Neg	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_1_grad/Reshape_1	model/get_train_op/gradients/AddN_67	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/Tile	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_1_grad/truediv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Square_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Square_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_grad/Neg	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/AddN_67	model/get_train_op/gradients/AddN_68	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_grad/Neg	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/sub_grad/Reshape_1	model/get_train_op/gradients/AddN_67	
model/get_train_op/gradients/AddN_67	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/Tile	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/ffn/layer_normalization/Mean_grad/truediv	model/get_train_op/gradients/AddN_68	
model/get_train_op/gradients/AddN_68	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/add_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/add_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/AddN_71	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/add_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/combine_heads/Reshape_grad/Reshape	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/combine_heads/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/combine_heads/transpose_grad/transpose	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/combine_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/MatMul_1_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/MatMul_1_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/MatMul_1_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_2/transpose_grad/transpose	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/MatMul_1_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_2/transpose_grad/transpose	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/v/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/v/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/AddN_69	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/attention_weights_grad/sub	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/attention_weights_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/attention_weights_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/attention_weights_grad/sub	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/attention_weights_grad/sub	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/attention_weights_grad/mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/attention_weights_grad/mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/k/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/k/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads/transpose_grad/transpose	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/AddN_69	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/split_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/AddN_69	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/AddN_69	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_grad/Mul_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_grad/Sum_1	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_1/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/mul_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_1_grad/Neg	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_1_grad/Reshape	model/get_train_op/gradients/AddN_70	model/get_train_op/gradients/AddN_71	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_1_grad/Neg	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_1_grad/Reshape_1	model/get_train_op/gradients/AddN_70	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/Tile	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_1_grad/truediv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Square_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Square_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_grad/Neg	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/AddN_70	model/get_train_op/gradients/AddN_71	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_grad/Neg	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/sub_grad/Reshape_1	model/get_train_op/gradients/AddN_70	
model/get_train_op/gradients/AddN_70	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/Tile	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_1/self_attention/layer_normalization/Mean_grad/truediv	model/get_train_op/gradients/AddN_71	
model/get_train_op/gradients/AddN_71	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/add_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/add_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/dropout/mul_grad/Mul	model/get_train_op/gradients/AddN_73	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/add_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/re_add_padding/Reshape_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/re_add_padding/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/re_add_padding/ScatterNd_grad/GatherNd	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/re_add_padding/ScatterNd_grad/GatherNd	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/re_add_padding/Squeeze_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/re_add_padding/Squeeze_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/BiasAdd_grad/BiasAddGrad	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/BiasAdd_grad/BiasAddGrad	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/dropout/mul_grad/Mul	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/output_layer/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Relu_grad/ReluGrad	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Relu_grad/ReluGrad	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/BiasAdd_grad/BiasAddGrad	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/BiasAdd_grad/BiasAddGrad	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/ExpandDims_grad/Reshape	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/feed_foward_network/filter_layer/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/ExpandDims_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/tensor	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/GatherNd_grad/Squeeze/_4570	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/GatherNd_grad/Squeeze/_4571	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/GatherNd_grad/Squeeze/_4571	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/tensor	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape/tensor	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/feed_foward_network/remove_padding/Reshape_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/ffn/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/mul_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_1_grad/Neg	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_1_grad/Reshape	model/get_train_op/gradients/AddN_72	model/get_train_op/gradients/AddN_73	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_1_grad/Neg	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_1_grad/Reshape_1	model/get_train_op/gradients/AddN_72	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/Tile	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_1_grad/truediv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Square_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Square_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_grad/Neg	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/AddN_72	model/get_train_op/gradients/AddN_73	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_grad/Neg	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/sub_grad/Reshape_1	model/get_train_op/gradients/AddN_72	
model/get_train_op/gradients/AddN_72	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/Tile	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/ffn/layer_normalization/Mean_grad/truediv	model/get_train_op/gradients/AddN_73	
model/get_train_op/gradients/AddN_73	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/add_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/add_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/add_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/AddN_76	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/add_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/output_transform/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/combine_heads/Reshape_grad/Reshape	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/output_transform/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/combine_heads/Reshape_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/combine_heads/transpose_grad/transpose	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/combine_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/MatMul_1_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/MatMul_1_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/MatMul_1_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_2/transpose_grad/transpose	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/MatMul_1_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_2/transpose_grad/transpose	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_2/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/v/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/v/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/v/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/v/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/v/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/AddN_74	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/v/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/attention_weights_grad/sub	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/attention_weights_grad/mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/attention_weights_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/attention_weights_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/attention_weights_grad/sub	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/attention_weights_grad/sub	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/attention_weights_grad/mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/attention_weights_grad/mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads_1/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/k/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/k/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/k/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/k/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads/transpose_grad/transpose	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/k/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/AddN_74	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/k/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/split_heads/transpose_grad/transpose	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/MatMul_grad/MatMul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/q/kernel/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/self_attention/q/Tensordot/Reshape_grad/Reshape	model/get_train_op/gradients/AddN_74	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/self_attention/q/kernel/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/AddN_74	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Mul_1	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_bias/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_1_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_grad/Mul_1	model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_grad/Sum_1	
model/get_train_op/train/update_model/Transformer/encoder_stack/layer_0/self_attention/layer_normalization/layer_norm_scale/ResourceApplyAdam	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_grad/Reshape_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_1_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/mul_grad/tuple/group_deps	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_1_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_1_grad/Neg	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Rsqrt_grad/RsqrtGrad	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_1_grad/Reshape	model/get_train_op/gradients/AddN_75	model/get_train_op/gradients/AddN_76	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_1_grad/Neg	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_1_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_1_grad/Reshape_1	model/get_train_op/gradients/AddN_75	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Tile	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/Tile	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/truediv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_1_grad/truediv	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Square_grad/Const	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Square_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Square_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Square_grad/Mul_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Square_grad/Mul_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_grad/Sum_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_grad/Sum_1	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_grad/Neg	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_grad/Reshape	model/get_train_op/gradients/AddN_75	model/get_train_op/gradients/AddN_76	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_grad/Neg	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_grad/Reshape_1	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/sub_grad/Reshape_1	model/get_train_op/gradients/AddN_75	
model/get_train_op/gradients/AddN_75	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Tile	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/Tile	model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/truediv	
model/get_train_op/gradients/model/Transformer/encode/encoder_stack/layer_0/self_attention/layer_normalization/Mean_grad/truediv	model/get_train_op/gradients/AddN_76	
model/get_train_op/gradients/AddN_76	model/get_train_op/gradients/model/Transformer/encode/dropout/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/dropout/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/dropout/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/dropout/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/dropout/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/dropout/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/dropout/div_grad/RealDiv	
model/get_train_op/gradients/model/Transformer/encode/dropout/div_grad/RealDiv	model/get_train_op/gradients/model/Transformer/encode/dropout/div_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/dropout/div_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/dropout/div_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/dropout/div_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/add_pos_encoding/add_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/add_pos_encoding/add_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/add_pos_encoding/add_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/add_pos_encoding/add_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/mul_1_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/mul_1_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/mul_1_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/mul_1_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/mul_1_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/mul_1_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/mul_grad/Mul	
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/mul_grad/Mul	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/mul_grad/Sum	
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/mul_grad/Sum	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/mul_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/mul_grad/Reshape	model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/Gather_grad/Reshape	
model/get_train_op/gradients/model/Transformer/encode/embedding_shared_weights/embedding/Gather_grad/Reshape	model/get_train_op/gradients/concat	
model/get_train_op/gradients/concat	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/UnsortedSegmentSum	
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/Unique/_4572	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/Unique/_4573	
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/Unique/_4573	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/UnsortedSegmentSum	
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/UnsortedSegmentSum	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/mul_1	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/mul_3	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/mul_4	
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/mul_1	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/ResourceScatterAdd	
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/mul_3	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/mul_4	
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/ResourceScatterAdd	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/ReadVariableOp_4	
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/mul_4	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/ResourceScatterAdd_1	
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/ReadVariableOp_4	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/mul_6	
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/ResourceScatterAdd_1	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/ReadVariableOp_7	
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/mul_6	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/truediv_1	
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/ReadVariableOp_7	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/Sqrt_1	
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/Sqrt_1	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/add	
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/add	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/truediv_1	
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/truediv_1	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/AssignSubVariableOp	
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/AssignSubVariableOp	model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/ReadVariableOp_8	
model/get_train_op/train/update_model/Transformer/embedding_shared_weights/embedding_and_softmax/weights/ReadVariableOp_8	model/get_train_op/train/ReadVariableOp	model/get_train_op/train/ReadVariableOp_2	
model/get_train_op/train/ReadVariableOp	model/get_train_op/train/mul	
model/get_train_op/train/ReadVariableOp_2	model/get_train_op/train/mul_1	
model/get_train_op/train/mul	model/get_train_op/train/AssignVariableOp	
model/get_train_op/train/mul_1	model/get_train_op/train/AssignVariableOp_1	
model/get_train_op/train/AssignVariableOp	model/get_train_op/train/ReadVariableOp_1	
model/get_train_op/train/AssignVariableOp_1	model/get_train_op/train/ReadVariableOp_3	
model/get_train_op/train/ReadVariableOp_1	model/get_train_op/train/Const	
model/get_train_op/train/ReadVariableOp_3	model/get_train_op/train/Const	
model/get_train_op/train/Const	model/get_train_op/train/AssignAddVariableOp	
model/get_train_op/train/AssignAddVariableOp	model/get_train_op/group_deps	
model/get_train_op/group_deps	_SINK	
Identity/_4574	_SINK	
model/truediv/_4576	_SINK	
