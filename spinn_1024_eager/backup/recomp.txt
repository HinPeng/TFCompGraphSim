2019-07-09 10:07:58,976  graphSim_eager.py 2292L InitNodesExecutionTime : INFO  Total num of Nodes is 55739
2019-07-09 10:11:34,643  graphSim_eager.py 2402L InitNodesFanin : INFO  Total num of Tensors is 373298
2019-07-09 10:11:38,945  graphSim_eager.py 2518L InitTensorSize : INFO  Sum GPU memory allocated is 28916.109619 MB
2019-07-09 10:11:56,705  graphSim_eager.py 532L access_analysisV1 : INFO  mm_candidates: 50029
2019-07-09 10:12:21,774  graphSim_eager.py 543L access_analysisV1 : INFO  Peak memory usage from tensor access is 20859.250977 MB
2019-07-09 10:12:21,775  graphSim_eager.py 544L access_analysisV1 : INFO  Peak memory usage live tensors number is 1372
2019-07-09 10:12:23,436  graphSim_eager.py 796L GetMaxSavingMemory : INFO  Maximum node is RealDiv_1 with 114.803223 MB
2019-07-09 10:12:23,437  graphSim_eager.py 798L GetMaxSavingMemory : INFO  Can swap out 1372 tensors, total memory we can save is -17375.736816 MB
2019-07-09 10:12:23,437  graphSim_eager.py 1372L InitRecomp : INFO  Required saving not set, will choose AMAP for recomputation
2019-07-09 10:52:45,634  recomp_info.py 883L IsRoot : INFO  Reshape_3:0 has no inputs
2019-07-09 10:52:45,634  graphSim_eager.py 1446L InitRecomp : WARNING  set root: Reshape_3:0
2019-07-09 10:52:45,634  recomp_info.py 883L IsRoot : INFO  ConcatV2_789:0 has no inputs
2019-07-09 10:52:45,634  graphSim_eager.py 1448L InitRecomp : WARNING  Got multiple root: ConcatV2_789:0
